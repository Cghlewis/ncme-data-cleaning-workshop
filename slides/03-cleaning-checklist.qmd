# Data Cleaning Checklist {.background-secondary}

## Data Cleaning

![](images/side-by-side-data.PNG){fig-align="center"}


## Standard Data Cleaning Checklist

:::: {.columns}

::: {.column width="50%"}

`r fontawesome::fa("check")` Import the raw data

`r fontawesome::fa("check")` Review the raw data

`r fontawesome::fa("check")` Find missing data

`r fontawesome::fa("check")` Adjust the sample

`r fontawesome::fa("check")` De-identify data

`r fontawesome::fa("check")` Drop irrelevant columns

`r fontawesome::fa("check")` Split columns

`r fontawesome::fa("check")` Rename variables

`r fontawesome::fa("check")` Normalize variables

`r fontawesome::fa("check")` Standardize variables

:::
 
::: {.column width="50%"}

`r fontawesome::fa("check")` Update variable types

`r fontawesome::fa("check")` Recode variables

`r fontawesome::fa("check")` Construct new variables

`r fontawesome::fa("check")` Add missing values

`r fontawesome::fa("check")` [Add metadata](https://github.com/Cghlewis/data-wrangling-functions/wiki/Label-Data)

`r fontawesome::fa("check")` Validate data

`r fontawesome::fa("check")` [Join data](https://cghlewis.com/blog/joins/)

`r fontawesome::fa("check")` [Reshape data](https://osf.io/xumg4)

`r fontawesome::fa("check")` Save clean data

:::
:::

::: {.notes}

However, to produce datasets that consistently meet the data quality criteria we just reviewed, it can be helpful to follow a standardized checklist of data cleaning steps. These steps, although they are really general here, once you tailor them to your specific data source they can help you produce a dataset that meets our data quality standards. 

As you use this checklist to clean your specific dataset you use the steps that are relevant to your data and remove the steps that are not relevant. 

The order of these steps are fluid. With the exception of the first two on the list, you can move them around in whatever order makes sense for your specific dataset.

We are going to take some time to review each step on this list with the exception of the ones in blue. Those require more time to cover than we have today, so instead I have linked to more information here for you to review in your own time.


:::

## Import raw data

![](images/checklist1.PNG){fig-align="center"}

::: {.notes}

Importing your raw data will always be number one of course, and the most important rule here is to never make any manual edits directly in the raw data file. Your raw data file is your single source of truth for that data source. If you make errors in your data cleaning process, you should always be able to go back to the untouched raw data to start over again if you need to. 

:::

## Review data

![](images/checklist2.PNG){fig-align="center"}

::: {.notes}

Reviewing your data should always be step number two. It's important that you know exactly what is happening in your data before moving forward in the cleaning process.

If you have access to those documents we discussed earlier, participant tracking database and a data dictionary, now is the time to use them.

:::

## Find missing data

![](images/checklist3.PNG){fig-align="center"}

::: {.notes}

If you find that any data is missing in your review process (missing cases/missing variables) you'll want to retrieve that missing data before moving forward in the cleaning process

Start back at step 1

:::

## Adjust the sample

![](images/checklist4.PNG){fig-align="center"}

::: {.notes}

This means removing anyone who should not be in the dataset - maybe they didn't consent to be in the study

It also means taking care of any duplicates in your data

The first thing you'll want to do before removing duplicates is determine if it is a true duplicate, not just an error in the data

Then removing any true duplicates based on your duplicate removal rule

It's really important that these kinds of decisions rules are documented for future data users. And we'll talk more about where to document these kinds of things later.

:::

## De-identify data

![](images/checklist5-1.PNG){fig-align="center"}

## De-identify data

![](images/checklist5-2.PNG){fig-align="center"}

## De-identify data

![](images/checklist5-3.PNG){fig-align="center"}

|Source|Resource|
|--------|-----------|
|[Alena Filip](https://www.sjsu.edu/research/docs/irb-data-management-handbook.pdf) |Table 2 provides pros and cons of various de-identification methods|
|[J-PAL](https://www.povertyactionlab.org/resource/data-de-identification)| Table 3 provides a list of direct and indirect identifiers and recommended removal methods|
|[Schatschneider, et.al](https://figshare.com/articles/preprint/De-Identification_Guide/13228664)| Deidentifying Data Guide|

:::{.notes}

- Redaction
  - Eliminate the entire variable from the data
- Suppression
  - Remove data in a particular cell or row (In this example, age 67 was an outlier so I suppressed that cell value and replaced it with -98 which I’ve coded as suppressed).
- Generalization
  - Reduce precision in the data (In this example here, I’ve binned my age ranges so they are less precise)
- Truncation
  - Restricting upper and lower ranges to mask outliers
  
There are many, even more sophisticated ways, to de-identify data

:::

## Drop irrelevant columns

<br>

![](images/checklist6.PNG){fig-align="center"}

## Split columns

![](images/checklist7.PNG){fig-align="center"}

## Rename variables

![](images/checklist8.PNG){fig-align="center"}

## Normalize variables

- Compare the variable types in your raw data to the types you expected in your data dictionary. 
  - Do they align? If not, what needs to be done so that they do

![](images/checklist9.PNG){fig-align="center"}

:::{.notes}

I realize this is unconventional terminology to use, but here I am using the term normalize to talk about returning variables to their normal or expected state. 

:::

## Standardize variables

- Are columns consistently measured, categorized, and formatted according to your data dictionary?
  - If not, what needs to be done so that they are

![](images/checklist10.PNG){fig-align="center"}

:::{.notes}

Here I am using the term standardize to convey the process of checking for consistency

:::

## Update variable types

![](images/checklist11.PNG){fig-align="center"}

:::{.notes}

Character to Numeric, Numeric to Date, And so forth

:::

## Recode variables

![](images/checklist12.PNG){fig-align="center"}

:::{.notes}

- This includes recoding your categorical numeric values to match your data dictionary values
- But it also includes any planned coding, such as reverse coding a variable
- As well as recoding any implicit values to their explicit values

:::

## Construct additional variables

![](images/checklist13.PNG){fig-align="center"}

:::{.notes}

- This is not the time to construct analysis-specific variables. This is the time to create or calculate variables that should always be a part of the core study dataset.

- This could be things like grouping variables (treatment, cohort, site)
- It could be time component variables (year, wave)
- It could be additional unique identifiers that you need to add for linking purposes (like adding a school ID to a teacher file)
- Or it could be measure composite or summary scores that you want included in the core dataset
- Any other variables you want added to the core sharing dataset

- Some of these variables will be calculated, others may be merged in from other sources

:::

## Add missing values

![](images/checklist14.PNG){fig-align="center"}


## Data validation

::: columns

::: {.column width="50%"}

![](images/checklist15-1.PNG)

:::

::: {.column width="50%"}

::: {layout-nrow=2}

![](images/checklist15-2.PNG)

![](images/checklist15-3.PNG)

:::

:::
:::

:::{.notes}

You should absolutely be checking your transformations throughout your cleaning process, but then, before exporting your data you should do one final review to make sure you haven't missed anything.  

Here are several examples where various researchers did not have data validation as part of their data cleaning process and found out much later on that their data contained errors. And so we want to try to prevent this scenario by catching any errors now, rather than later.

:::


## Data validation

:::: {.columns}

::: {.column width="60%"}

- Complete
  - Check for missing/duplicate cases
    - Check Ns by groups for completeness
  - Check for missing/too many columns
- Valid and consistent
  - Check for unallowed categories/values out of range
    - Check ranges by groups
  - Check for invalid, non-unique, or missing study IDs
  - Check for incorrect variable types/formats
  - Check missing value patterns

:::
 
::: {.column width="40%"}

- Accurate
  - Agreement across variables
- De-identified
  - All direct identifiers are removed
  - All indirect identifiers managed as needed
- Interpretable
  - Variables correctly named

:::
:::

:::{.notes}

Use your data quality indicator list as a guide when doing your final data review

:::

## Data validation

:::: {.columns}

::: {.column width="60%"}

1. Documentation errors
    - Fix in documentation
2. Data cleaning errors
    - Fix in your cleaning process
3. Data entry/export process errors
    - Fix at the source and export new raw file
4. True values that are inaccurate, uninterpretable, or outside of a valid range
    - Leave the data as is (document the issue)
    - Recode those values to designated error code
    - Create data quality indicators
    - Choose one source of truth for inconsistent values
    - Use logical/deductive editing
    
:::
 
::: {.column width="40%"}

![](images/checklist15-4.PNG){fig-align="center"}

:::
:::

:::{.notes}

What's most important is that you document your decisions for future users

:::

## Export data

<br>

![](images/checklist16.jpg){fig-align="center"}

## Export data

When you export your files, it's important to name them consistently and clearly.

- Follow rules similar to our variable naming rules
  - Machine-readable (except now `-` is allowed)
  - Human-readable
    - A user should be able to understand what the file contains without opening it

<br>

Which gives you a better idea of what is in the file? 🤔

  - "Project X Full Data.csv"
  - "projectx_wave1_stu_svy_clean.csv"


## Creating a data cleaning plan

![](images/data_cleaning_plan.PNG){fig-align="center"}


:::{.notes}

Ultimately what I like to do in a cleaning process is pull out my checklist, import and review my data, and then plan out the steps that are needed to clean my specific dataset

:::

## BREAK!

![](https://media1.tenor.com/m/XFNnJtXYH_gAAAAC/dog-wipe-face.gif){fig-align="center" width=80%}

## BREAK!

```{r}
#| echo: false
#| cache: false
countdown(minutes = 15, font_size = "10em", style = "position: relative; width: min-content;")

```
