# Cleaning in R {.background-secondary}

:::{.notes}

- Before we jump
- that this material is not about learning a comprehensive set of data cleaning functions that you can use to solve every data cleaning issue you may encounter
- There's no way to cover that much material, and on top of that, for every data cleaning issue you encounter in your data, there are probably 10 different ways to solve that issue. 
- Instead this section is more about learning a standardized way of thinking through a data cleaning process and pulling from the available R functions, some of which we will learn today, to work through that process. 

:::

## Objects

<br>

- If you want to save the output from something you do in R, you need to save it to an object that lives in your environment
  - Objects should follow the same naming rules we discussed earlier
- If you simply want to view an output, you don't need to save it into an object

<br>

::: columns
::: {.column width="50%"}

```{r echo=TRUE}

age <- c(12, 10, 8)

age_new <- age + 1

```

:::

::: {.column width="50%"}

```{r echo=TRUE}

mean(age_new)

```

:::
:::


:::{.notes}

Foundational

:::

## Objects

<br>

::: columns
::: {.column width="50%"}

Data Frame (Tibble)

- Two dimensional structure

```{r}

df <- data.frame(id = c(10, 20),
                 age = c(12, 8))

df

```

:::

::: {.column width="50%"}

Vector

- Consists of one or more elements all of the same type

```{r}

id <- c(10, 20)

id

```

- Common vector types (class)
  - character, numeric, date, logical
  
:::
:::

## RStudio Pane Layout


![Image from [RStudio User Guide](https://docs.posit.co/ide/user/ide/guide/ui/ui-panes.html)](images/r_panes.PNG)

## Script Files

::: columns
::: {.column width="50%"}

R Script File

![](images/script.PNG){fig-align="center"}

:::

::: {.column width="50%"}

R Markdown File

![](images/rmdfile.PNG){fig-align="center"}

:::
:::


## Functions

::: columns
::: {.column width="60%"}

- Anatomy of a function
    - **function_name(argument1, argument2, argument3, ...)**
      - the first argument is usually an object
    - You can view arguments by typing `?functionname` in your console

- Arguments usually have defaults
    - For example `mean(x, trim, na.rm)`
      - trim = 0
      - na.rm = FALSE

- R has many built in (base) functions

:::

::: {.column width="40%"}

<br>
<br>
<br>

|Function | Task |
|-----|----------|
| View() | View object |
| str() |Display internal structure of an object |
|c() |Combine elements| 
| class() |Check the class/type of an object |

:::
:::

:::{.notes}

If you like the defaults, do nothing. You don't have to type out the arguments. If you want to change the default, you need to type out the arguments.

:::

## Packages

- We can also use functions that live in packages that we can install onto our computer

- Once installed, there are two ways to call packages
  - You may see both methods used in these slides

<br>

::: columns
::: {.column width="50%"}

Using `library()`

```{r echo=TRUE, eval=FALSE}

library(dplyr)

select(df, var1, var2) 

```
:::

::: {.column width="50%"}

Using Namespacing `package::function()`

```{r echo=TRUE, eval=FALSE}

# library(dplyr) not needed

dplyr::select(df, var1, var2) 

```
:::
:::

:::{.notes}

Foundational

:::


## Pipes

-   2014+ magrittr pipe `%>%`

-   2021+ (R $\geq$ 4.1.0) native R pipe `|>`

. . .

Isabella Velásquez's blog post [*Understanding the native R pipe* \|\>](https://ivelasq.rbind.io/blog/understanding-the-r-pipe/) (2022)

<br>

. . .

::: columns
::: {.column width="50%"}
```{r echo=TRUE, eval=FALSE}

sch_data <- select(sch_data, id, 
                    test_score)

sch_data <- filter(sch_data, 
                    test_score > 300)

```
:::

::: {.column width="50%"}
```{r}
#| echo: true
#| eval: false

sch_data <- sch_data |>
  select(id, test_score) |>
  filter(test_score > 300)

```
:::
:::

. . .

<br>

To turn on the native pipe:

`Tools` → `Global Options` → `Code` → `Editing` → `Use Native Pipe Operator`

## Operators

::: columns
::: {.column width="50%"}

Comparison operators

- `==` equal to
- `!=` not equal to
- `<` less than
- `>` greater than
- `%in%` value is present within

```{r eval=FALSE}

df |>
  filter(city %in% c("boston","philly"))

```

:::

::: {.column width="50%"}

Assignment operators

- `<-` Assign values to an object
- `=` Assign value to an argument

```{r eval = FALSE}

df <- df |>
  mutate(year = "2024")

```

:::
:::

## Scenario

#### Take 5 minutes to open and look at our data file.

1. Log in to Posit Cloud and navigate to our project
    - [**https://posit.cloud/content/7872027**](https://posit.cloud/content/7872027)
2. Open the `data` folder and open "sample_tch_svy_raw.xlsx"
    - Notice that the "labels" tab has some basic information about the variables

![](images/sample-data.PNG){fig-align="center"}

```{r}
#| echo: false
#| cache: false
countdown(minutes = 5, font_size = "2em")

```


## Import our data

<br>

Common data importing functions

- `read_csv()`, `read_delim()` from the `readr` package

- `read_excel()` from the `readxl` package

- `read_sav()`, `read_sas()`, `read_dta()` from the `haven` package

- Learn more about importing multiple files at once [here](https://github.com/Cghlewis/data-wrangling-functions/wiki/Import-Files)

<br>

. . .

**Which function should we use to read in our sample data?**🤔

## Import our file

::: columns
 
::: {.column width="50%"}

- `read_excel()` has several arguments. 
  - path
    - Name of the file, plus folder names as needed
    - "data/w1_stu_obs_raw.xlsx"
  - sheet = NULL
  - col_names = TRUE
  - na = ""
  - skip = 0
- Type `?read_excel()` in your console to see more arguments

:::

::: {.column width="50%"}

![](images/read_excel.PNG){fig-align="center"}

:::
:::


## [Exercise]{style="color:#ccd64d"}{.background-secondary}

<br>

### Take 3 minutes to import the data.

<br>

1. Open "exercises.Rmd" in our Posit Cloud project.
2. First run the "Library packages" chunk using the green arrow.
3. Then navigate to Exercise 1. 
4. Update the first code chunk and run the code to read in the data.
5. Run the second code chunk to view the data.

If you get stuck, you can open "solutions.Rmd"

```{r}
#| echo: false
#| cache: false
countdown(minutes = 3, font_size = "2em")

```

:::{.notes}

Everything in this file will build off of each other so you will need to keep up with the exercises along the way.

:::

## Review our data

<br>

::: columns
::: {.column width="50%"}

- How many rows?
  - In this hypothetical situation, we assume we are not missing any cases
  - However, there may be duplicates
- How many columns?
  - Compare to our data dictionary
- What are the variable values and ranges? Variable types?
  - Compare to our data dictionary
- How much missing data do we have?

:::

::: {.column width="50%"}

There are several functions we can use to explore data

- `dplyr::glimpse()`
- `skimr::skim()`
- `base::summary()`
- **`summarytools::dfSummary()`**
- `Hmisc::describe()`

:::
:::

## [Exercise]{style="color:#ccd64d"}{.background-secondary}

<br>

### Take 5 minutes to review our data.

1. Navigate to Exercise 2.
2. Run the code. 
    - Write down any potential issues you see in the data based on our data quality criteria.
3. Open "sample_tch_svy_data-dictionary.xlsx" in the `docs` folder. 
    - What issues do you see when you compare the data to our data dictionary?
4. Open "sample_tch_svy_cleaning-plan.txt" in the `docs` folder. 
    - How does it compare to the issues you wrote down?

```{r}
#| echo: false
#| cache: false
countdown(minutes = 5, font_size = "2em")

```

:::{.notes}

So we are going to follow this data cleaning plan for the rest of this section

:::


## Adjust the sample

<br>

There are two key functions we can use to both identify and remove duplicates in our data

<br>

  - `janitor::get_dupes()`
    - Tells you which rows contain duplicate unique identifiers, if any

<br>

  - `dplyr::distinct()`
    - Keeps the first instance of a duplicate unique identifier

      
:::{.notes}

So the next step in our checklist is to adjust the sample
And we found some duplicates in our sample

:::
  
## Adjust the sample

::: panel-tabset
### Check for duplicates

```{r}
#| echo: true
#| eval: false

df |>
  get_dupes(id_vars)

```

- Replace `id_vars` with your unique identifier
- If you have more than one variable that uniquely identifies rows, use `c(first_name, last_name)`

### Remove duplicates

```{r}
#| echo: true
#| eval: false
 
df |>
  distinct(id_vars, 
           .keep_all = TRUE)

```
- Replace `id_vars` with your unique identifier/s
- Always add the argument *.keep_all = TRUE*
- But remember, this always keeps the first instance of your duplicate
  - This may not always be want you want

### Remove duplicates

```{r}
#| echo: true
#| eval: false
 
df |>
  arrange(date) |>
  distinct(id_vars, 
           .keep_all = TRUE)

```
- Consider arranging your data first, before removing duplicates
- Replace `date` with any variable that you want to arrange your data by
  - The default is to sort values in ascending order
    - If you want descending order `arrange(desc(date))`

:::



## [Exercise]{style="color:#ccd64d"}{.background-secondary}

<br>

### Take 5 minutes to check for and remove duplicates.

1. Navigate to Exercise 3.
2. Run the code to check for duplicates. 
    - Which `tch_id` is duplicated?
3. Run the code to remove our duplicates. 
    - Our documented rule is that if both surveys are complete, keep the most recently completed row.
4. Run a check to make sure duplicates are removed.
5. Run the code to confirm that we kept the most recent submission of the duplicate survey ("2024-04-02").

```{r}
#| echo: false
#| cache: false
countdown(minutes = 5, font_size = "2em")

```

## De-identify data

<br>

The functions used here will depend on what is required.

<br>

Examples of functions you might use:

- `dplyr::select()` to drop variables
- `dplyr::case_when()` or `dplyr::recode()` to collapse categories/recode values
- `dplyr::*_join()` to merge in study unique IDs
- `stringr::str_remove_all()` or `stringr::str_replace_all()` to redact character values


For our sample data we are going to use the following.

1. `dplyr::case_when()` to recategorize names into our unique study ID values and
2. `dplyr::select()` to drop identifying variables

## De-identify data

::: panel-tabset

### Recategorize values

```{r}
#| echo: true
#| eval: false

df |>
  dplyr::mutate(new_var_name =
                  case_when(
                    var_name == old_value1 ~ new_value1,
                    var_name == old_value2 ~ new_value2
                  ))

```

- To learn more about setting *default* values for `case_when()`, type `?case_when` in your console
- Note that there is a new function, `case_match()`, that is worth looking in to. It reduces repetition in the syntax.

### Recategorize values

::: columns
::: {.column width="50%"}


My data frame that I want to de-identify

```{r}
#| echo: false

library(tidyverse)

df <- data.frame(fname = c("emma", "brandon"),
                 lname = c("royce", "figueroa"),
                 score1 = c(22, 40),
                 score2 = c(50, 61))

df

```

:::

::: {.column width="50%"}

```{r}

df |>
  mutate(id = 
           case_when(
             fname == "emma" ~ 300,
             fname == "brandon" ~ 301
           ))


```

 
:::
:::

### Select variables

::: columns
::: {.column width="50%"}


To select variables of interest

```{r}
#| echo: true
#| eval: false

df |>
  select(score1, score2, id)

```

```{r}
#| echo: true
#| eval: false

df |>
  select(score1:id)

```

```{r}
#| echo: true
#| eval: false

df |>
  select(starts_with("score"), id)

```

:::

::: {.column width="50%"}

To drop variables I add **`-`**

```{r}
#| echo: true
#| eval: false
 
df |>
  select(-fname:lname)

```

```{r}
#| echo: true
#| eval: false
 
df |>
  select(-c(fname, lname))

```

```{r}
#| echo: true
#| eval: false
 
df |>
  select(-contains("name"))

```

:::
:::

:::

## [Exercise]{style="color:#ccd64d"}{.background-secondary}

<br>

### Take 5 minutes to de-identify our data

1. Navigate to Exercise 4.
2. Edit and run the code to create a `sch_id` variable.
    - Review the new variable after it is created.
3. Edit and run the code to drop our identifying variables.
    - Review to make sure those variables were removed.

```{r}
#| echo: false
#| cache: false
countdown(minutes = 5, font_size = "2em")

```

## Rename variables

Two functions we can use to rename variables

- `dplyr::rename()`
    - Commonly used to rename just a few variables
- `purrr::set_names()`
    - Used to rename all of our variables
    - Variables in your dataset must be ordered in the same way as in `set_names()`

<br>

::: columns
::: {.column width="50%"}

Rename just a few variables

```{r}
#| echo: true
#| eval: false

df |>
  rename(new_name = old_name)

```

:::

::: {.column width="50%"}

Rename all variables

```{r}
#| echo: true
#| eval: false
 
df |>
  set_names(c("name1", "name2", "name3"))

```

:::
:::

## [Exercise]{style="color:#ccd64d"}{.background-secondary}

<br>

### Take 3 minutes to rename variables

1. Navigate to Exercise 5.
2. Review the current variable names.
3. Edit the code to rename variables according to our data dictionary.
4. Check variable names again to make sure the renaming worked.

```{r}
#| echo: false
#| cache: false
countdown(minutes = 3, font_size = "2em")

```


## Normalize variables

There are several functions that can help us remove unexpected values from our variables. 

Some examples of those include:

- `stringr::str_remove_all()`
- `stringr::str_replace_all()`
- `readr::parse_number()`

<br>

Say this is our data

```{r echo=FALSE}

library(stringr)
library(readr)

df <- tibble::tribble(~id, ~income,
                      1, "$32,000",
                      2, "120000",
                      3, "$45,000")

df

```


## Normalize variables

<br>

::: columns
::: {.column width="50%"}

Remove character values with `stringr::str_remove_all()`

```{r}
#| echo: true

df |>
  dplyr::mutate(income = 
                  str_remove_all(income, "\\$|,"))

```

- Notice that our variable is still character type

:::

::: {.column width="50%"}

Remove character values with `readr::parse_number()`

```{r}
#| echo: true
 
df |>
  dplyr::mutate(income = 
                  parse_number(income))

```

- Notice that `parse_number()` converts our variable to numeric type

:::
:::

## [Exercise]{style="color:#ccd64d"}{.background-secondary}

<br>

### Take 3 minutes to normalize our `tch_yrs` variable

1. Navigate to Exercise 6.
2. Review the current values for `tch_yrs`.
3. Edit the code to remove all non-numeric values from this variable.
4. Review the new values in `tch_yrs`.

```{r}
#| echo: false
#| cache: false
countdown(minutes = 3, font_size = "2em")

```

## Update variable type

Depending on what is needed, there are several functions we can use to change variable types.

<br>

Some examples include:

- `as.numeric()`
- `as.character()`
- `as.Date()`
- Several functions in the `lubridate` package to assist with converting dates
- `janitor::excel_numeric_to_date()` can be very helpful at times

## Update variable type

It's important to normalize variables **before** converting types (especially when converting from character to numeric)

<br>

::: columns
::: {.column width="50%"}

Our data without normalizing

```{r}
#| echo: true

df

```

:::

::: {.column width="50%"}

When we try to convert `income` to numeric....

```{r}
#| echo: true
#| warning: true
 
df |>
  dplyr::mutate(income = 
                  as.numeric(income))

```

We end up converting several values to `NA` (notice our warning)

:::
:::

## [Exercise]{style="color:#ccd64d"}{.background-secondary}

<br>

### Take 3 minutes to convert `tch_yrs` to numeric

1. Navigate to Exercise 7.
2. Review the current variable type for `tch_yrs`.
3. Edit the code and convert the variable type to numeric.
4. Review the new variable type for `tch_yrs`.

```{r}
#| echo: false
#| cache: false
countdown(minutes = 3, font_size = "2em")

```

## Recode variables

Common functions for recoding values are

- `dplyr::case_when()`
- `dplyr::recode()`
- `tidyr::replace_na()`

<br>

::: columns
::: {.column width="50%"}

```{r eval=FALSE}

df |>
  mutate(newvar = 
           recode(oldvar,
                  oldvalue = newvalue))

```

- If the oldvalue is numeric, it requires ticks around the number, e.g., \`5\`
- If either the oldvalue or newvalue is character use quotation marks, e.g., "yes", 

:::

::: {.column width="50%"}

```{r eval=FALSE}

df |> 
  mutate(newvar = 
           replace_na(oldvar, 
                      replace = newvalue))

```

:::
:::

## Recode variables

<br>

`dplyr::across()` allows you to apply the same transformation across multiple columns  

- This can be used in `case_when()`, `recode()`, or `replace_na()`

<br>

```{r eval=FALSE}

df |>
  mutate(across(var1:var3, 
                  ~ replace_na(., replace = 0)))

```

This will save over existing variables.  

- If you don't want to save over the existing variables, you can add the argument *.names* which lives in the `dplyr::across()` function. This creates new variables with new names.

## [Exercise]{style="color:#ccd64d"}{.background-secondary}

<br>

### Take 5 minutes to recode variables

1. Navigate to Exercise 8.
2. Update the code to recode the blank values for the `grade` variables.  
    - Check to see if the recoding worked.
3. Update the code to recode the `mathanx` variable.  
    - Check to see that the recoding worked.

```{r}
#| echo: false
#| cache: false
countdown(minutes = 5, font_size = "2em")

```

## Construct new variables

- The most important function for constructing new variables is `dplyr::mutate()`

- From there, other functions may be required. For today, we are going to use `rowSums()` which allows us to create sum scores for each row

<br>

::: columns
::: {.column width="50%"}

The default is to **not** calculate a sum if there are any `NA` values

```{r eval=FALSE}

df |>
  mutate(newvar = rowSums(
    across(var1:var3)))

```

:::

::: {.column width="50%"}

If you want to calculate a sum even if there are NA values, add *na.rm = TRUE*

```{r eval=FALSE}

df |>
  mutate(newvar = rowSums(
    across(var1:var3), na.rm = TRUE))

```

:::
:::

## [Exercise]{style="color:#ccd64d"}{.background-secondary}

<br>

### Take 3 minutes to construct `gad_sum`

1. Navigate to Exercise 9.
2. Update the code to calculate `gad_sum`
3. Review summary information for the new variable.

```{r}
#| echo: false
#| cache: false
countdown(minutes = 3, font_size = "2em")

```

## Validate data

::: columns
::: {.column width="60%"}

- Create tables of information
  - `dplyr::count()`, `janitor::tabyl()`
- Create graphs
  - `ggplot2`
- Calculate summary statistics
  - All of the functions from "Review the data" section
- Create codebooks
  - `codebookr`, `memisc`, `sjPlot`
- Create tests that pass/fail based on a set of criteria
  - **`pointblank`**, `validate`, `assertr`, `dataquieR`


:::

::: {.column width="40%"}

![](images/codebook.PNG){fig-align="center"}

:::
:::

:::{.notes}

- There are many ways to validate data based on data quality criteria

- Codebooks, which can be exported to things like word or text documents, provide univariate summary statistics about your data. It just gives you a nice easy to read summary of what is happening in your data.

- You most likely want to do a combination of these things in your validation process

:::
## Validate data

::: panel-tabset

### Create our validation criteria

Here we are using the [pointblank](https://rstudio.github.io/pointblank/reference/index.html) package to develop some validation tests

<br>

```{r echo=FALSE}

library(pointblank)

df <- tibble::tribble(~stu_id, ~age, ~test_score,
                      300, 12, 400,
                      301, 13, 450,
                      303, 12, 999)
```


```{r eval=FALSE}

create_agent(df) |>
  rows_distinct(columns = vars(stu_id)) |>
  col_vals_not_null(columns = vars(stu_id)) |>
  col_vals_between(columns = vars(stu_id), left = 300, right = 500, na_pass = FALSE) |>
  col_is_numeric(columns = vars(age, test_score)) |>
  col_vals_between(columns = vars(test_score), left = 0, right = 500, na_pass = TRUE) |>
  interrogate()

```

### Review the report

![](images/pointblank.PNG){fig-align="center"}

:::

## [Exercise]{style="color:#ccd64d"}{.background-secondary}

<br>

### Take 5 minutes to validate our data

1. Navigate to Exercise 10.
2. Run the validation code.
    - Do all of our tests pass?
3. Update the code with one more validation criteria. Run the code again.
    - Do all of our tests still pass?

```{r}
#| echo: false
#| cache: false
countdown(minutes = 5, font_size = "2em")

```

## Export data

Similar to importing data, we have many options for exporting our data depending on the format we want to export to.

- `openxlsx::write.xlsx()`
- `haven::write_sav()`, `haven::write_dta()`, `haven::write_sas()`
- `readr::write_csv()`
    - x 
      - The object we are exporting
    - file
      - The name of the new file plus any folders where you want the file to live
    - na = "NA"
    
```{r eval=FALSE}

write_csv(df, file = "data/w1_stu_obs_clean.csv", na = "")

```

## [Exercise]{style="color:#ccd64d"}{.background-secondary}

<br>

### Take 2 minutes to export our data

1. Navigate to Exercise 11.
2. Update our code to export the clean data file.
3. Once exported, open the file to confirm it looks as expected.

```{r}
#| echo: false
#| cache: false
countdown(minutes = 2, font_size = "2em")

```

## Coding best practices

::: columns
::: {.column width="60%"}

1. Use a coding template
2. Follow a coding style guide
    - The [tidyverse style guide](https://style.tidyverse.org/syntax.html)
3. Use relative file paths
    - ❌ "C:/Users/Crystal/Desktop/project/data/raw_file.csv"
    - ✔️ "data/raw_file.csv"
4. Write all cleaning steps in code
5. Comment every step in your code
6. Check all of your work throughout
7. If possible, have someone else review your code

:::

::: {.column width="40%"}

![](images/code_template.PNG){fig-align="center"}

:::
:::

:::{.notes}

That will just help ensure that your code is more readable, usable, and reproducible in the future. 

- your chain of processing is lost, and your work is no longer reproducible

You may have noticed that throughout these exercises, that we always performed a check to make sure that the transformation worked as expected

:::

## Versioning

1. Version your code ("sample_tch_svy_cleaning_v01.R")
2. Version your files ("sample_tch_svy_clean_v01.csv")
3. Make notes in a changelog.

![](images/changelog.PNG){fig-align="center"}

