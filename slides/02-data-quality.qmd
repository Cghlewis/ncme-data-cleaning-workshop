# Data Quality Indicators {.background-secondary}

## The Data are Ready

![](images/data-ready.PNG){fig-align="center" width="80%"}

::: {.notes}

Has anyone here ever had someone give them a dataset that they've said is good to go, but then you open the data and it looks something like this? Just a mess.

I feel like this happens to me on a weekly basis.

So today we are going to review a standard set of data quality indicators that we can use to determine if a dataset is really ready to be shared or not.

:::

## 7 Data Quality Indicators

::: columns
::: {.column width="40%"}

<br>

1. Analyzable

2. Interpretable

3. Complete

4. Valid

5. Accurate

6. Consistent

7. De-identified


:::
 
::: {.column width="60%"}

![Taming the Data Beast, by Allison Horst](images/data_beast_allison_horst.jpeg)

:::
:::

## Analyzable

- Data should make a rectangle of rows and columns
  - The first row, and only the first row, is your variable names
  - The remaining data should be made up of values in cells
  - At least one column uniquely defines the rows in the data (e.g., unique identifier)

![](images/quality-analyze1.PNG){fig-align="center"}

::: {.notes}

So first and foremost, data needs to make a rectangle. This rectangle shape is how machines read data.

- short representation of the information contained in a column.


:::

## Analyzable

- Column values are analyzable
  - Information is explicit
  
![](images/quality-analyze2.PNG){fig-align="center" width="70%"}

::: {.notes}

Another rule of analyzable data is that information is explicit, not implicit. This means unless data is actually missing, there should be no blanks in your data. They should be filled with the applicable values.

:::

## Analyzable

<br>

![](images/quality-analyze3.PNG){fig-align="center"}

::: {.notes}

Another example of data that is not explicit is when color coding is used. Here, color coding is used to indicate study treatment groups. However, machines cannot interpret color codes. This information needs to be defined in a variable with values assigned for each group.

:::

## Analyzable

- Only one piece of information is collected per variable

![](images/quality-analyze4.PNG){fig-align="center"}

::: {.notes}

And then last, for data to be analyzable, you should only collect one piece of information per variable. In this example, a rate variable has been included the data where the numerator is the number of incidents and the denominator is the total number of students in the school. But it is difficult to work with combined information. It's much better to separate those pieces of information into their own variables and then you can aggregate information as needed.

:::



## [Exercise]{style="color:#ccd64d"}{.background-secondary}

<br>

What data quality issues do you detect for the "analyzable" indicator?

![](images/example-data.PNG){fig-align="center"}


```{r}
#| echo: false
#| cache: false
countdown(minutes = 1, font_size = "2em")

```

## [Solution]{style="color:#ccd64d"}{.background-secondary}

- Data does not make a rectangle
- Color coding used to convey information
- More than one piece of information in a variable
- Blank values implied to be 0 for `Q4`{style="color:#ccd64d"} variables


![](images/quality-exercise1.PNG){fig-align="center"}

## Interpretable

::: columns
::: {.column width="50%"}


- Variable names should be machine-readable
  - Unique
  - No spaces or special characters except `_`
    - This includes no `.` or `-`
  - Not begin with a number
  - Character limit of 32
  

- Variable names should be human-readable
  - Meaningful (`gender` instead of `Q1`)
  - Consistently formatted (capitalization and delimiters)
  - Consistent order of information
    - `wave_responder_scale#` (`w1_t_mast1`)

:::
 
::: {.column width="50%"}

![In that case, by Allison Horst](images/naming_case.jpg)

:::
:::


::: {.notes}

- First interpretable applies to your variable names

- Even dashes are not allowed because R reads them as minus signs
- While periods are allowed in R, they aren't in other languages like Stata so it's best to avoid them.

- Most statistical programs are case sensitive so if you are inconsistent with things like delimiters and capitalization, it just makes it so much more difficult to work with your data.

:::

## Interpretable

- When publicly sharing data, it is recommended to share data in at least one non-proprietary format (e.g., CSV)
  - But if you would also like to share a copy in a commonly used format such as SPSS, SAS, or Stata, consider adding embedded metadata (i.e., **variable label** and **value labels**)
  
![](images/quality-interpret1.PNG){fig-align="center"}

::: {.notes}

- But interpretable can also apply to other formatting

- Because that can really help with interpretation. Rather than having to flip back and forth to the data dictionary to see what codes mean or what a variable represents, the information lives within the dataset and can be accessed as needed.

:::


## [Exercise]{style="color:#ccd64d"}{.background-secondary}

<br>

What data quality issues do you detect for the "interpretable" indicator?

![](images/example-data.PNG){fig-align="center"}

```{r}
#| echo: false
#| cache: false
countdown(minutes = 1, font_size = "2em")

```

## [Solution]{style="color:#ccd64d"}{.background-secondary}

- Spaces and special characters used in variable names
- Some variable names are unclear
- Inconsistent use of capitalization

![](images/quality-exercise2.PNG){fig-align="center"}

## Complete

- Cases
  - The number of rows in your dataset should total to your sample N
    - No missing cases
    - No duplicate cases (i.e., no unique identifier)
    
- Variables
  - The number of columns in your dataset should total to what you planned to have
    - No missing variables
  - No unexpected missing data
    - If you collected the data, it should exist in the dataset

## Complete

#### Tracking Database

![](images/quality-complete1.PNG){fig-align="center"}

#### Data Dictionary

![](images/quality-complete2.PNG){fig-align="center"}

::: {.notes}

Two documents that can be helpful for verifying if you have complete data are a participant tracking database and a data dictionary.

A participant tracking database is a spreadsheet or database where a project coordinator tracks what is collected in a study for each participant. Depending on your role in the study, you may or may not have access to this type of database. If you do not, you are just going to have to trust that you have been given a dataset that includes the entire sample.

A data dictionary is something you hopefully always have access to though and this should list out exactly what variables exist in a dataset and what those variables represent.

Both of these documents are excellent resources for determining if you have a complete dataset.

:::

## [Exercise]{style="color:#ccd64d"}{.background-secondary}

<br>

What data quality issues do you detect for the "complete" indicator?

![](images/example-data.PNG){fig-align="center"}

```{r}
#| echo: false
#| cache: false
countdown(minutes = 1, font_size = "2em")

```

::: {.notes}

Here we don't have access to a tracking database or a data dictionary but there is still something we can catch in this dataset without those documents.

:::

## [Solution]{style="color:#ccd64d"}{.background-secondary}

- The data contain a duplicate ID (104)

![](images/quality-exercise3.PNG){fig-align="center"}

## Valid

- Variables conform to the planned constraints
  - Planned variable types (e.g., `numeric`, `character`, `date`)
  - Allowable variable values and ranges (e.g., `1-5`)
  - Item-level missingness aligns with variable universe rules and skip patterns
  
![](images/quality-valid1.PNG){fig-align="center"}


## Valid

![](images/quality-valid2.PNG){fig-align="center"}

::: {.notes}

Again, the data dictionary is going to be a really important document in determining if data is valid because the dicionary defines all of the constraints that need to be checked.

:::

## [Exercise]{style="color:#ccd64d"}{.background-secondary}

<br>

What data quality issues do you detect for the "valid" indicator?

![](images/example-data.PNG){fig-align="center"}

```{r}
#| echo: false
#| cache: false
countdown(minutes = 1, font_size = "2em")

```

::: {.notes}

Again we don't have a data dictionary for this example...

:::

## [Solution]{style="color:#ccd64d"}{.background-secondary}

- `AGE/YR`{style="color:#ccd64d"} does not adhere to our planned variable type
- Values in `Score`{style="color:#ccd64d"} fall out of our expected range

![](images/quality-exercise4.PNG){fig-align="center"}


## Accurate

- Information should be accurate based on any implicit knowledge you have
  - For instance, maybe you know a student is in 2nd grade because you've interacted with that student, but their grade level is shown as 5th in the data

- Accurate within and across sources
  - A date of birth collected from school records should match the date of birth provided by the student
  - If a student is in 2nd grade, they should be associated with a second grade teacher
  
::: {.notes}

So accuracy can be a tough thing to judge, but depending on your level of involvement in the study, you may have some implicit knowledge you can use to judge accuracy.

:::
  
## [Exercise]{style="color:#ccd64d"}{.background-secondary}

<br>

What data quality issues do you detect for the "accurate" indicator?

![](images/example-data.PNG){fig-align="center"}

```{r}
#| echo: false
#| cache: false
countdown(minutes = 1, font_size = "2em")

```

::: {.notes}

So in this case we don't have any implicit knowledge, but by comparing pieces of information within the dataset, what data quality issues do you see for the accurate indicator here?

:::

## [Solution]{style="color:#ccd64d"}{.background-secondary}

- ID 105 has conflicting information for `TEACHING LEVEL`{style="color:#ccd64d"} and `SCHOOL`{style="color:#ccd64d"}

![](images/quality-exercise5.PNG){fig-align="center"}

## Consistent

- Variable values are consistently measured, formatted, or categorized within a column

- Variables are consistently measured across collections of the same form

![](images/quality-consistent1.PNG){fig-align="center"}

::: {.notes}

And the reason that this consistency matters is that a computer doesn't know that three different spellings of yes are all still yes. It will think these are 3 different things.

So if you collect an item in the fall and then you collect that same item in the spring, you want to make sure that item is coded and formatted in the same way. This allows you to more easily compare and combine information.

:::


## [Exercise]{style="color:#ccd64d"}{.background-secondary}

<br>

What data quality issues do you detect for the "consistent" indicator?

![](images/example-data.PNG){fig-align="center"}

```{r}
#| echo: false
#| cache: false
countdown(minutes = 1, font_size = "2em")

```

## [Solution]{style="color:#ccd64d"}{.background-secondary}

- Values for `GENDER`{style="color:#ccd64d"} are not consistently categorized

![](images/quality-exercise6.PNG){fig-align="center"}

## De-identified

![](images/quality-identify1.PNG){fig-align="center"}

::: {.notes}

In the world of education research we are often working with human subjects and we often promise those subjects that their identifying information will remain private

Direct identifiers are unique to an individual and can be used alone to identify a participant. 

Indirect identifiers however are not necessarily unique to a particular individual, but if combined with other information they could be used to identify a participant.

  - age + gender + education level
  - 50 + female + PhD
  - itâ€™s possible that someone could use that information to identify someone in a dataset

:::

## De-identified

- Direct identifiers are removed


![](images/quality-identify2.PNG){fig-align="center"}

## De-identified

- Open-ended questions
  - These variables may contain information that can directly or indirectly identify individuals
- Outliers
  - If someone has extreme values for a variable, it may be easier to identify that individual
- Small cell sizes
  - [NCES Standard 4-2-10](https://nces.ed.gov/pubsearch/pubsinfo.asp?pubid=2003601), suggests that all categories have at least 3 cases to minimize risk
- Combinations of variables, or crosstabs, can also create small cell-sizes
  - race + gender + grade level

<br>

ðŸš¨ Consider this in the context of risk

- Math assessment may be low risk while a survey on substance use is higher risk

::: {.notes}

But there is more you need to check for.

You also need to consider all of this in the context of risk. So if you are collecting information that is fairly innocuous (like maybe it's a math assessment), the risk of harm if your re-identified is pretty low. If you are collecting information like on substance use, the risk is higher because that information could impact your career, relationships, and so forth. 
:::

## [Exercise]{style="color:#ccd64d"}{.background-secondary}

<br>

What data quality issues do you detect for the "de-identified" indicator?

![](images/example-data.PNG){fig-align="center"}

```{r}
#| echo: false
#| cache: false
countdown(minutes = 1, font_size = "2em")

```

::: {.notes}

This is a very small dataset so don't worry about indirect identifiers right now. Focus more on direct identifiers

:::

## [Solution]{style="color:#ccd64d"}{.background-secondary}

- Replace School Name with an unique ID
- Review outliers and combination of demographics to see if other alterations are necessary

![](images/quality-exercise7.PNG){fig-align="center"}


## Biggest Advice

The number one way to reduce data errors is to make a plan before you collect data

> Correct data at the source

<br>

. . .

- Plan the variables you want to collect

. . .

- Build your data collection/entry tools in a way that follows your plan

. . .

- Test your data tools before collecting/entering data

. . .

- Check your data often during data collection/entry

::: {.notes}

So before we move on to how to our data cleaning checklist, I want to point out one really important thing. And that is, if you are collecting your own original data

Doing this ensures not only that you have much less data cleaning to do in the end, but it also prevents you from potentially losing data or having to recollect bad data. So it's 100% worth the effort to spend time planning for quality data collection in the beginning if you can.

But of course, we are not always in charge of data collection and we just have to deal with the data we are given and so are going to talk about this in the next sections.

:::
