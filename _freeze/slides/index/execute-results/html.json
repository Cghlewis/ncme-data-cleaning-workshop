{
  "hash": "42a99c7273581baf4b025b42e106623d",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Data Cleaning for Data Sharing<br> Using R\"\nauthor: \"Crystal Lewis // April 11, 2024<br>NCME Annual Meeting\"\nfooter: \"Data Cleaning for Data Sharing // [Cghlewis.github.io/ncme-data-cleaning-workshop/](https://Cghlewis.github.io/ncme-data-cleaning-workshop/)\"\nlogo: \"images/NCME-AnnualMeeting2024Logo-F.png\"\nformat: \n  revealjs: \n    width: 1600\n    height: 900  \n    theme: slides.scss\n    highlight-style: a11y\n    transition: fade\n    slide-number: true\nexecute:\n  echo: true\n---\n\n::: {.cell}\n\n:::\n\n## Schedule\n\n<br>\n\n\n| Time          | Topic           |\n|---------------|--------------------|\n|8:45 - 9:00  |   Intro/Logistics | \n|9:00 - 9:45 | Fundamentals of Data Organization|\n|9:45 - 10:30 | Standardized Data Cleaning Checklist|\n|10:30 - 10:45 | Break|\n|10:45 - 12:30 | Data Cleaning Functions|\n|12:30 - 12:45 | Documentation for Data Sharing|\n\n  \n## Logistics\n\n**Materials**\n\n[Cghlewis.github.io/ncme-data-cleaning-workshop/](https://Cghlewis.github.io/ncme-data-cleaning-workshop/)\n\n<br>\n\n**Exercises**\n\nLogin to Posit Cloud workspace: [**https://posit.cloud/content/7872027**](https://posit.cloud/content/7872027).\n\n. . .\n\n<br>\n\nIf Posit Cloud doesn't work, download materials locally:\n\n::: {.cell}\n\n```{.r .cell-code}\nusethis::use_course(\n    \"https://github.com/Cghlewis/ncme-data-cleaning-workshop/raw/main/exercises/exercises.zip\",\n    destdir = \"___\")\n```\n:::\n\n. . .\n\n<br>\n\nFeel free to interrupt me with questions/comments at any time ✋.\n\n<br>\n\nGet up and move around as much as you need to 🚶.\n  \n::: {.notes}\n- All materials for the workshop can be found at this website. \n  - Link also lives at the bottom of these slides\n\n- Hands on exercises in R in the second half of this workshop \n  - Posit Cloud trouble shoot\n  - If you have any trouble logging into Posit Cloud\n\n- If Posit Cloud is a total failure, you should also be able to download the materials \n\n- And then I really hope that today will be a very relaxed environment.\n\n:::\n\n## About the Speaker\n\n::: columns\n::: {.column width=\"50%\"}\n\n- Independent Research Data Management Consultant\n   - [cghlewis.com](https://cghlewis.com/)\n- Previously data manager for the Missouri Prevention Science Institute\n- Co-organizer for R-Ladies St. Louis\n  - [meetup.com/rladies-st-louis](https://www.meetup.com/rladies-st-louis/)\n- Co-organizer for the POWER Data Management in Education Research Hub\n  - [https://osf.io/ap3tk/](https://osf.io/ap3tk/)\n- Author *Data Management in Large-Scale Education Research*\n  - [datamgmtinedresearch.com](https://datamgmtinedresearch.com/)\n\n:::\n \n::: {.column width=\"50%\"}\n![](images/book-cover.jpg){fig-align=\"center\" width=60%}\n\n:::\n:::\n\n::: {.notes}\n- Independent research data management consultant\n  - This means I work for myself. \n\n- Prior to this I worked for the MPSI for 8 years \n\n- I'm also a co-organization for two organizations. \n  - whose mission it is to promote gender diversity in the R community. \n  - We organize monthly meetups\n\n- I also organize the POWER Data Management in Education Research Hub.\n  - Our smaller hub is particularly focused on sharing knowledge around data management issues in education research.\n\n- And then probably the most noteworthy thing about me right now is that I recently finished writing this book\n\n:::\n\n## Introductions\n\n::: columns\n::: {.column width=\"40%\"}\n\n- Your name\n- Your affiliation\n- Your role\n- Your data cleaning experience\n- Your experience with R\n\n:::\n \n::: {.column width=\"60%\"}\n![Image from [Unsplash](https://unsplash.com/photos/brown-and-black-short-coated-small-dog-with-white-long-coat-small-dog-on-gray-concrete-NIKl5WwL-RE)](images/greeting.jpg){fig-align=\"center\"}\n:::\n:::\n\n\n## 3 Phases of Data\n\n![](images/phases.jpg){fig-align=\"center\"}\n\n::: {.notes}\n\n- So, before we begin, I want to clarify what we will be talking about today. So in terms of data, there are typically 3 phases.\n\n- First, there is raw data. And I am defining raw data as data that comes directly from a source.     - That source could be original data \n    - What makes it raw, no transformations\n    - You simply downloaded \n    - And the thing about this raw data is that it usually is messy AND it usually (in the world of education research) contains some identifying information. And we often can't share this outside of our research team.\n\n- Next, we have the clean data. And this is the data that we will be talking about today. \n   - This is the data we typically share \n   - This data is still in its true, raw form, but has been de-identified and minimally altered to allow the data to be correctly interpreted. \n   - entire study sample (no outliers have been removed), all missing data is still labelled as missing (no imputation is done), and no analysis-specific variables are calculated. \n\n- Last, we have all of these analytic datasets. \n  - These are datasets that are created from the general clean dataset and contain further manipulations that are done for a specific analysis\n  - These datasets will typically also be publicly shared in a repository\n  - But these datasets are analysis specific and are not going to be part of the data cleaning process we are discussing today.\n\n:::\n\n## A Sampling of Open Datasets\n\n::: {.r-stack}\n\n\n![](images/publicdata5.PNG){.fragment}\n\n\n![](images/publicdata2.PNG){.fragment}\n\n\n![](images/publicdata1-1.PNG){.fragment}\n\n\n![](images/publicdata6.PNG){.fragment}\n\n\n![](images/publicdata4.PNG){.fragment}\n\n\n:::\n\n::: {.notes}\n\nSo in preparation for this workshop, I went through several public repositories and found a sampling of shared datasets. Let me show you some of them.\n\nWhat do you notice when you look at these different datasets?\n\nThere is no real consistency in how data is structured, variables are named, or how information is coded. And this is a problem because it makes reuse of this data very difficult.\n\nData don't necessarily have to be identically formatted. Different variable naming conventions can be used, different coding schemes can be used. But there are several data quality standards that all data should adhere to in order to allow data to be interpretable and usable, and that is what we are going to talk about today.\n\n:::\n\n## Learning Objectives\n\n::: incremental\n\n1.  Understand how to assess a data set for 7 data quality indicators\n\n<br>\n\n2.  Be able to review a data set and apply a list of standardized data cleaning steps as needed\n\n<br>\n\n3.  Feel comfortable using R code to clean a data set using our standardized steps\n\n<br>\n\n4.  Understand types of documentation that should be shared alongside data\n\n:::\n\n\n# Data Quality Indicators {.background-secondary}\n\n## The Data are Ready\n\n![](images/data-ready.PNG){fig-align=\"center\" width=\"80%\"}\n\n::: {.notes}\n\nHas anyone here ever had someone give them a dataset that they've said is good to go, but then you open the data and it looks something like this? Just a mess.\n\nI feel like this happens to me on a weekly basis.\n\nSo today we are going to review a standard set of data quality indicators that we can use to determine if a dataset is really ready to be shared or not.\n\n:::\n\n## 7 Data Quality Indicators\n\n::: columns\n::: {.column width=\"40%\"}\n\n<br>\n\n1. Analyzable\n\n2. Interpretable\n\n3. Complete\n\n4. Valid\n\n5. Accurate\n\n6. Consistent\n\n7. De-identified\n\n\n:::\n \n::: {.column width=\"60%\"}\n\n![Taming the Data Beast, by Allison Horst](images/data_beast_allison_horst.jpeg)\n\n:::\n:::\n\n## Analyzable\n\n- Data should make a rectangle of rows and columns\n  - The first row, and only the first row, is your variable names\n  - The remaining data should be made up of values in cells\n  - At least one column uniquely defines the rows in the data (e.g., unique identifier)\n\n![](images/quality-analyze1.PNG){fig-align=\"center\"}\n\n::: {.notes}\n\nSo first and foremost, data needs to make a rectangle. This rectangle shape is how machines read data.\n\n- short representation of the information contained in a column.\n\n\n:::\n\n## Analyzable\n\n- Column values are analyzable\n  - Information is explicit\n  \n![](images/quality-analyze2.PNG){fig-align=\"center\" width=\"70%\"}\n\n::: {.notes}\n\nAnother rule of analyzable data is that information is explicit, not implicit. This means unless data is actually missing, there should be no blanks in your data. They should be filled with the applicable values.\n\n:::\n\n## Analyzable\n\n<br>\n\n![](images/quality-analyze3.PNG){fig-align=\"center\"}\n\n::: {.notes}\n\nAnother example of data that is not explicit is when color coding is used. Here, color coding is used to indicate study treatment groups. However, machines cannot interpret color codes. This information needs to be defined in a variable with values assigned for each group.\n\n:::\n\n## Analyzable\n\n- Only one piece of information is collected per variable\n\n![](images/quality-analyze4.PNG){fig-align=\"center\"}\n\n::: {.notes}\n\nAnd then last, for data to be analyzable, you should only collect one piece of information per variable. In this example, a rate variable has been included the data where the numerator is the number of incidents and the denominator is the total number of students in the school. But it is difficult to work with combined information. It's much better to separate those pieces of information into their own variables and then you can aggregate information as needed.\n\n:::\n\n\n\n## [Exercise]{style=\"color:#ccd64d\"}{.background-secondary}\n\n<br>\n\nWhat data quality issues do you detect for the **`analyzable`** indicator?\n\n![](images/example-data.PNG){fig-align=\"center\"}\n\n\n::: {.cell}\n::: {.cell-output-display}\n\n```{=html}\n<div class=\"countdown\" id=\"timer_7fdeefd6\" data-update-every=\"1\" tabindex=\"0\" style=\"right:0;bottom:0;--countdown-font-size:2em;\">\n<div class=\"countdown-controls\"><button class=\"countdown-bump-down\">&minus;</button><button class=\"countdown-bump-up\">&plus;</button></div>\n<code class=\"countdown-time\"><span class=\"countdown-digits minutes\">01</span><span class=\"countdown-digits colon\">:</span><span class=\"countdown-digits seconds\">00</span></code>\n</div>\n```\n\n:::\n:::\n\n## [Solution]{style=\"color:#ccd64d\"}{.background-secondary}\n\n- Data does not make a rectangle\n- Color coding used to convey information\n- More than one piece of information in a variable\n- Blank values implied to be 0 for `Q4`{style=\"color:#ccd64d\"} variables\n\n\n![](images/quality-exercise1.PNG){fig-align=\"center\"}\n\n## Interpretable\n\n::: columns\n::: {.column width=\"50%\"}\n\n\n- Variable names should be machine-readable\n  - Unique\n  - No spaces or special characters except `_`\n    - This includes no `.` or `-`\n  - Not begin with a number\n  - Character limit of 32\n  \n\n- Variable names should be human-readable\n  - Meaningful (`gender` instead of `Q1`)\n  - Consistently formatted (capitalization and delimiters)\n  - Consistent order of information\n    - `wave_responder_scale#` (`w1_t_mast1`)\n\n:::\n \n::: {.column width=\"50%\"}\n\n![In that case, by Allison Horst](images/naming_case.jpg)\n\n:::\n:::\n\n\n::: {.notes}\n\n- First interpretable applies to your variable names\n\n- Even dashes are not allowed because R reads them as minus signs\n- While periods are allowed in R, they aren't in other languages like Stata so it's best to avoid them.\n\n- Most statistical programs are case sensitive so if you are inconsistent with things like delimiters and capitalization, it just makes it so much more difficult to work with your data.\n\n:::\n\n## Interpretable\n\n- When publicly sharing data, it is recommended to share data in at least one non-proprietary format (e.g., CSV)\n  - But if you would also like to share a copy in a commonly used format such as SPSS, SAS, or Stata, consider adding embedded metadata (i.e., **variable label** and **value labels**)\n  \n![](images/quality-interpret1.PNG){fig-align=\"center\"}\n\n::: {.notes}\n\n- But interpretable can also apply to other formatting\n\n- Because that can really help with interpretation. Rather than having to flip back and forth to the data dictionary to see what codes mean or what a variable represents, the information lives within the dataset and can be accessed as needed.\n\n:::\n\n\n## [Exercise]{style=\"color:#ccd64d\"}{.background-secondary}\n\n<br>\n\nWhat data quality issues do you detect for the **`interpretable`** indicator?\n\n![](images/example-data.PNG){fig-align=\"center\"}\n\n::: {.cell}\n::: {.cell-output-display}\n\n```{=html}\n<div class=\"countdown\" id=\"timer_0116cae3\" data-update-every=\"1\" tabindex=\"0\" style=\"right:0;bottom:0;--countdown-font-size:2em;\">\n<div class=\"countdown-controls\"><button class=\"countdown-bump-down\">&minus;</button><button class=\"countdown-bump-up\">&plus;</button></div>\n<code class=\"countdown-time\"><span class=\"countdown-digits minutes\">01</span><span class=\"countdown-digits colon\">:</span><span class=\"countdown-digits seconds\">00</span></code>\n</div>\n```\n\n:::\n:::\n\n## [Solution]{style=\"color:#ccd64d\"}{.background-secondary}\n\n- Spaces and special characters used in variable names\n- Some variable names are unclear\n- Inconsistent use of capitalization\n\n![](images/quality-exercise2.PNG){fig-align=\"center\"}\n\n## Complete\n\n- Cases\n  - The number of rows in your dataset should total to your sample N\n    - No missing cases\n    - No duplicate cases (i.e., no unique identifier)\n    \n- Variables\n  - The number of columns in your dataset should total to what you planned to have\n    - No missing variables\n  - No unexpected missing data\n    - If you collected the data, it should exist in the dataset\n\n## Complete\n\n#### Tracking Database\n\n![](images/quality-complete1.PNG){fig-align=\"center\"}\n\n#### Data Dictionary\n\n![](images/quality-complete2.PNG){fig-align=\"center\"}\n\n::: {.notes}\n\nTwo documents that can be helpful for verifying if you have complete data are a participant tracking database and a data dictionary.\n\nA participant tracking database is a spreadsheet or database where a project coordinator tracks what is collected in a study for each participant. Depending on your role in the study, you may or may not have access to this type of database. If you do not, you are just going to have to trust that you have been given a dataset that includes the entire sample.\n\nA data dictionary is something you hopefully always have access to though and this should list out exactly what variables exist in a dataset and what those variables represent.\n\nBoth of these documents are excellent resources for determining if you have a complete dataset.\n\n:::\n\n## [Exercise]{style=\"color:#ccd64d\"}{.background-secondary}\n\n<br>\n\nWhat data quality issues do you detect for the **`complete`** indicator?\n\n![](images/example-data.PNG){fig-align=\"center\"}\n\n::: {.cell}\n::: {.cell-output-display}\n\n```{=html}\n<div class=\"countdown\" id=\"timer_f047d31a\" data-update-every=\"1\" tabindex=\"0\" style=\"right:0;bottom:0;--countdown-font-size:2em;\">\n<div class=\"countdown-controls\"><button class=\"countdown-bump-down\">&minus;</button><button class=\"countdown-bump-up\">&plus;</button></div>\n<code class=\"countdown-time\"><span class=\"countdown-digits minutes\">01</span><span class=\"countdown-digits colon\">:</span><span class=\"countdown-digits seconds\">00</span></code>\n</div>\n```\n\n:::\n:::\n\n::: {.notes}\n\nHere we don't have access to a tracking database or a data dictionary but there is still something we can catch in this dataset without those documents.\n\n:::\n\n## [Solution]{style=\"color:#ccd64d\"}{.background-secondary}\n\n- The data contain a duplicate ID (104)\n\n![](images/quality-exercise3.PNG){fig-align=\"center\"}\n\n## Valid\n\n- Variables conform to the planned constraints\n  - Planned variable types (e.g., `numeric`, `character`, `date`)\n  - Allowable variable values and ranges (e.g., `1-5`)\n  - Item-level missingness aligns with variable universe rules and skip patterns\n  \n![](images/quality-valid1.PNG){fig-align=\"center\"}\n\n\n## Valid\n\n![](images/quality-valid2.PNG){fig-align=\"center\"}\n\n::: {.notes}\n\nAgain, the data dictionary is going to be a really important document in determining if data is valid because the dicionary defines all of the constraints that need to be checked.\n\n:::\n\n## [Exercise]{style=\"color:#ccd64d\"}{.background-secondary}\n\n<br>\n\nWhat data quality issues do you detect for the **`valid`** indicator?\n\n![](images/example-data.PNG){fig-align=\"center\"}\n\n::: {.cell}\n::: {.cell-output-display}\n\n```{=html}\n<div class=\"countdown\" id=\"timer_3f5fff31\" data-update-every=\"1\" tabindex=\"0\" style=\"right:0;bottom:0;--countdown-font-size:2em;\">\n<div class=\"countdown-controls\"><button class=\"countdown-bump-down\">&minus;</button><button class=\"countdown-bump-up\">&plus;</button></div>\n<code class=\"countdown-time\"><span class=\"countdown-digits minutes\">01</span><span class=\"countdown-digits colon\">:</span><span class=\"countdown-digits seconds\">00</span></code>\n</div>\n```\n\n:::\n:::\n\n::: {.notes}\n\nAgain we don't have a data dictionary for this example...\n\n:::\n\n## [Solution]{style=\"color:#ccd64d\"}{.background-secondary}\n\n- `AGE/YR`{style=\"color:#ccd64d\"} does not adhere to our planned variable type\n- Values in `Score`{style=\"color:#ccd64d\"} fall out of our expected range\n\n![](images/quality-exercise4.PNG){fig-align=\"center\"}\n\n\n## Accurate\n\n- Information should be accurate based on any implicit knowledge you have\n  - For instance, maybe you know a student is in 2nd grade because you've interacted with that student, but their grade level is shown as 5th in the data\n\n- Accurate within and across sources\n  - A date of birth collected from school records should match the date of birth provided by the student\n  - If a student is in 2nd grade, they should be associated with a second grade teacher\n  \n::: {.notes}\n\nSo accuracy can be a tough thing to judge, but depending on your level of involvement in the study, you may have some implicit knowledge you can use to judge accuracy.\n\n:::\n  \n## [Exercise]{style=\"color:#ccd64d\"}{.background-secondary}\n\n<br>\n\nWhat data quality issues do you detect for the **`accurate`** indicator?\n\n![](images/example-data.PNG){fig-align=\"center\"}\n\n::: {.cell}\n::: {.cell-output-display}\n\n```{=html}\n<div class=\"countdown\" id=\"timer_788cc826\" data-update-every=\"1\" tabindex=\"0\" style=\"right:0;bottom:0;--countdown-font-size:2em;\">\n<div class=\"countdown-controls\"><button class=\"countdown-bump-down\">&minus;</button><button class=\"countdown-bump-up\">&plus;</button></div>\n<code class=\"countdown-time\"><span class=\"countdown-digits minutes\">01</span><span class=\"countdown-digits colon\">:</span><span class=\"countdown-digits seconds\">00</span></code>\n</div>\n```\n\n:::\n:::\n\n::: {.notes}\n\nSo in this case we don't have any implicit knowledge, but by comparing pieces of information within the dataset, what data quality issues do you see for the accurate indicator here?\n\n:::\n\n## [Solution]{style=\"color:#ccd64d\"}{.background-secondary}\n\n- ID 105 has conflicting information for `TEACHING LEVEL`{style=\"color:#ccd64d\"} and `SCHOOL`{style=\"color:#ccd64d\"}\n\n![](images/quality-exercise5.PNG){fig-align=\"center\"}\n\n## Consistent\n\n- Variable values are consistently measured, formatted, or categorized within a column\n\n- Variables are consistently measured across collections of the same form\n\n![](images/quality-consistent1.PNG){fig-align=\"center\"}\n\n::: {.notes}\n\nAnd the reason that this consistency matters is that a computer doesn't know that three different spellings of yes are all still yes. It will think these are 3 different things.\n\nSo if you collect an item in the fall and then you collect that same item in the spring, you want to make sure that item is coded and formatted in the same way. This allows you to more easily compare and combine information.\n\n:::\n\n\n## [Exercise]{style=\"color:#ccd64d\"}{.background-secondary}\n\n<br>\n\nWhat data quality issues do you detect for the **`consistent`** indicator?\n\n![](images/example-data.PNG){fig-align=\"center\"}\n\n::: {.cell}\n::: {.cell-output-display}\n\n```{=html}\n<div class=\"countdown\" id=\"timer_8a14e0b0\" data-update-every=\"1\" tabindex=\"0\" style=\"right:0;bottom:0;--countdown-font-size:2em;\">\n<div class=\"countdown-controls\"><button class=\"countdown-bump-down\">&minus;</button><button class=\"countdown-bump-up\">&plus;</button></div>\n<code class=\"countdown-time\"><span class=\"countdown-digits minutes\">01</span><span class=\"countdown-digits colon\">:</span><span class=\"countdown-digits seconds\">00</span></code>\n</div>\n```\n\n:::\n:::\n\n## [Solution]{style=\"color:#ccd64d\"}{.background-secondary}\n\n- Values for `GENDER`{style=\"color:#ccd64d\"} are not consistently categorized\n\n![](images/quality-exercise6.PNG){fig-align=\"center\"}\n\n## De-identified\n\n![](images/quality-identify1.PNG){fig-align=\"center\"}\n\n::: {.notes}\n\nIn the world of education research we are often working with human subjects and we often promise those subjects that their identifying information will remain private\n\nDirect identifiers are unique to an individual and can be used alone to identify a participant. \n\nIndirect identifiers however are not necessarily unique to a particular individual, but if combined with other information they could be used to identify a participant.\n\n  - age + gender + education level\n  - 50 + female + PhD\n  - it’s possible that someone could use that information to identify someone in a dataset\n\n:::\n\n## De-identified\n\n- Direct identifiers are removed\n\n\n![](images/quality-identify2.PNG){fig-align=\"center\"}\n\n## De-identified\n\n- Open-ended questions\n  - These variables may contain information that can directly or indirectly identify individuals\n- Outliers\n  - If someone has extreme values for a variable, it may be easier to identify that individual\n- Small cell sizes\n  - [NCES Standard 4-2-10](https://nces.ed.gov/pubsearch/pubsinfo.asp?pubid=2003601), suggests that all categories have at least 3 cases to minimize risk\n- Combinations of variables, or crosstabs, can also create small cell-sizes\n  - race + gender + grade level\n\n<br>\n\n🚨 Consider this in the context of risk\n\n- Math assessment may be low risk while a survey on substance use is higher risk\n\n::: {.notes}\n\nBut there is more you need to check for.\n\nMaking transformations based on these kinds of criteria can greatly alter your data, depending on the kinds of alterations you make. So before making alterations, you also need to consider all of this in the context of risk. So if you are collecting information that is fairly innocuous (like maybe it's a math assessment), the risk of harm if a participant re-identified is pretty low and you may decide to make minimal changes. If you are collecting information like on substance use, the risk is higher because that information could impact your career, relationships, and so forth and you need to be really thoughtful and careful in deciding what is the best course of action for your data. \n:::\n\n## [Exercise]{style=\"color:#ccd64d\"}{.background-secondary}\n\n<br>\n\nWhat data quality issues do you detect for the **`de-identified`** indicator?\n\n![](images/example-data.PNG){fig-align=\"center\"}\n\n::: {.cell}\n::: {.cell-output-display}\n\n```{=html}\n<div class=\"countdown\" id=\"timer_dc0f88ff\" data-update-every=\"1\" tabindex=\"0\" style=\"right:0;bottom:0;--countdown-font-size:2em;\">\n<div class=\"countdown-controls\"><button class=\"countdown-bump-down\">&minus;</button><button class=\"countdown-bump-up\">&plus;</button></div>\n<code class=\"countdown-time\"><span class=\"countdown-digits minutes\">01</span><span class=\"countdown-digits colon\">:</span><span class=\"countdown-digits seconds\">00</span></code>\n</div>\n```\n\n:::\n:::\n\n::: {.notes}\n\nThis is a very small dataset so don't worry about indirect identifiers right now. Focus more on direct identifiers\n\n:::\n\n## [Solution]{style=\"color:#ccd64d\"}{.background-secondary}\n\n- Replace School Name with an unique ID\n- Review outliers and combination of demographics to see if other alterations are necessary\n\n![](images/quality-exercise7.PNG){fig-align=\"center\"}\n\n\n## Biggest Advice\n\nThe number one way to reduce data errors is to make a plan before you collect data\n\n> Correct data at the source\n\n<br>\n\n. . .\n\n- Plan the variables you want to collect\n\n. . .\n\n- Build your data collection/entry tools in a way that follows your plan\n\n. . .\n\n- Test your data tools before collecting/entering data\n\n. . .\n\n- Check your data often during data collection/entry\n\n::: {.notes}\n\nSo before we move on to how to our data cleaning checklist, I want to point out one really important thing. And that is, if you are collecting your own original data\n\nDoing this ensures not only that you have much less data cleaning to do in the end, but it also prevents you from potentially losing data or having to recollect bad data. So it's 100% worth the effort to spend time planning for quality data collection in the beginning if you can.\n\nBut of course, we are not always in charge of data collection and we just have to deal with the data we are given and so are going to talk about this in the next sections.\n\n:::\n\n# Data Cleaning Checklist {.background-secondary}\n\n## Data Cleaning\n\n![](images/side-by-side-data.PNG){fig-align=\"center\"}\n\n\n## Standard Data Cleaning Checklist\n\n:::: {.columns}\n\n::: {.column width=\"50%\"}\n\n`<svg aria-hidden=\"true\" role=\"img\" viewBox=\"0 0 512 512\" style=\"height:1em;width:1em;vertical-align:-0.125em;margin-left:auto;margin-right:auto;font-size:inherit;fill:currentColor;overflow:visible;position:relative;\"><path d=\"M173.898 439.404l-166.4-166.4c-9.997-9.997-9.997-26.206 0-36.204l36.203-36.204c9.997-9.998 26.207-9.998 36.204 0L192 312.69 432.095 72.596c9.997-9.997 26.207-9.997 36.204 0l36.203 36.204c9.997 9.997 9.997 26.206 0 36.204l-294.4 294.401c-9.998 9.997-26.207 9.997-36.204-.001z\"/></svg>`{=html} Import the raw data\n\n`<svg aria-hidden=\"true\" role=\"img\" viewBox=\"0 0 512 512\" style=\"height:1em;width:1em;vertical-align:-0.125em;margin-left:auto;margin-right:auto;font-size:inherit;fill:currentColor;overflow:visible;position:relative;\"><path d=\"M173.898 439.404l-166.4-166.4c-9.997-9.997-9.997-26.206 0-36.204l36.203-36.204c9.997-9.998 26.207-9.998 36.204 0L192 312.69 432.095 72.596c9.997-9.997 26.207-9.997 36.204 0l36.203 36.204c9.997 9.997 9.997 26.206 0 36.204l-294.4 294.401c-9.998 9.997-26.207 9.997-36.204-.001z\"/></svg>`{=html} Review the raw data\n\n`<svg aria-hidden=\"true\" role=\"img\" viewBox=\"0 0 512 512\" style=\"height:1em;width:1em;vertical-align:-0.125em;margin-left:auto;margin-right:auto;font-size:inherit;fill:currentColor;overflow:visible;position:relative;\"><path d=\"M173.898 439.404l-166.4-166.4c-9.997-9.997-9.997-26.206 0-36.204l36.203-36.204c9.997-9.998 26.207-9.998 36.204 0L192 312.69 432.095 72.596c9.997-9.997 26.207-9.997 36.204 0l36.203 36.204c9.997 9.997 9.997 26.206 0 36.204l-294.4 294.401c-9.998 9.997-26.207 9.997-36.204-.001z\"/></svg>`{=html} Find missing data\n\n`<svg aria-hidden=\"true\" role=\"img\" viewBox=\"0 0 512 512\" style=\"height:1em;width:1em;vertical-align:-0.125em;margin-left:auto;margin-right:auto;font-size:inherit;fill:currentColor;overflow:visible;position:relative;\"><path d=\"M173.898 439.404l-166.4-166.4c-9.997-9.997-9.997-26.206 0-36.204l36.203-36.204c9.997-9.998 26.207-9.998 36.204 0L192 312.69 432.095 72.596c9.997-9.997 26.207-9.997 36.204 0l36.203 36.204c9.997 9.997 9.997 26.206 0 36.204l-294.4 294.401c-9.998 9.997-26.207 9.997-36.204-.001z\"/></svg>`{=html} Adjust the sample\n\n`<svg aria-hidden=\"true\" role=\"img\" viewBox=\"0 0 512 512\" style=\"height:1em;width:1em;vertical-align:-0.125em;margin-left:auto;margin-right:auto;font-size:inherit;fill:currentColor;overflow:visible;position:relative;\"><path d=\"M173.898 439.404l-166.4-166.4c-9.997-9.997-9.997-26.206 0-36.204l36.203-36.204c9.997-9.998 26.207-9.998 36.204 0L192 312.69 432.095 72.596c9.997-9.997 26.207-9.997 36.204 0l36.203 36.204c9.997 9.997 9.997 26.206 0 36.204l-294.4 294.401c-9.998 9.997-26.207 9.997-36.204-.001z\"/></svg>`{=html} De-identify data\n\n`<svg aria-hidden=\"true\" role=\"img\" viewBox=\"0 0 512 512\" style=\"height:1em;width:1em;vertical-align:-0.125em;margin-left:auto;margin-right:auto;font-size:inherit;fill:currentColor;overflow:visible;position:relative;\"><path d=\"M173.898 439.404l-166.4-166.4c-9.997-9.997-9.997-26.206 0-36.204l36.203-36.204c9.997-9.998 26.207-9.998 36.204 0L192 312.69 432.095 72.596c9.997-9.997 26.207-9.997 36.204 0l36.203 36.204c9.997 9.997 9.997 26.206 0 36.204l-294.4 294.401c-9.998 9.997-26.207 9.997-36.204-.001z\"/></svg>`{=html} Drop irrelevant columns\n\n`<svg aria-hidden=\"true\" role=\"img\" viewBox=\"0 0 512 512\" style=\"height:1em;width:1em;vertical-align:-0.125em;margin-left:auto;margin-right:auto;font-size:inherit;fill:currentColor;overflow:visible;position:relative;\"><path d=\"M173.898 439.404l-166.4-166.4c-9.997-9.997-9.997-26.206 0-36.204l36.203-36.204c9.997-9.998 26.207-9.998 36.204 0L192 312.69 432.095 72.596c9.997-9.997 26.207-9.997 36.204 0l36.203 36.204c9.997 9.997 9.997 26.206 0 36.204l-294.4 294.401c-9.998 9.997-26.207 9.997-36.204-.001z\"/></svg>`{=html} Split columns\n\n`<svg aria-hidden=\"true\" role=\"img\" viewBox=\"0 0 512 512\" style=\"height:1em;width:1em;vertical-align:-0.125em;margin-left:auto;margin-right:auto;font-size:inherit;fill:currentColor;overflow:visible;position:relative;\"><path d=\"M173.898 439.404l-166.4-166.4c-9.997-9.997-9.997-26.206 0-36.204l36.203-36.204c9.997-9.998 26.207-9.998 36.204 0L192 312.69 432.095 72.596c9.997-9.997 26.207-9.997 36.204 0l36.203 36.204c9.997 9.997 9.997 26.206 0 36.204l-294.4 294.401c-9.998 9.997-26.207 9.997-36.204-.001z\"/></svg>`{=html} Rename variables\n\n`<svg aria-hidden=\"true\" role=\"img\" viewBox=\"0 0 512 512\" style=\"height:1em;width:1em;vertical-align:-0.125em;margin-left:auto;margin-right:auto;font-size:inherit;fill:currentColor;overflow:visible;position:relative;\"><path d=\"M173.898 439.404l-166.4-166.4c-9.997-9.997-9.997-26.206 0-36.204l36.203-36.204c9.997-9.998 26.207-9.998 36.204 0L192 312.69 432.095 72.596c9.997-9.997 26.207-9.997 36.204 0l36.203 36.204c9.997 9.997 9.997 26.206 0 36.204l-294.4 294.401c-9.998 9.997-26.207 9.997-36.204-.001z\"/></svg>`{=html} Normalize variables\n\n`<svg aria-hidden=\"true\" role=\"img\" viewBox=\"0 0 512 512\" style=\"height:1em;width:1em;vertical-align:-0.125em;margin-left:auto;margin-right:auto;font-size:inherit;fill:currentColor;overflow:visible;position:relative;\"><path d=\"M173.898 439.404l-166.4-166.4c-9.997-9.997-9.997-26.206 0-36.204l36.203-36.204c9.997-9.998 26.207-9.998 36.204 0L192 312.69 432.095 72.596c9.997-9.997 26.207-9.997 36.204 0l36.203 36.204c9.997 9.997 9.997 26.206 0 36.204l-294.4 294.401c-9.998 9.997-26.207 9.997-36.204-.001z\"/></svg>`{=html} Standardize variables\n\n:::\n \n::: {.column width=\"50%\"}\n\n`<svg aria-hidden=\"true\" role=\"img\" viewBox=\"0 0 512 512\" style=\"height:1em;width:1em;vertical-align:-0.125em;margin-left:auto;margin-right:auto;font-size:inherit;fill:currentColor;overflow:visible;position:relative;\"><path d=\"M173.898 439.404l-166.4-166.4c-9.997-9.997-9.997-26.206 0-36.204l36.203-36.204c9.997-9.998 26.207-9.998 36.204 0L192 312.69 432.095 72.596c9.997-9.997 26.207-9.997 36.204 0l36.203 36.204c9.997 9.997 9.997 26.206 0 36.204l-294.4 294.401c-9.998 9.997-26.207 9.997-36.204-.001z\"/></svg>`{=html} Update variable types\n\n`<svg aria-hidden=\"true\" role=\"img\" viewBox=\"0 0 512 512\" style=\"height:1em;width:1em;vertical-align:-0.125em;margin-left:auto;margin-right:auto;font-size:inherit;fill:currentColor;overflow:visible;position:relative;\"><path d=\"M173.898 439.404l-166.4-166.4c-9.997-9.997-9.997-26.206 0-36.204l36.203-36.204c9.997-9.998 26.207-9.998 36.204 0L192 312.69 432.095 72.596c9.997-9.997 26.207-9.997 36.204 0l36.203 36.204c9.997 9.997 9.997 26.206 0 36.204l-294.4 294.401c-9.998 9.997-26.207 9.997-36.204-.001z\"/></svg>`{=html} Recode variables\n\n`<svg aria-hidden=\"true\" role=\"img\" viewBox=\"0 0 512 512\" style=\"height:1em;width:1em;vertical-align:-0.125em;margin-left:auto;margin-right:auto;font-size:inherit;fill:currentColor;overflow:visible;position:relative;\"><path d=\"M173.898 439.404l-166.4-166.4c-9.997-9.997-9.997-26.206 0-36.204l36.203-36.204c9.997-9.998 26.207-9.998 36.204 0L192 312.69 432.095 72.596c9.997-9.997 26.207-9.997 36.204 0l36.203 36.204c9.997 9.997 9.997 26.206 0 36.204l-294.4 294.401c-9.998 9.997-26.207 9.997-36.204-.001z\"/></svg>`{=html} Construct new variables\n\n`<svg aria-hidden=\"true\" role=\"img\" viewBox=\"0 0 512 512\" style=\"height:1em;width:1em;vertical-align:-0.125em;margin-left:auto;margin-right:auto;font-size:inherit;fill:currentColor;overflow:visible;position:relative;\"><path d=\"M173.898 439.404l-166.4-166.4c-9.997-9.997-9.997-26.206 0-36.204l36.203-36.204c9.997-9.998 26.207-9.998 36.204 0L192 312.69 432.095 72.596c9.997-9.997 26.207-9.997 36.204 0l36.203 36.204c9.997 9.997 9.997 26.206 0 36.204l-294.4 294.401c-9.998 9.997-26.207 9.997-36.204-.001z\"/></svg>`{=html} Add missing values\n\n`<svg aria-hidden=\"true\" role=\"img\" viewBox=\"0 0 512 512\" style=\"height:1em;width:1em;vertical-align:-0.125em;margin-left:auto;margin-right:auto;font-size:inherit;fill:currentColor;overflow:visible;position:relative;\"><path d=\"M173.898 439.404l-166.4-166.4c-9.997-9.997-9.997-26.206 0-36.204l36.203-36.204c9.997-9.998 26.207-9.998 36.204 0L192 312.69 432.095 72.596c9.997-9.997 26.207-9.997 36.204 0l36.203 36.204c9.997 9.997 9.997 26.206 0 36.204l-294.4 294.401c-9.998 9.997-26.207 9.997-36.204-.001z\"/></svg>`{=html} [Add metadata](https://github.com/Cghlewis/data-wrangling-functions/wiki/Label-Data)\n\n`<svg aria-hidden=\"true\" role=\"img\" viewBox=\"0 0 512 512\" style=\"height:1em;width:1em;vertical-align:-0.125em;margin-left:auto;margin-right:auto;font-size:inherit;fill:currentColor;overflow:visible;position:relative;\"><path d=\"M173.898 439.404l-166.4-166.4c-9.997-9.997-9.997-26.206 0-36.204l36.203-36.204c9.997-9.998 26.207-9.998 36.204 0L192 312.69 432.095 72.596c9.997-9.997 26.207-9.997 36.204 0l36.203 36.204c9.997 9.997 9.997 26.206 0 36.204l-294.4 294.401c-9.998 9.997-26.207 9.997-36.204-.001z\"/></svg>`{=html} Validate data\n\n`<svg aria-hidden=\"true\" role=\"img\" viewBox=\"0 0 512 512\" style=\"height:1em;width:1em;vertical-align:-0.125em;margin-left:auto;margin-right:auto;font-size:inherit;fill:currentColor;overflow:visible;position:relative;\"><path d=\"M173.898 439.404l-166.4-166.4c-9.997-9.997-9.997-26.206 0-36.204l36.203-36.204c9.997-9.998 26.207-9.998 36.204 0L192 312.69 432.095 72.596c9.997-9.997 26.207-9.997 36.204 0l36.203 36.204c9.997 9.997 9.997 26.206 0 36.204l-294.4 294.401c-9.998 9.997-26.207 9.997-36.204-.001z\"/></svg>`{=html} [Join data](https://cghlewis.com/blog/joins/)\n\n`<svg aria-hidden=\"true\" role=\"img\" viewBox=\"0 0 512 512\" style=\"height:1em;width:1em;vertical-align:-0.125em;margin-left:auto;margin-right:auto;font-size:inherit;fill:currentColor;overflow:visible;position:relative;\"><path d=\"M173.898 439.404l-166.4-166.4c-9.997-9.997-9.997-26.206 0-36.204l36.203-36.204c9.997-9.998 26.207-9.998 36.204 0L192 312.69 432.095 72.596c9.997-9.997 26.207-9.997 36.204 0l36.203 36.204c9.997 9.997 9.997 26.206 0 36.204l-294.4 294.401c-9.998 9.997-26.207 9.997-36.204-.001z\"/></svg>`{=html} [Reshape data](https://osf.io/xumg4)\n\n`<svg aria-hidden=\"true\" role=\"img\" viewBox=\"0 0 512 512\" style=\"height:1em;width:1em;vertical-align:-0.125em;margin-left:auto;margin-right:auto;font-size:inherit;fill:currentColor;overflow:visible;position:relative;\"><path d=\"M173.898 439.404l-166.4-166.4c-9.997-9.997-9.997-26.206 0-36.204l36.203-36.204c9.997-9.998 26.207-9.998 36.204 0L192 312.69 432.095 72.596c9.997-9.997 26.207-9.997 36.204 0l36.203 36.204c9.997 9.997 9.997 26.206 0 36.204l-294.4 294.401c-9.998 9.997-26.207 9.997-36.204-.001z\"/></svg>`{=html} Save clean data\n\n:::\n:::\n\n::: {.notes}\n\nHowever, to produce datasets that consistently meet the data quality criteria we just reviewed, it can be helpful to follow a standardized checklist of data cleaning steps. These steps, although they are really general here, once you tailor them to your specific data source they can help you produce a dataset that meets our data quality standards. \n\nAs you use this checklist to clean your specific dataset you use the steps that are relevant to your data and remove the steps that are not relevant. \n\nThe order of these steps are fluid. With the exception of the first two on the list, you can move them around in whatever order makes sense for your specific dataset.\n\nWe are going to take some time to review each step on this list with the exception of the ones in blue. Those require more time to cover than we have today, so instead I have linked to more information here for you to review in your own time.\n\n\n:::\n\n## Import raw data\n\n![](images/checklist1.PNG){fig-align=\"center\"}\n\n::: {.notes}\n\nImporting your raw data will always be number one of course, and the most important rule here is to never make any manual edits directly in the raw data file. Your raw data file is your single source of truth for that data source. If you make errors in your data cleaning process, you should always be able to go back to the untouched raw data to start over again if you need to. \n\n:::\n\n## Review data\n\n![](images/checklist2.PNG){fig-align=\"center\"}\n\n::: {.notes}\n\nReviewing your data should always be step number two. It's important that you know exactly what is happening in your data before moving forward in the cleaning process.\n\nIf you have access to those documents we discussed earlier, participant tracking database and a data dictionary, now is the time to use them.\n\n:::\n\n## Find missing data\n\n![](images/checklist3.PNG){fig-align=\"center\"}\n\n::: {.notes}\n\nIf you find that any data is missing in your review process (missing cases/missing variables) you'll want to retrieve that missing data before moving forward in the cleaning process\n\nStart back at step 1\n\n:::\n\n## Adjust the sample\n\n![](images/checklist4.PNG){fig-align=\"center\"}\n\n::: {.notes}\n\nThis means removing anyone who should not be in the dataset - maybe they didn't consent to be in the study\n\nIt also means taking care of any duplicates in your data\n\nThe first thing you'll want to do before removing duplicates is determine if it is a true duplicate, not just an error in the data\n\nThen removing any true duplicates based on your duplicate removal rule\n\nIt's really important that these kinds of decisions rules are documented for future data users. And we'll talk more about where to document these kinds of things later.\n\n:::\n\n## De-identify data\n\n![](images/checklist5-1.PNG){fig-align=\"center\"}\n\n## De-identify data\n\n![](images/checklist5-2.PNG){fig-align=\"center\"}\n\n## De-identify data\n\n![](images/checklist5-3.PNG){fig-align=\"center\"}\n\n|Source|Resource|\n|--------|-----------|\n|[Alena Filip](https://www.sjsu.edu/research/docs/irb-data-management-handbook.pdf) |Table 2 provides pros and cons of various de-identification methods|\n|[J-PAL](https://www.povertyactionlab.org/resource/data-de-identification)| Table 3 provides a list of direct and indirect identifiers and recommended removal methods|\n|[Schatschneider, et.al](https://figshare.com/articles/preprint/De-Identification_Guide/13228664)| Deidentifying Data Guide|\n\n:::{.notes}\n\n- Redaction\n  - Eliminate the entire variable from the data\n- Suppression\n  - Remove data in a particular cell or row (In this example, age 67 was an outlier so I suppressed that cell value and replaced it with -98 which I’ve coded as suppressed).\n- Generalization\n  - Reduce precision in the data (In this example here, I’ve binned my age ranges so they are less precise)\n- Truncation\n  - Restricting upper and lower ranges to mask outliers\n  \nThere are many, even more sophisticated ways, to de-identify data\n\n:::\n\n## Drop irrelevant columns\n\n<br>\n\n![](images/checklist6.PNG){fig-align=\"center\"}\n\n## Split columns\n\n![](images/checklist7.PNG){fig-align=\"center\"}\n\n## Rename variables\n\n![](images/checklist8.PNG){fig-align=\"center\"}\n\n## Normalize variables\n\n- Compare the variable types in your raw data to the types you expected in your data dictionary. \n  - Do they align? If not, what needs to be done so that they do\n\n![](images/checklist9.PNG){fig-align=\"center\"}\n\n:::{.notes}\n\nI realize this is unconventional terminology to use, but here I am using the term normalize to talk about returning variables to their normal or expected state. \n\n:::\n\n## Standardize variables\n\n- Are columns consistently measured, categorized, and formatted according to your data dictionary?\n  - If not, what needs to be done so that they are\n\n![](images/checklist10.PNG){fig-align=\"center\"}\n\n:::{.notes}\n\nHere I am using the term standardize to convey the process of checking for consistency\n\n:::\n\n## Update variable types\n\n![](images/checklist11.PNG){fig-align=\"center\"}\n\n:::{.notes}\n\nCharacter to Numeric, Numeric to Date, And so forth\n\n:::\n\n## Recode variables\n\n![](images/checklist12.PNG){fig-align=\"center\"}\n\n:::{.notes}\n\n- This includes recoding your categorical numeric values to match your data dictionary values\n- But it also includes any planned coding, such as reverse coding a variable\n- As well as recoding any implicit values to their explicit values\n\n:::\n\n## Construct additional variables\n\n![](images/checklist13.PNG){fig-align=\"center\"}\n\n:::{.notes}\n\n- This is not the time to construct analysis-specific variables. This is the time to create or calculate variables that should always be a part of the core study dataset.\n\n- This could be things like grouping variables (treatment, cohort, site)\n- It could be time component variables (year, wave)\n- It could be additional unique identifiers that you need to add for linking purposes (like adding a school ID to a teacher file)\n- Or it could be measure composite or summary scores that you want included in the core dataset\n- Any other variables you want added to the core sharing dataset\n\n- Some of these variables will be calculated, others may be merged in from other sources\n\n:::\n\n## Add missing values\n\n![](images/checklist14.PNG){fig-align=\"center\"}\n\n\n## Data validation\n\n::: columns\n\n::: {.column width=\"50%\"}\n\n![](images/checklist15-1.PNG)\n\n:::\n\n::: {.column width=\"50%\"}\n\n::: {layout-nrow=2}\n\n![](images/checklist15-2.PNG)\n\n![](images/checklist15-3.PNG)\n\n:::\n\n:::\n:::\n\n:::{.notes}\n\nYou should absolutely be checking your transformations throughout your cleaning process, but then, before exporting your data you should do one final review to make sure you haven't missed anything.  \n\nHere are several examples where various researchers did not have data validation as part of their data cleaning process and found out much later on that their data contained errors. And so we want to try to prevent this scenario by catching any errors now, rather than later.\n\n:::\n\n\n## Data validation\n\n:::: {.columns}\n\n::: {.column width=\"60%\"}\n\n- Complete\n  - Check for missing/duplicate cases\n    - Check Ns by groups for completeness\n  - Check for missing/too many columns\n- Valid and consistent\n  - Check for unallowed categories/values out of range\n    - Check ranges by groups\n  - Check for invalid, non-unique, or missing study IDs\n  - Check for incorrect variable types/formats\n  - Check missing value patterns\n\n:::\n \n::: {.column width=\"40%\"}\n\n- Accurate\n  - Agreement across variables\n- De-identified\n  - All direct identifiers are removed\n  - All indirect identifiers managed as needed\n- Interpretable\n  - Variables correctly named\n\n:::\n:::\n\n:::{.notes}\n\nUse your data quality indicator list as a guide when doing your final data review\n\n:::\n\n## Data validation\n\n:::: {.columns}\n\n::: {.column width=\"60%\"}\n\n1. Documentation errors\n    - Fix in documentation\n2. Data cleaning errors\n    - Fix in your cleaning process\n3. Data entry/export process errors\n    - Fix at the source and export new raw file\n4. True values that are inaccurate, uninterpretable, or outside of a valid range\n    - Leave the data as is (document the issue)\n    - Recode those values to designated error code\n    - Create data quality indicators\n    - Choose one source of truth for inconsistent values\n    - Use logical/deductive editing\n    \n:::\n \n::: {.column width=\"40%\"}\n\n![](images/checklist15-4.PNG){fig-align=\"center\"}\n\n:::\n:::\n\n:::{.notes}\n\nWhat's most important is that you document your decisions for future users\n\n:::\n\n## Export data\n\n<br>\n\n![](images/checklist16.jpg){fig-align=\"center\"}\n\n## Export data\n\nWhen you export your files, it's important to name them consistently and clearly.\n\n- Follow rules similar to our variable naming rules\n  - Machine-readable (except now `-` is allowed)\n  - Human-readable\n    - A user should be able to understand what the file contains without opening it\n\n<br>\n\nWhich gives you a better idea of what is in the file? 🤔\n\n  - \"Project X Full Data.csv\"\n  - \"projectx_wave1_stu_svy_clean.csv\"\n\n\n## Creating a data cleaning plan\n\n![](images/data_cleaning_plan.PNG){fig-align=\"center\"}\n\n\n:::{.notes}\n\nUltimately what I like to do in a cleaning process is pull out my checklist, import and review my data, and then plan out the steps that are needed to clean my specific dataset\n\n:::\n\n## BREAK!\n\n![](https://media1.tenor.com/m/XFNnJtXYH_gAAAAC/dog-wipe-face.gif){fig-align=\"center\" width=80%}\n\n## BREAK!\n\n::: {.cell}\n::: {.cell-output-display}\n\n```{=html}\n<div class=\"countdown\" data-update-every=\"1\" id=\"timer_b9539522\" style=\"right:0;bottom:0;--countdown-font-size:10em; position: relative; width: min-content;\" tabindex=\"0\">\n<div class=\"countdown-controls\"><button class=\"countdown-bump-down\">&minus;</button><button class=\"countdown-bump-up\">&plus;</button></div>\n<code class=\"countdown-time\"><span class=\"countdown-digits minutes\">15</span><span class=\"countdown-digits colon\">:</span><span class=\"countdown-digits seconds\">00</span></code>\n</div>\n```\n\n:::\n:::\n\n# Cleaning in R {.background-secondary}\n\n:::{.notes}\n\n- Before we jump\n- that this material is not about learning a comprehensive set of data cleaning functions that you can use to solve every data cleaning issue you may encounter\n- There's no way to cover that much material, and on top of that, for every data cleaning issue you encounter in your data, there are probably 10 different ways to solve that issue. \n- Instead this section is more about learning a standardized way of thinking through a data cleaning process and pulling from the available R functions, some of which we will learn today, to work through that process. \n\n:::\n\n## Objects\n\n<br>\n\n- If you want to save the output from something you do in R, you need to save it to an object that lives in your environment\n  - Objects should follow the same naming rules we discussed earlier\n- If you simply want to view an output, you don't need to save it into an object\n\n<br>\n\n::: columns\n::: {.column width=\"50%\"}\n\n::: {.cell}\n\n```{.r .cell-code}\nage <- c(12, 10, 8)\n\nage_new <- age + 1\n```\n:::\n\n:::\n\n::: {.column width=\"50%\"}\n\n::: {.cell}\n\n```{.r .cell-code}\nmean(age_new)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 11\n```\n\n\n:::\n:::\n\n:::\n:::\n\n\n:::{.notes}\n\nFoundational\n\n:::\n\n## Objects\n\n<br>\n\n::: columns\n::: {.column width=\"50%\"}\n\nData Frame (Tibble)\n\n- Two dimensional structure\n\n::: {.cell}\n\n```{.r .cell-code}\ndf <- data.frame(id = c(10, 20),\n                 age = c(12, 8))\n\ndf\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  id age\n1 10  12\n2 20   8\n```\n\n\n:::\n:::\n\n:::\n\n::: {.column width=\"50%\"}\n\nVector\n\n- Consists of one or more elements all of the same type\n\n::: {.cell}\n\n```{.r .cell-code}\nid <- c(10, 20)\n\nid\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 10 20\n```\n\n\n:::\n:::\n\n- Common vector types (class)\n  - character, numeric, date (POSIXct, POSIXlt), logical\n  \n:::\n:::\n\n## RStudio Pane Layout\n\n\n![Image from [RStudio User Guide](https://docs.posit.co/ide/user/ide/guide/ui/ui-panes.html)](images/r_panes.PNG)\n\n## Script Files\n\n::: columns\n::: {.column width=\"50%\"}\n\nR Script File\n\n![](images/script.PNG){fig-align=\"center\"}\n\n:::\n\n::: {.column width=\"50%\"}\n\nR Markdown File\n\n![](images/rmdfile.PNG){fig-align=\"center\"}\n\n:::\n:::\n\n\n## Functions\n\n::: columns\n::: {.column width=\"60%\"}\n\n- Anatomy of a function\n    - **function_name(argument1, argument2, argument3, ...)**\n      - the first argument is usually an object\n    - You can view arguments by typing `?functionname` in your console\n\n- Arguments usually have defaults\n    - For example `mean(x, trim, na.rm)`\n      - trim = 0\n      - na.rm = FALSE\n\n- R has many built in (base) functions\n\n:::\n\n::: {.column width=\"5%\"}\n\n:::\n\n::: {.column width=\"35%\"}\n\n<br>\n<br>\n<br>\n\n|Function | Task |\n|-----|----------|\n| View() | View object |\n| str() |Display internal structure of an object |\n|c() |Combine elements| \n| class() |Check the class/type of an object |\n\n:::\n:::\n\n:::{.notes}\n\nIf you like the defaults, do nothing. You don't have to type out the arguments. If you want to change the default, you need to type out the arguments.\n\n:::\n\n## Packages\n\n- We can also use functions that live in packages that we can install onto our computer\n\n- Once installed, there are two ways to call packages\n  - You may see both methods used in these slides\n\n<br>\n\n::: columns\n::: {.column width=\"50%\"}\n\nUsing `library()`\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(dplyr)\n\nselect(df, var1, var2) \n```\n:::\n:::\n\n::: {.column width=\"50%\"}\n\nUsing Namespacing `package::function()`\n\n::: {.cell}\n\n```{.r .cell-code}\n# library(dplyr) not needed\n\ndplyr::select(df, var1, var2) \n```\n:::\n:::\n:::\n\n:::{.notes}\n\nFoundational\n\n:::\n\n\n## Pipes\n\n-   2014+ magrittr pipe `%>%`\n\n-   2021+ (R $\\geq$ 4.1.0) native R pipe `|>`\n\n. . .\n\nIsabella Velásquez's blog post [*Understanding the native R pipe* \\|\\>](https://ivelasq.rbind.io/blog/understanding-the-r-pipe/) (2022)\n\n<br>\n\n. . .\n\n::: columns\n::: {.column width=\"50%\"}\n::: {.cell}\n\n```{.r .cell-code}\nsch_data <- select(sch_data, id, \n                    test_score)\n\nsch_data <- filter(sch_data, \n                    test_score > 300)\n```\n:::\n:::\n\n::: {.column width=\"50%\"}\n::: {.cell}\n\n```{.r .cell-code}\nsch_data <- sch_data |>\n  select(id, test_score) |>\n  filter(test_score > 300)\n```\n:::\n:::\n:::\n\n. . .\n\n<br>\n\nTo turn on the native pipe:\n\n`Tools` → `Global Options` → `Code` → `Editing` → `Use Native Pipe Operator`\n\n## Operators\n\n::: columns\n::: {.column width=\"50%\"}\n\nComparison operators\n\n- `==` equal to\n- `!=` not equal to\n- `<` less than\n- `>` greater than\n- `%in%` value is present within\n\n::: {.cell}\n\n```{.r .cell-code}\ndf |>\n  filter(city %in% c(\"boston\",\"philly\"))\n```\n:::\n\n:::\n\n::: {.column width=\"50%\"}\n\nAssignment operators\n\n- `<-` Assign values to an object\n- `=` Assign value to an argument\n\n::: {.cell}\n\n```{.r .cell-code}\ndf <- df |>\n  mutate(year = \"2024\")\n```\n:::\n\n:::\n:::\n\n## Scenario\n\n- A team member has just collected a teacher survey and has exported a raw data file.\n- They have asked you to clean the file up for the purposes of data sharing.\n\n![](images/sample-data.PNG){fig-align=\"center\"}\n\n\n## [Exercise]{style=\"color:#ccd64d\"}{.background-secondary}\n\n<br>\n\n#### Take 5 minutes to open and look at our data file.\n\n1. Log in to Posit Cloud and navigate to our project\n    - [**https://posit.cloud/content/7872027**](https://posit.cloud/content/7872027)\n2. Open the `data` folder and download \"sample_tch_svy_raw.xlsx\" to view the file on your computer\n    - To download the file, check the box next to the file and go to \"More\" then \"Export\"\n3. Open the data file and review it.\n    - Notice that there is a tab called \"labels\" which contains information about the current state of the variables in the dataset\n  \n  \n::: {.cell}\n::: {.cell-output-display}\n\n```{=html}\n<div class=\"countdown\" id=\"timer_6ed4ef20\" data-update-every=\"1\" tabindex=\"0\" style=\"right:0;bottom:0;--countdown-font-size:2em;\">\n<div class=\"countdown-controls\"><button class=\"countdown-bump-down\">&minus;</button><button class=\"countdown-bump-up\">&plus;</button></div>\n<code class=\"countdown-time\"><span class=\"countdown-digits minutes\">05</span><span class=\"countdown-digits colon\">:</span><span class=\"countdown-digits seconds\">00</span></code>\n</div>\n```\n\n:::\n:::\n\n## Import our data\n\n<br>\n\nCommon data importing functions\n\n- `read_csv()`, `read_delim()` from the `readr` package\n\n- `read_excel()` from the `readxl` package\n\n- `read_sav()`, `read_sas()`, `read_dta()` from the `haven` package\n\n- Learn more about importing multiple files at once [here](https://github.com/Cghlewis/data-wrangling-functions/wiki/Import-Files)\n\n<br>\n\n. . .\n\n**Which function should we use to read in our sample data?**🤔\n\n## Import our file\n\n::: columns\n \n::: {.column width=\"50%\"}\n\n- `read_excel()` has several arguments. \n  - path\n    - Name of the file, **plus folder names** as needed\n    - \"data/w1_stu_obs_raw.xlsx\"\n  - sheet = NULL\n  - col_names = TRUE\n  - na = \"\"\n  - skip = 0\n- Type `?read_excel()` in your console to see more arguments\n\n:::\n\n::: {.column width=\"50%\"}\n\n![](images/read_excel.PNG){fig-align=\"center\"}\n\n:::\n:::\n\n\n## [Exercise]{style=\"color:#ccd64d\"}{.background-secondary}\n\n<br>\n\n### Take 2 minutes to import the data.\n\n<br>\n\n1. Open \"exercises.Rmd\" in our Posit Cloud project.\n2. First run the \"Library packages\" chunk using the green arrow.\n3. Then navigate to Exercise 1. \n4. Update the first code chunk and run the code to read in the data.\n5. Run the second code chunk to view the data.\n\nIf you get stuck, you can open \"solutions.Rmd\"\n\n::: {.cell}\n::: {.cell-output-display}\n\n```{=html}\n<div class=\"countdown\" id=\"timer_307abaf7\" data-update-every=\"1\" tabindex=\"0\" style=\"right:0;bottom:0;--countdown-font-size:2em;\">\n<div class=\"countdown-controls\"><button class=\"countdown-bump-down\">&minus;</button><button class=\"countdown-bump-up\">&plus;</button></div>\n<code class=\"countdown-time\"><span class=\"countdown-digits minutes\">02</span><span class=\"countdown-digits colon\">:</span><span class=\"countdown-digits seconds\">00</span></code>\n</div>\n```\n\n:::\n:::\n\n:::{.notes}\n\nEverything in this file will build off of each other so you will need to keep up with the exercises along the way.\n\n:::\n\n## Review our data\n\n<br>\n\n::: columns\n::: {.column width=\"50%\"}\n\n- How many rows?\n  - In this hypothetical situation, we assume we are not missing any cases\n  - However, there may be duplicates\n- How many columns?\n- What are the variable values and ranges? Variable types?\n- How much missing data do we have?\n\n:::\n\n::: {.column width=\"5%\"}\n\n:::\n\n::: {.column width=\"45%\"}\n\nThere are several functions we can use to explore data\n\n- `dplyr::glimpse()`\n- `skimr::skim()`\n- `base::summary()`\n- **`summarytools::dfSummary()`**\n- `Hmisc::describe()`\n\n:::\n:::\n\n## Review our data\n\n![](images/dfsummary.PNG){fig-align=\"center\" width=\"70%\"}\n\n## [Exercise - Part 1]{style=\"color:#ccd64d\"}{.background-secondary}\n\n<br>\n\n### Take 3 minutes to review our data.\n\n1. Navigate to Exercise 2.\n2. Run the code. \n    - Write down any potential issues you see in the data based on our data quality criteria (analyzable, interpretable, complete, valid, accurate, consistent, de-identified).\n    - Note: Ignore the warning messages from `dfSummary()`\n\n::: {.cell}\n::: {.cell-output-display}\n\n```{=html}\n<div class=\"countdown\" id=\"timer_603b42a3\" data-update-every=\"1\" tabindex=\"0\" style=\"right:0;bottom:0;--countdown-font-size:2em;\">\n<div class=\"countdown-controls\"><button class=\"countdown-bump-down\">&minus;</button><button class=\"countdown-bump-up\">&plus;</button></div>\n<code class=\"countdown-time\"><span class=\"countdown-digits minutes\">03</span><span class=\"countdown-digits colon\">:</span><span class=\"countdown-digits seconds\">00</span></code>\n</div>\n```\n\n:::\n:::\n\n:::{.notes}\n\nSo we are going to follow this data cleaning plan for the rest of this section\n\n:::\n\n## [Exercise - Part 2]{style=\"color:#ccd64d\"}{.background-secondary}\n\n<br>\n\n### Take 5 minutes to compare our data to our documents.\n\n1. Export and open the \"sample_tch_svy_data-dictionary.xlsx\" in the `docs` folder. \n    - Compare the data dictionary to what you see in our raw data. \n    - What additional issues do you see when you compare the data to our data dictionary?\n2. Export and open the \"sample_tch_svy_cleaning-plan.txt\" in the `docs` folder. \n    - How does the cleaning plan compare to the issues you wrote down?\n\n::: {.cell}\n::: {.cell-output-display}\n\n```{=html}\n<div class=\"countdown\" id=\"timer_78115a83\" data-update-every=\"1\" tabindex=\"0\" style=\"right:0;bottom:0;--countdown-font-size:2em;\">\n<div class=\"countdown-controls\"><button class=\"countdown-bump-down\">&minus;</button><button class=\"countdown-bump-up\">&plus;</button></div>\n<code class=\"countdown-time\"><span class=\"countdown-digits minutes\">05</span><span class=\"countdown-digits colon\">:</span><span class=\"countdown-digits seconds\">00</span></code>\n</div>\n```\n\n:::\n:::\n\n:::{.notes}\n\nSo we are going to follow this data cleaning plan for the rest of this section\n\n:::\n\n\n## Adjust the sample\n\n<br>\n\nThere are two key functions we can use to both identify and remove duplicates in our data\n\n<br>\n\n  - `janitor::get_dupes()`\n    - Tells you which rows contain duplicate unique identifiers, if any\n\n<br>\n\n  - `dplyr::distinct()`\n    - Keeps the first instance of a duplicate unique identifier\n\n      \n:::{.notes}\n\nSo the next step in our checklist is to adjust the sample\nAnd we found some duplicates in our sample\n\n:::\n  \n## Adjust the sample\n\n::: panel-tabset\n### Check for duplicates\n\n::: {.cell}\n\n```{.r .cell-code}\ndf |>\n  get_dupes(id_vars)\n```\n:::\n\n- Replace `id_vars` with your unique identifier\n- If you have more than one variable that uniquely identifies rows, use `c(first_name, last_name)`\n\n### Remove duplicates\n\n::: {.cell}\n\n```{.r .cell-code}\ndf |>\n  distinct(id_vars, \n           .keep_all = TRUE)\n```\n:::\n- Replace `id_vars` with your unique identifier/s\n- Always add the argument *.keep_all = TRUE*\n- But remember, this always keeps the first instance of your duplicate\n  - This may not always be want you want\n\n### Remove duplicates\n\n::: {.cell}\n\n```{.r .cell-code}\ndf |>\n  arrange(date) |>\n  distinct(id_vars, \n           .keep_all = TRUE)\n```\n:::\n- Consider arranging your data first, before removing duplicates\n- Replace `date` with any variable that you want to arrange your data by\n  - The default is to sort values in ascending order\n    - If you want descending order `arrange(desc(date))`\n\n:::\n\n\n\n## [Exercise]{style=\"color:#ccd64d\"}{.background-secondary}\n\n<br>\n\n### Take 3 minutes to check for and remove duplicates.\n\n1. Navigate to Exercise 3.\n2. Run the code to check for duplicates. \n    - Make note of the duplicate `tch_id` number.\n3. Run the code to remove our duplicates. \n    - Our documented rule is that if both surveys are complete, keep the most recently completed row.\n4. Run a check to make sure duplicates are removed.\n5. Run the code to confirm that we kept the most recent submission of the duplicate survey (\"2024-04-02\").\n\n::: {.cell}\n::: {.cell-output-display}\n\n```{=html}\n<div class=\"countdown\" id=\"timer_a049dd5a\" data-update-every=\"1\" tabindex=\"0\" style=\"right:0;bottom:0;--countdown-font-size:2em;\">\n<div class=\"countdown-controls\"><button class=\"countdown-bump-down\">&minus;</button><button class=\"countdown-bump-up\">&plus;</button></div>\n<code class=\"countdown-time\"><span class=\"countdown-digits minutes\">03</span><span class=\"countdown-digits colon\">:</span><span class=\"countdown-digits seconds\">00</span></code>\n</div>\n```\n\n:::\n:::\n\n## De-identify data\n\n<br>\n\nThe functions used here will depend on what is required.\n\n<br>\n\nExamples of functions you might use:\n\n- `dplyr::select()` to drop variables\n- `dplyr::case_when()` or `dplyr::recode()` to collapse categories/recode values\n- `dplyr::*_join()` to merge in study unique IDs\n- `stringr::str_remove_all()` or `stringr::str_replace_all()` to redact character values\n\n\nFor our sample data we are going to use the following.\n\n1. `dplyr::case_when()` to recategorize names into our unique study ID values and\n2. `dplyr::select()` to drop identifying variables\n\n## De-identify data\n\n::: panel-tabset\n\n### Recategorize values\n\n::: {.cell}\n\n```{.r .cell-code}\ndf |>\n  dplyr::mutate(new_var_name =\n                  case_when(\n                    var_name == old_value1 ~ new_value1,\n                    var_name == old_value2 ~ new_value2\n                  ))\n```\n:::\n\n- To learn more about setting *default* values for `case_when()`, type `?case_when` in your console\n- Note that there is a new function, `case_match()`, that is worth looking in to. It reduces repetition in the syntax.\n\n### Recategorize values\n\n::: columns\n::: {.column width=\"50%\"}\n\n\nMy data frame that I want to de-identify\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n\n```\n    fname    lname score1 score2\n1    emma    royce     22     50\n2 brandon figueroa     40     61\n```\n\n\n:::\n:::\n\n:::\n\n::: {.column width=\"50%\"}\n\n::: {.cell}\n\n```{.r .cell-code}\ndf |>\n  mutate(id = \n           case_when(\n             fname == \"emma\" ~ 300,\n             fname == \"brandon\" ~ 301\n           ))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n    fname    lname score1 score2  id\n1    emma    royce     22     50 300\n2 brandon figueroa     40     61 301\n```\n\n\n:::\n:::\n\n \n:::\n:::\n\n### Select variables\n\n::: columns\n::: {.column width=\"50%\"}\n\n\nTo select variables of interest\n\n::: {.cell}\n\n```{.r .cell-code}\ndf |>\n  select(score1, score2, id)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ndf |>\n  select(score1:id)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ndf |>\n  select(starts_with(\"score\"), id)\n```\n:::\n\n:::\n\n::: {.column width=\"50%\"}\n\nTo drop variables I add **`-`**\n\n::: {.cell}\n\n```{.r .cell-code}\ndf |>\n  select(-fname:lname)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ndf |>\n  select(-c(fname, lname))\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ndf |>\n  select(-contains(\"name\"))\n```\n:::\n\n:::\n:::\n\n:::\n\n## [Exercise]{style=\"color:#ccd64d\"}{.background-secondary}\n\n<br>\n\n### Take 3 minutes to de-identify our data\n\n1. Navigate to Exercise 4.\n2. Edit and run the code to create a `sch_id` variable.\n    - Review the new variable after it is created.\n3. Edit and run the code to drop our identifying variables.\n    - Review to make sure those variables were removed.\n\n::: {.cell}\n::: {.cell-output-display}\n\n```{=html}\n<div class=\"countdown\" id=\"timer_ad03d954\" data-update-every=\"1\" tabindex=\"0\" style=\"right:0;bottom:0;--countdown-font-size:2em;\">\n<div class=\"countdown-controls\"><button class=\"countdown-bump-down\">&minus;</button><button class=\"countdown-bump-up\">&plus;</button></div>\n<code class=\"countdown-time\"><span class=\"countdown-digits minutes\">03</span><span class=\"countdown-digits colon\">:</span><span class=\"countdown-digits seconds\">00</span></code>\n</div>\n```\n\n:::\n:::\n\n## Rename variables\n\nTwo functions we can use to rename variables\n\n- `dplyr::rename()`\n    - Commonly used to rename just a few variables\n- `purrr::set_names()`\n    - Used to rename all of our variables\n    - Variables in your dataset must be ordered in the same way as in `set_names()`\n\n<br>\n\n::: columns\n::: {.column width=\"50%\"}\n\nRename just a few variables\n\n::: {.cell}\n\n```{.r .cell-code}\ndf |>\n  rename(new_name = old_name)\n```\n:::\n\n:::\n\n::: {.column width=\"50%\"}\n\nRename all variables\n\n::: {.cell}\n\n```{.r .cell-code}\ndf |>\n  set_names(c(\"name1\", \"name2\", \"name3\"))\n```\n:::\n\n:::\n:::\n\n## [Exercise]{style=\"color:#ccd64d\"}{.background-secondary}\n\n<br>\n\n### Take 3 minutes to rename variables\n\n1. Navigate to Exercise 5.\n2. Review the current variable names.\n3. Edit the code to rename variables according to our data dictionary/data cleaning plan.\n4. Check variable names again to make sure the renaming worked.\n\n::: {.cell}\n::: {.cell-output-display}\n\n```{=html}\n<div class=\"countdown\" id=\"timer_c596be18\" data-update-every=\"1\" tabindex=\"0\" style=\"right:0;bottom:0;--countdown-font-size:2em;\">\n<div class=\"countdown-controls\"><button class=\"countdown-bump-down\">&minus;</button><button class=\"countdown-bump-up\">&plus;</button></div>\n<code class=\"countdown-time\"><span class=\"countdown-digits minutes\">03</span><span class=\"countdown-digits colon\">:</span><span class=\"countdown-digits seconds\">00</span></code>\n</div>\n```\n\n:::\n:::\n\n\n## Normalize variables\n\nThere are several functions that can help us remove unexpected values from our variables. \n\nSome examples of those include:\n\n- `stringr::str_remove_all()`\n- `stringr::str_replace_all()`\n- `readr::parse_number()`\n\n<br>\n\nSay this is our data\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 3 x 2\n     id income \n  <dbl> <chr>  \n1     1 $32,000\n2     2 120000 \n3     3 $45,000\n```\n\n\n:::\n:::\n\n\n## Normalize variables\n\n<br>\n\n::: columns\n::: {.column width=\"50%\"}\n\nRemove character values with `stringr::str_remove_all()`\n\n::: {.cell}\n\n```{.r .cell-code}\ndf |>\n  dplyr::mutate(income = \n                  str_remove_all(income, \"\\\\$|,\"))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 3 x 2\n     id income\n  <dbl> <chr> \n1     1 32000 \n2     2 120000\n3     3 45000 \n```\n\n\n:::\n:::\n\n- Notice that our variable is still character type\n\n:::\n\n::: {.column width=\"50%\"}\n\nRemove character values with `readr::parse_number()`\n\n::: {.cell}\n\n```{.r .cell-code}\ndf |>\n  dplyr::mutate(income = \n                  parse_number(income))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 3 x 2\n     id income\n  <dbl>  <dbl>\n1     1  32000\n2     2 120000\n3     3  45000\n```\n\n\n:::\n:::\n\n- Notice that `parse_number()` converts our variable to numeric type\n\n:::\n:::\n\n## [Exercise]{style=\"color:#ccd64d\"}{.background-secondary}\n\n<br>\n\n### Take 2 minutes to normalize our `tch_yrs` variable\n\n1. Navigate to Exercise 6.\n2. Review the current values for `tch_yrs`.\n3. Edit the code to remove all non-numeric values from this variable.\n4. Review the new values in `tch_yrs`.\n\n::: {.cell}\n::: {.cell-output-display}\n\n```{=html}\n<div class=\"countdown\" id=\"timer_3d35d4bc\" data-update-every=\"1\" tabindex=\"0\" style=\"right:0;bottom:0;--countdown-font-size:2em;\">\n<div class=\"countdown-controls\"><button class=\"countdown-bump-down\">&minus;</button><button class=\"countdown-bump-up\">&plus;</button></div>\n<code class=\"countdown-time\"><span class=\"countdown-digits minutes\">02</span><span class=\"countdown-digits colon\">:</span><span class=\"countdown-digits seconds\">00</span></code>\n</div>\n```\n\n:::\n:::\n\n## Update variable type\n\nDepending on what is needed, there are several functions we can use to change variable types.\n\n<br>\n\nSome examples include:\n\n- `as.numeric()`\n- `as.character()`\n- `as.Date()`\n- Several functions in the `lubridate` package to assist with converting dates\n- `janitor::excel_numeric_to_date()` can be very helpful at times\n\n## Update variable type\n\nIt's important to normalize variables **before** converting types (especially when converting from character to numeric)\n\n<br>\n\n::: columns\n::: {.column width=\"50%\"}\n\nOur data without normalizing\n\n::: {.cell}\n\n```{.r .cell-code}\ndf\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 3 x 2\n     id income \n  <dbl> <chr>  \n1     1 $32,000\n2     2 120000 \n3     3 $45,000\n```\n\n\n:::\n:::\n\n:::\n\n::: {.column width=\"50%\"}\n\nWhen we try to convert `income` to numeric....\n\n::: {.cell}\n\n```{.r .cell-code}\ndf |>\n  dplyr::mutate(income = \n                  as.numeric(income))\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning in mask$eval_all_mutate(quo): NAs introduced by coercion\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 3 x 2\n     id income\n  <dbl>  <dbl>\n1     1     NA\n2     2 120000\n3     3     NA\n```\n\n\n:::\n:::\n\nWe end up converting several values to `NA` (notice our warning)\n\n:::\n:::\n\n## [Exercise]{style=\"color:#ccd64d\"}{.background-secondary}\n\n<br>\n\n### Take 1 minute to convert `tch_yrs` to numeric\n\n1. Navigate to Exercise 7.\n2. Review the current variable type for `tch_yrs`.\n3. Edit the code and convert the variable type to numeric.\n4. Review the new variable type for `tch_yrs`.\n\n::: {.cell}\n::: {.cell-output-display}\n\n```{=html}\n<div class=\"countdown\" id=\"timer_d456027d\" data-update-every=\"1\" tabindex=\"0\" style=\"right:0;bottom:0;--countdown-font-size:2em;\">\n<div class=\"countdown-controls\"><button class=\"countdown-bump-down\">&minus;</button><button class=\"countdown-bump-up\">&plus;</button></div>\n<code class=\"countdown-time\"><span class=\"countdown-digits minutes\">01</span><span class=\"countdown-digits colon\">:</span><span class=\"countdown-digits seconds\">00</span></code>\n</div>\n```\n\n:::\n:::\n\n## Recode variables\n\nCommon functions for recoding values are\n\n- `dplyr::case_when()`\n- `dplyr::recode()`\n- `tidyr::replace_na()`\n\n<br>\n\n::: columns\n::: {.column width=\"50%\"}\n\n::: {.cell}\n\n```{.r .cell-code}\ndf |>\n  mutate(newvar = \n           recode(oldvar,\n                  oldvalue = newvalue))\n```\n:::\n\n- If the oldvalue is numeric, it requires ticks around the number, e.g., \\`5\\`\n- If either the oldvalue or newvalue is character use quotation marks, e.g., \"yes\", \n\n:::\n\n::: {.column width=\"50%\"}\n\n::: {.cell}\n\n```{.r .cell-code}\ndf |> \n  mutate(newvar = \n           replace_na(oldvar, \n                      replace = newvalue))\n```\n:::\n\n:::\n:::\n\n## Recode variables\n\n<br>\n\n`dplyr::across()` allows you to apply the same transformation across multiple columns  \n\n- This can be used in `case_when()`, `recode()`, or `replace_na()`\n\n<br>\n\n::: {.cell}\n\n```{.r .cell-code}\ndf |>\n  mutate(across(var1:var3, \n                  ~ replace_na(., replace = 0)))\n```\n:::\n\nThis will save over existing variables.  \n\n- If you don't want to save over the existing variables, you can add the argument *.names* which lives in the `dplyr::across()` function. This creates new variables with new names.\n\n## [Exercise]{style=\"color:#ccd64d\"}{.background-secondary}\n\n<br>\n\n### Take 2 minutes to recode variables\n\n1. Navigate to Exercise 8.\n2. Update the code to recode the blank values for the `grade` variables.  \n    - Check to see if the recoding worked.\n3. Update the code to recode the `mathanx` variable.  \n    - Check to see that the recoding worked.\n\n::: {.cell}\n::: {.cell-output-display}\n\n```{=html}\n<div class=\"countdown\" id=\"timer_f1417780\" data-update-every=\"1\" tabindex=\"0\" style=\"right:0;bottom:0;--countdown-font-size:2em;\">\n<div class=\"countdown-controls\"><button class=\"countdown-bump-down\">&minus;</button><button class=\"countdown-bump-up\">&plus;</button></div>\n<code class=\"countdown-time\"><span class=\"countdown-digits minutes\">02</span><span class=\"countdown-digits colon\">:</span><span class=\"countdown-digits seconds\">00</span></code>\n</div>\n```\n\n:::\n:::\n\n## Construct new variables\n\n- The most important function for constructing new variables is `dplyr::mutate()`\n\n- From there, other functions may be required. For today, we are going to use `rowSums()` which allows us to create sum scores for each row\n\n<br>\n\n::: columns\n::: {.column width=\"50%\"}\n\nThe default is to **not** calculate a sum if there are any `NA` values\n\n::: {.cell}\n\n```{.r .cell-code}\ndf |>\n  mutate(newvar = rowSums(\n    across(var1:var3)))\n```\n:::\n\n:::\n\n::: {.column width=\"50%\"}\n\nIf you want to calculate a sum even if there are NA values, add *na.rm = TRUE*\n\n::: {.cell}\n\n```{.r .cell-code}\ndf |>\n  mutate(newvar = rowSums(\n    across(var1:var3), na.rm = TRUE))\n```\n:::\n\n:::\n:::\n\n## [Exercise]{style=\"color:#ccd64d\"}{.background-secondary}\n\n<br>\n\n### Take 1 minute to construct `gad_sum`\n\n1. Navigate to Exercise 9.\n2. Update the code to calculate `gad_sum`\n3. Review summary information for the new variable.\n\n::: {.cell}\n::: {.cell-output-display}\n\n```{=html}\n<div class=\"countdown\" id=\"timer_26c69e49\" data-update-every=\"1\" tabindex=\"0\" style=\"right:0;bottom:0;--countdown-font-size:2em;\">\n<div class=\"countdown-controls\"><button class=\"countdown-bump-down\">&minus;</button><button class=\"countdown-bump-up\">&plus;</button></div>\n<code class=\"countdown-time\"><span class=\"countdown-digits minutes\">01</span><span class=\"countdown-digits colon\">:</span><span class=\"countdown-digits seconds\">00</span></code>\n</div>\n```\n\n:::\n:::\n\n## Validate data\n\n::: columns\n::: {.column width=\"60%\"}\n\n- Create tables of information\n  - `dplyr::count()`, `janitor::tabyl()`\n- Create graphs\n  - `ggplot2`\n- Calculate summary statistics\n  - All of the functions from \"Review the data\" section\n- Create codebooks\n  - `codebookr`, `memisc`, `sjPlot`\n- Create tests that pass/fail based on a set of criteria\n  - **`pointblank`**, `validate`, `assertr`, `dataquieR`\n\n\n:::\n\n::: {.column width=\"40%\"}\n\n![](images/codebook.PNG){fig-align=\"center\"}\n\n:::\n:::\n\n:::{.notes}\n\n- There are many ways to validate data based on data quality criteria\n\n- Codebooks, which can be exported to things like word or text documents, provide univariate summary statistics about your data. It just gives you a nice easy to read summary of what is happening in your data.\n\n- You most likely want to do a combination of these things in your validation process\n\n:::\n## Validate data\n\n::: panel-tabset\n\n### Create our validation criteria\n\nHere we are using the [pointblank](https://rstudio.github.io/pointblank/reference/index.html) package to develop some validation tests\n\n<br>\n\n::: {.cell}\n\n:::\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncreate_agent(df) |>\n  rows_distinct(columns = vars(stu_id)) |>\n  col_vals_not_null(columns = vars(stu_id)) |>\n  col_vals_between(columns = vars(stu_id), left = 300, right = 500, na_pass = FALSE) |>\n  col_is_numeric(columns = vars(age, test_score)) |>\n  col_vals_between(columns = vars(test_score), left = 0, right = 500, na_pass = TRUE) |>\n  interrogate()\n```\n:::\n\n### Review the report\n\n![](images/pointblank.PNG){fig-align=\"center\"}\n\n:::\n\n## [Exercise]{style=\"color:#ccd64d\"}{.background-secondary}\n\n<br>\n\n### Take 5 minutes to validate our data\n\n1. Navigate to Exercise 10.\n2. Run the validation code.\n    - Do all of our tests pass?\n3. Update the code with one more validation criteria. Run the code again.\n    - Do all of our tests still pass?\n\n::: {.cell}\n::: {.cell-output-display}\n\n```{=html}\n<div class=\"countdown\" id=\"timer_24db20bf\" data-update-every=\"1\" tabindex=\"0\" style=\"right:0;bottom:0;--countdown-font-size:2em;\">\n<div class=\"countdown-controls\"><button class=\"countdown-bump-down\">&minus;</button><button class=\"countdown-bump-up\">&plus;</button></div>\n<code class=\"countdown-time\"><span class=\"countdown-digits minutes\">05</span><span class=\"countdown-digits colon\">:</span><span class=\"countdown-digits seconds\">00</span></code>\n</div>\n```\n\n:::\n:::\n\n## Export data\n\nSimilar to importing data, we have many options for exporting our data depending on the format we want to export to.\n\n- `openxlsx::write.xlsx()`\n- `haven::write_sav()`, `haven::write_dta()`, `haven::write_sas()`\n- `readr::write_csv()`\n    - x \n      - The object we are exporting\n    - file\n      - The name of the new file **plus any folders** where you want the file to live\n    - na = \"NA\"\n    \n::: {.cell}\n\n```{.r .cell-code}\nwrite_csv(df, file = \"data/w1_stu_obs_clean.csv\", na = \"\")\n```\n:::\n\n## [Exercise]{style=\"color:#ccd64d\"}{.background-secondary}\n\n<br>\n\n### Take 2 minutes to export our data\n\n1. Navigate to Exercise 11.\n2. Update our code to export the clean data file to our \"data\" folder.\n3. Once exported, download and open the file to confirm it looks as expected.\n\n::: {.cell}\n::: {.cell-output-display}\n\n```{=html}\n<div class=\"countdown\" id=\"timer_552115bf\" data-update-every=\"1\" tabindex=\"0\" style=\"right:0;bottom:0;--countdown-font-size:2em;\">\n<div class=\"countdown-controls\"><button class=\"countdown-bump-down\">&minus;</button><button class=\"countdown-bump-up\">&plus;</button></div>\n<code class=\"countdown-time\"><span class=\"countdown-digits minutes\">02</span><span class=\"countdown-digits colon\">:</span><span class=\"countdown-digits seconds\">00</span></code>\n</div>\n```\n\n:::\n:::\n\n## Coding best practices\n\n::: columns\n::: {.column width=\"60%\"}\n\n1. Use a coding template\n2. Follow a coding style guide\n    - The [tidyverse style guide](https://style.tidyverse.org/syntax.html)\n3. Use relative file paths\n    - ❌ \"C:/Users/Crystal/Desktop/project/data/raw_file.csv\"\n    - ✔️ \"data/raw_file.csv\"\n4. Write all cleaning steps in code\n5. Comment every step in your code\n6. Check all of your work throughout\n7. If possible, have someone else review your code\n\n:::\n\n::: {.column width=\"40%\"}\n\n![](images/code_template.PNG){fig-align=\"center\"}\n\n:::\n:::\n\n:::{.notes}\n\nThat will just help ensure that your code is more readable, usable, and reproducible in the future. \n\n- your chain of processing is lost, and your work is no longer reproducible\n\nYou may have noticed that throughout these exercises, that we always performed a check to make sure that the transformation worked as expected\n\n:::\n\n## Versioning\n\n1. Version your code (\"sample_tch_svy_cleaning_v01.R\")\n2. Version your files (\"sample_tch_svy_clean_v01.csv\")\n3. Make notes in a changelog.\n\n![](images/changelog.PNG){fig-align=\"center\"}\n\n\n# Documentation for Data Sharing {.background-secondary}\n\n\n## Types of documentation\n\n::: columns\n::: {.column width=\"50%\"}\n\n<br>\n\n1. Project-level documentation\n    - Project summary document\n\n2. Data-level documentation\n    - README\n    - Cleaning code/Data cleaning plan\n\n3. Variable-level documentation\n    - Data dictionary OR\n    - Codebook\n\n4. Repository Metadata\n\n:::\n\n::: {.column width=\"50%\"}\n\n\n<br>\n\n<br>\n\n✔️ Allows your data to be correctly interpreted and used\n\n<br>\n\n✔️ Allows your work to be reproducible\n\n<br>\n\n✔️ Allows your work to be findable\n\n:::\n:::\n\n:::{.notes}\n\nAlways share some sort of documentation along with your file\n\nEven if you have the most pristine data file, users have no context for that file\n\nWhat project this data is associated with, how data was collected and who it was collected on, any transformations done to data, what variables represent\n\n:::\n\n\n## Project-level documentation\n\n::: columns\n::: {.column width=\"50%\"}\n\n- Funding source\n- Overview of study\n- Setting and sample\n- Project timeline\n- Measures used\n- Overview of study procedures\n  - Recruitment, consent, data collection \n- Data preparation and processing\n  - Data quality monitoring, de-identification procedures, decision rules\n- Appendices\n  - Copies of instruments, consort diagrams\n:::\n\n::: {.column width=\"50%\"}\n\n![](images/project_summary.PNG){fig-align=\"center\" width=\"75%\"}\n\n:::\n:::\n\n:::{.notes}\n\nThis would be where you could document your decision rules for things dropping duplicates\n\n:::\n\n## Data-level documentation\n\n::: columns\n::: {.column width=\"50%\"}\n\n\nREADME\n\n![](images/readme.PNG){fig-align=\"center\"}\n\n:::\n\n::: {.column width=\"50%\"}\n\nData Cleaning Plan\n\n![](images/data_cleaning_plan2.PNG){fig-align=\"center\"}\n\n:::\n:::\n\n## Variable-level documentation\n\n::: columns\n::: {.column width=\"50%\"}\n\nData dictionary\n\n![](images/dictionary.PNG){fig-align=\"center\"}\n\n:::\n\n::: {.column width=\"50%\"}\n\n\nCodebook\n\n![](images/codebook.PNG){fig-align=\"center\"}\n\n:::\n:::\n\n\n## Repository Metadata\n\n::: columns\n::: {.column width=\"50%\"}\n\n![](images/osf_project.PNG){fig-align=\"center\"}\n\n:::\n\n::: {.column width=\"50%\"}\n\n![](images/repository_metadata.PNG){fig-align=\"center\" width=\"90%\"}\n\n:::\n:::\n\n::: footer\n\n[Example Project Open Data Sharing](https://osf.io/59gte/)\n\n:::\n\n## Thank you! {.background-secondary}\n\n<br>\n\n🌟  **Please provide feedback on this workshop using this short survey.**   \n[https://forms.gle/qVTvVgP8nafbAuXT8](https://forms.gle/qVTvVgP8nafbAuXT8)\n\n<br>\n\n🌟 **Stay connected!**\n\n{{< fa link size=xl >}} [https://cghlewis.com/](https://cghlewis.com/)   \n{{< fa brands linkedin size=xl >}}    [https://www.linkedin.com/in/crystal-lewis-922b4193/](https://www.linkedin.com/in/crystal-lewis-922b4193/)   \n{{< fa brands github size=xl >}}  [https://github.com/Cghlewis](https://github.com/Cghlewis)  \n\n\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<link href=\"../site_libs/countdown-0.5.0/countdown.css\" rel=\"stylesheet\" />\n<script src=\"../site_libs/countdown-0.5.0/countdown.js\"></script>\n"
      ],
      "include-after-body": [
        "\n<script>\n  // htmlwidgets need to know to resize themselves when slides are shown/hidden.\n  // Fire the \"slideenter\" event (handled by htmlwidgets.js) when the current\n  // slide changes (different for each slide format).\n  (function () {\n    // dispatch for htmlwidgets\n    function fireSlideEnter() {\n      const event = window.document.createEvent(\"Event\");\n      event.initEvent(\"slideenter\", true, true);\n      window.document.dispatchEvent(event);\n    }\n\n    function fireSlideChanged(previousSlide, currentSlide) {\n      fireSlideEnter();\n\n      // dispatch for shiny\n      if (window.jQuery) {\n        if (previousSlide) {\n          window.jQuery(previousSlide).trigger(\"hidden\");\n        }\n        if (currentSlide) {\n          window.jQuery(currentSlide).trigger(\"shown\");\n        }\n      }\n    }\n\n    // hookup for slidy\n    if (window.w3c_slidy) {\n      window.w3c_slidy.add_observer(function (slide_num) {\n        // slide_num starts at position 1\n        fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);\n      });\n    }\n\n  })();\n</script>\n\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}