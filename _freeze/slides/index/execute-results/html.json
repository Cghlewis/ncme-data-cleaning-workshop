{
  "hash": "7c2a379c6bbd1b86f15f95fe7ecb1e56",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Data Cleaning for Data Sharing<br> Using R\"\nauthor: \"Crystal Lewis // April 11, 2024<br>NCME Annual Meeting\"\nfooter: \"Data Cleaning for Data Sharing // [Cghlewis.github.io/ncme-data-cleaning-workshop/](https://Cghlewis.github.io/ncme-data-cleaning-workshop/)\"\nlogo: \"images/NCME-AnnualMeeting2024Logo-F.png\"\nformat: \n  revealjs: \n    width: 1600\n    height: 900  \n    theme: slides.scss\n    highlight-style: a11y\n    transition: fade\n    slide-number: true\nexecute:\n  echo: true\n---\n\n::: {.cell}\n\n:::\n\n## Schedule\n\n<br>\n\n\n| Time          | Topic           |\n|---------------|--------------------|\n|8:45 - 9:00  |   Intro/Logistics | \n|9:00 - 9:45 | Fundamentals of Data Organization|\n|9:45 - 10:30 | Standardized Data Cleaning Checklist|\n|10:30 - 10:45 | Break|\n|10:45 - 12:30 | Data Cleaning Functions|\n|12:30 - 12:45 | Documentation for Data Sharing|\n\n  \n## Logistics\n\n**Materials**\n\n[Cghlewis.github.io/ncme-data-cleaning-workshop/](https://Cghlewis.github.io/ncme-data-cleaning-workshop/)\n\n<br>\n\n**Exercises**\n\nLogin to Posit Cloud workspace: [**https://posit.cloud/content/7872027**](https://posit.cloud/content/7872027).\n\n. . .\n\n<br>\n\nIf Posit Cloud doesn't work, download materials locally:\n\n::: {.cell}\n\n```{.r .cell-code}\nusethis::use_course(\n    \"https://github.com/Cghlewis/ncme-data-cleaning-workshop/raw/main/exercises/exercises.zip\",\n    destdir = \"___\")\n```\n:::\n\n. . .\n\n<br>\n\nFeel free to interrupt me with questions/comments at any time âœ‹.\n\n<br>\n\nGet up and move around as much as you need to ðŸš¶.\n  \n::: {.notes}\n- All materials for the workshop can be found at this website. \n  - Link also lives at the bottom of these slides\n\n- Hands on exercises in R in the second half of this workshop \n  - Posit Cloud trouble shoot\n  - If you have any trouble logging into Posit Cloud\n\n- If Posit Cloud is a total failure, you should also be able to download the materials \n\n- And then I really hope that today will be a very relaxed environment.\n\n:::\n\n## About the Speaker\n\n::: columns\n::: {.column width=\"50%\"}\n\n- Independent Research Data Management Consultant\n   - [cghlewis.com](https://cghlewis.com/)\n- Previously data manager for the Missouri Prevention Science Institute\n- Co-organizer for R-Ladies St. Louis\n  - [meetup.com/rladies-st-louis](https://www.meetup.com/rladies-st-louis/)\n- Co-organizer for the POWER Data Management in Education Research Hub\n  - [https://osf.io/ap3tk/](https://osf.io/ap3tk/)\n- Author *Data Management in Large-Scale Education Research*\n  - [datamgmtinedresearch.com](https://datamgmtinedresearch.com/)\n\n:::\n \n::: {.column width=\"50%\"}\n![](images/book-cover.jpg){fig-align=\"center\" width=60%}\n\n:::\n:::\n\n::: {.notes}\n- Independent research data management consultant\n  - This means I work for myself. \n\n- Prior to this I worked for the MPSI for 8 years \n\n- I'm also a co-organization for two organizations. \n  - whose mission it is to promote gender diversity in the R community. \n  - We organize monthly meetups\n\n- I also organize the POWER Data Management in Education Research Hub.\n  - Our smaller hub is particularly focused on sharing knowledge around data management issues in education research.\n\n- And then probably the most noteworthy thing about me right now is that I recently finished writing this book\n\n:::\n\n## Introductions\n\n::: columns\n::: {.column width=\"40%\"}\n\n- Your name\n- Your affiliation\n- Your role\n- Your data cleaning experience\n- Your experience with R\n\n:::\n \n::: {.column width=\"60%\"}\n![Image from [Unsplash](https://unsplash.com/photos/brown-and-black-short-coated-small-dog-with-white-long-coat-small-dog-on-gray-concrete-NIKl5WwL-RE)](images/greeting.jpg){fig-align=\"center\"}\n:::\n:::\n\n\n## 3 Phases of Data\n\n![](images/phases.jpg){fig-align=\"center\"}\n\n::: {.notes}\n\n- So, before we begin, I want to clarify what we will be talking about today. So in terms of data, there are typically 3 phases.\n\n- First, there is raw data. And I am defining raw data as data that comes directly from a source.     - That source could be original data \n    - What makes it raw, no transformations\n    - You simply downloaded \n    - And the thing about this raw data is that it usually is messy AND it usually (in the world of education research) contains some identifying information. And we often can't share this outside of our research team.\n\n- Next, we have the clean data. And this is the data that we will be talking about today. \n   - This is the data we typically share \n   - This data is still in its true, raw form, but has been de-identified and minimally altered to allow the data to be correctly interpreted. \n   - entire study sample (no outliers have been removed), all missing data is still labelled as missing (no imputation is done), and no analysis-specific variables are calculated. \n\n- Last, we have all of these analytic datasets. \n  - These are datasets that are created from the general clean dataset and contain further manipulations that are done for a specific analysis\n  - These datasets will typically also be publicly shared in a repository\n  - But these datasets are analysis specific and are not going to be part of the data cleaning process we are discussing today.\n\n:::\n\n## A Sampling of Open Datasets\n\n::: {.r-stack}\n\n\n![](images/publicdata5.PNG){.fragment}\n\n\n![](images/publicdata2.PNG){.fragment}\n\n\n![](images/publicdata1-1.PNG){.fragment}\n\n\n![](images/publicdata6.PNG){.fragment}\n\n\n![](images/publicdata4.PNG){.fragment}\n\n\n:::\n\n::: {.notes}\n\nSo in preparation for this workshop, I went through several public repositories and found a sampling of shared datasets. Let me show you some of them.\n\nWhat do you notice when you look at these different datasets?\n\nThere is no real consistency in how data is structured, variables are named, or how information is coded. And this is a problem because it makes reuse of this data very difficult.\n\nData don't necessarily have to be identically formatted. Different variable naming conventions can be used, different coding schemes can be used. But there are several data quality standards that all data should adhere to in order to allow data to be interpretable and usable, and that is what we are going to talk about today.\n\n:::\n\n## Learning Objectives\n\n::: incremental\n\n1.  Understand how to assess a data set for 7 data quality indicators\n\n<br>\n\n2.  Be able to review a data set and apply a list of standardized data cleaning steps as needed\n\n<br>\n\n3.  Feel comfortable using R code to clean a data set using our standardized steps\n\n<br>\n\n4.  Understand types of documentation that should be shared alongside data\n\n:::\n\n\n# Data Quality Indicators {.background-secondary}\n\n## The Data are Ready\n\n![](images/data-ready.PNG){fig-align=\"center\" width=\"80%\"}\n\n::: {.notes}\n\nHas anyone here ever had someone give them a dataset that they've said is good to go, but then you open the data and it looks something like this? Just a mess.\n\nI feel like this happens to me on a weekly basis.\n\nSo today we are going to review a standard set of data quality indicators that we can use to determine if a dataset is really ready to be shared or not.\n\n:::\n\n## 7 Data Quality Indicators\n\n::: columns\n::: {.column width=\"40%\"}\n\n<br>\n\n1. Analyzable\n\n2. Interpretable\n\n3. Complete\n\n4. Valid\n\n5. Accurate\n\n6. Consistent\n\n7. De-identified\n\n\n:::\n \n::: {.column width=\"60%\"}\n\n![Taming the Data Beast, by Allison Horst](images/data_beast_allison_horst.jpeg)\n\n:::\n:::\n\n## Analyzable\n\n- Data should make a rectangle of rows and columns\n  - The first row, and only the first row, is your variable names\n  - The remaining data should be made up of values in cells\n  - At least one column uniquely defines the rows in the data (e.g., unique identifier)\n\n![](images/quality-analyze1.PNG){fig-align=\"center\"}\n\n::: {.notes}\n\nSo first and foremost, data needs to make a rectangle. This rectangle shape is how machines read data.\n\n- short representation of the information contained in a column.\n\n\n:::\n\n## Analyzable\n\n- Column values are analyzable\n  - Information is explicit\n  \n![](images/quality-analyze2.PNG){fig-align=\"center\" width=\"70%\"}\n\n::: {.notes}\n\nAnother rule of analyzable data is that information is explicit, not implicit. This means unless data is actually missing, there should be no blanks in your data. They should be filled with the applicable values.\n\n:::\n\n## Analyzable\n\n<br>\n\n![](images/quality-analyze3.PNG){fig-align=\"center\"}\n\n::: {.notes}\n\nAnother example of data that is not explicit is when color coding is used. Here, color coding is used to indicate study treatment groups. However, machines cannot interpret color codes. This information needs to be defined in a variable with values assigned for each group.\n\n:::\n\n## Analyzable\n\n- Only one piece of information is collected per variable\n\n![](images/quality-analyze4.PNG){fig-align=\"center\"}\n\n::: {.notes}\n\nAnd then last, for data to be analyzable, you should only collect one piece of information per variable. In this example, a rate variable has been included the data where the numerator is the number of incidents and the denominator is the total number of students in the school. But it is difficult to work with combined information. It's much better to separate those pieces of information into their own variables and then you can aggregate information as needed.\n\n:::\n\n\n\n## [Exercise]{style=\"color:#ccd64d\"}{.background-secondary}\n\n<br>\n\nWhat data quality issues do you detect for the \"analyzable\" indicator?\n\n![](images/example-data.PNG){fig-align=\"center\"}\n\n\n::: {.cell}\n::: {.cell-output-display}\n\n```{=html}\n<div class=\"countdown\" id=\"timer_e3472ab7\" data-update-every=\"1\" tabindex=\"0\" style=\"right:0;bottom:0;--countdown-font-size:2em;\">\n<div class=\"countdown-controls\"><button class=\"countdown-bump-down\">&minus;</button><button class=\"countdown-bump-up\">&plus;</button></div>\n<code class=\"countdown-time\"><span class=\"countdown-digits minutes\">01</span><span class=\"countdown-digits colon\">:</span><span class=\"countdown-digits seconds\">00</span></code>\n</div>\n```\n\n:::\n:::\n\n## [Solution]{style=\"color:#ccd64d\"}{.background-secondary}\n\n- Data does not make a rectangle\n- Color coding used to convey information\n- More than one piece of information in a variable\n- Blank values implied to be 0 for `Q4`{style=\"color:#ccd64d\"} variables\n\n\n![](images/quality-exercise1.PNG){fig-align=\"center\"}\n\n## Interpretable\n\n::: columns\n::: {.column width=\"50%\"}\n\n\n- Variable names should be machine-readable\n  - Unique\n  - No spaces or special characters except `_`\n    - This includes no `.` or `-`\n  - Not begin with a number\n  - Character limit of 32\n  \n\n- Variable names should be human-readable\n  - Meaningful (`gender` instead of `Q1`)\n  - Consistently formatted (capitalization and delimiters)\n  - Consistent order of information\n    - `wave_responder_scale#` (`w1_t_mast1`)\n\n:::\n \n::: {.column width=\"50%\"}\n\n![In that case, by Allison Horst](images/naming_case.jpg)\n\n:::\n:::\n\n\n::: {.notes}\n\n- First interpretable applies to your variable names\n\n- Even dashes are not allowed because R reads them as minus signs\n- While periods are allowed in R, they aren't in other languages like Stata so it's best to avoid them.\n\n- Most statistical programs are case sensitive so if you are inconsistent with things like delimiters and capitalization, it just makes it so much more difficult to work with your data.\n\n:::\n\n## Interpretable\n\n- When publicly sharing data, it is recommended to share data in at least one non-proprietary format (e.g., CSV)\n  - But if you would also like to share a copy in a commonly used format such as SPSS, SAS, or Stata, consider adding embedded metadata (i.e., **variable label** and **value labels**)\n  \n![](images/quality-interpret1.PNG){fig-align=\"center\"}\n\n::: {.notes}\n\n- But interpretable can also apply to other formatting\n\n- Because that can really help with interpretation. Rather than having to flip back and forth to the data dictionary to see what codes mean or what a variable represents, the information lives within the dataset and can be accessed as needed.\n\n:::\n\n## [Exercise]{style=\"color:#ccd64d\"}{.background-secondary}\n\n<br>\n\nWhat data quality issues do you detect for the \"interpretable\" indicator?\n\n![](images/example-data.PNG){fig-align=\"center\"}\n\n::: {.cell}\n::: {.cell-output-display}\n\n```{=html}\n<div class=\"countdown\" id=\"timer_31c1f0bd\" data-update-every=\"1\" tabindex=\"0\" style=\"right:0;bottom:0;--countdown-font-size:2em;\">\n<div class=\"countdown-controls\"><button class=\"countdown-bump-down\">&minus;</button><button class=\"countdown-bump-up\">&plus;</button></div>\n<code class=\"countdown-time\"><span class=\"countdown-digits minutes\">01</span><span class=\"countdown-digits colon\">:</span><span class=\"countdown-digits seconds\">00</span></code>\n</div>\n```\n\n:::\n:::\n\n## [Solution]{style=\"color:#ccd64d\"}{.background-secondary}\n\n- Spaces and special characters used in variable names\n- Some variable names are unclear\n- Inconsistent use of capitalization\n\n![](images/quality-exercise2.PNG){fig-align=\"center\"}\n\n## Complete\n\n- Cases\n  - The number of rows in your dataset should total to your sample N\n    - No missing cases\n    - No duplicate cases (i.e., no unique identifier)\n    \n- Variables\n  - The number of columns in your dataset should total to what you planned to have\n    - No missing variables\n  - No unexpected missing data\n    - If you collected the data, it should exist in the dataset\n\n## Complete\n\n#### Tracking Database\n\n![](images/quality-complete1.PNG){fig-align=\"center\"}\n\n#### Data Dictionary\n\n![](images/quality-complete2.PNG){fig-align=\"center\"}\n\n::: {.notes}\n\nTwo documents that can be helpful for verifying if you have complete data are a participant tracking database and a data dictionary.\n\nA participant tracking database is a spreadsheet or database where a project coordinator tracks what is collected in a study for each participant. Depending on your role in the study, you may or may not have access to this type of database. If you do not, you are just going to have to trust that you have been given a dataset that includes the entire sample.\n\nA data dictionary is something you hopefully always have access to though and this should list out exactly what variables exist in a dataset and what those variables represent.\n\nBoth of these documents are excellent resources for determining if you have a complete dataset.\n\n:::\n\n## [Exercise]{style=\"color:#ccd64d\"}{.background-secondary}\n\n<br>\n\nWhat data quality issues do you detect for the \"complete\" indicator?\n\n![](images/example-data.PNG){fig-align=\"center\"}\n\n::: {.cell}\n::: {.cell-output-display}\n\n```{=html}\n<div class=\"countdown\" id=\"timer_6385b3fa\" data-update-every=\"1\" tabindex=\"0\" style=\"right:0;bottom:0;--countdown-font-size:2em;\">\n<div class=\"countdown-controls\"><button class=\"countdown-bump-down\">&minus;</button><button class=\"countdown-bump-up\">&plus;</button></div>\n<code class=\"countdown-time\"><span class=\"countdown-digits minutes\">01</span><span class=\"countdown-digits colon\">:</span><span class=\"countdown-digits seconds\">00</span></code>\n</div>\n```\n\n:::\n:::\n\n::: {.notes}\n\nHere we don't have access to a tracking database or a data dictionary but there is still something we can catch in this dataset without those documents.\n\n:::\n\n## [Solution]{style=\"color:#ccd64d\"}{.background-secondary}\n\n- The data contain a duplicate ID (104)\n\n![](images/quality-exercise3.PNG){fig-align=\"center\"}\n\n## Valid\n\n- Variables conform to the planned constraints\n  - Planned variable types (e.g., `numeric`, `character`, `date`)\n  - Allowable variable values and ranges (e.g., `1-5`)\n  - Item-level missingness aligns with variable universe rules and skip patterns\n  \n![](images/quality-valid1.PNG){fig-align=\"center\"}\n\n\n## Valid\n\n![](images/quality-valid2.PNG){fig-align=\"center\"}\n\n::: {.notes}\n\nAgain, the data dictionary is going to be a really important document in determining if data is valid because the dicionary defines all of the constraints that need to be checked.\n\n:::\n\n## [Exercise]{style=\"color:#ccd64d\"}{.background-secondary}\n\n<br>\n\nWhat data quality issues do you detect for the \"valid\" indicator?\n\n![](images/example-data.PNG){fig-align=\"center\"}\n\n::: {.cell}\n::: {.cell-output-display}\n\n```{=html}\n<div class=\"countdown\" id=\"timer_85963fe2\" data-update-every=\"1\" tabindex=\"0\" style=\"right:0;bottom:0;--countdown-font-size:2em;\">\n<div class=\"countdown-controls\"><button class=\"countdown-bump-down\">&minus;</button><button class=\"countdown-bump-up\">&plus;</button></div>\n<code class=\"countdown-time\"><span class=\"countdown-digits minutes\">01</span><span class=\"countdown-digits colon\">:</span><span class=\"countdown-digits seconds\">00</span></code>\n</div>\n```\n\n:::\n:::\n\n::: {.notes}\n\nAgain we don't have a data dictionary for this example...\n\n:::\n\n## [Solution]{style=\"color:#ccd64d\"}{.background-secondary}\n\n- `AGE/YR`{style=\"color:#ccd64d\"} does not adhere to our planned variable type\n- Values in `Score`{style=\"color:#ccd64d\"} fall out of our expected range\n\n![](images/quality-exercise4.PNG){fig-align=\"center\"}\n\n\n## Accurate\n\n- Information should be accurate based on any implicit knowledge you have\n  - For instance, values should not exist for a school where you know that data was not collected that wave\n\n- Accurate within and across sources\n  - A date of birth collected from school records should match the date of birth provided by the student\n  - If a student is in 2nd grade, they should be associated with a second grade teacher\n  \n::: {.notes}\n\nSo accuracy can be a tough thing to judge, but depending on your level of involvement in the study, you may have some implicit knowledge you can use to judge accuracy.\n\n:::\n  \n## [Exercise]{style=\"color:#ccd64d\"}{.background-secondary}\n\n<br>\n\nWhat data quality issues do you detect for the \"accurate\" indicator?\n\n![](images/example-data.PNG){fig-align=\"center\"}\n\n::: {.cell}\n::: {.cell-output-display}\n\n```{=html}\n<div class=\"countdown\" id=\"timer_89906313\" data-update-every=\"1\" tabindex=\"0\" style=\"right:0;bottom:0;--countdown-font-size:2em;\">\n<div class=\"countdown-controls\"><button class=\"countdown-bump-down\">&minus;</button><button class=\"countdown-bump-up\">&plus;</button></div>\n<code class=\"countdown-time\"><span class=\"countdown-digits minutes\">01</span><span class=\"countdown-digits colon\">:</span><span class=\"countdown-digits seconds\">00</span></code>\n</div>\n```\n\n:::\n:::\n\n::: {.notes}\n\nSo in this case we don't have any implicit knowledge, but by comparing pieces of information within the dataset, what data quality issues do you see for the accurate indicator here?\n\n:::\n\n## [Solution]{style=\"color:#ccd64d\"}{.background-secondary}\n\n- ID 105 has conflicting information for `TEACHING LEVEL`{style=\"color:#ccd64d\"} and `SCHOOL`{style=\"color:#ccd64d\"}\n\n![](images/quality-exercise5.PNG){fig-align=\"center\"}\n\n## Consistent\n\n- Variable values are consistently measured, formatted, or categorized within a column\n\n- Variables are consistently measured across collections of the same form\n\n![](images/quality-consistent1.PNG){fig-align=\"center\"}\n\n::: {.notes}\n\nAnd the reason that this consistency matters is that a computer doesn't know that three different spellings of yes are all still yes. It will think these are 3 different things.\n\n:::\n\n\n## [Exercise]{style=\"color:#ccd64d\"}{.background-secondary}\n\n<br>\n\nWhat data quality issues do you detect for the \"consistent\" indicator?\n\n![](images/example-data.PNG){fig-align=\"center\"}\n\n::: {.cell}\n::: {.cell-output-display}\n\n```{=html}\n<div class=\"countdown\" id=\"timer_95403110\" data-update-every=\"1\" tabindex=\"0\" style=\"right:0;bottom:0;--countdown-font-size:2em;\">\n<div class=\"countdown-controls\"><button class=\"countdown-bump-down\">&minus;</button><button class=\"countdown-bump-up\">&plus;</button></div>\n<code class=\"countdown-time\"><span class=\"countdown-digits minutes\">01</span><span class=\"countdown-digits colon\">:</span><span class=\"countdown-digits seconds\">00</span></code>\n</div>\n```\n\n:::\n:::\n\n## [Solution]{style=\"color:#ccd64d\"}{.background-secondary}\n\n- Values for `GENDER`{style=\"color:#ccd64d\"} are not consistently categorized\n\n![](images/quality-exercise6.PNG){fig-align=\"center\"}\n\n## De-identified\n\n![](images/quality-identify1.PNG){fig-align=\"center\"}\n\n::: {.notes}\n\nIn the world of education research we are often working with human subjects and we often promise those subjects that their identifying information will remain private\n\nDirect identifiers are unique to an individual and can be used alone to identify a participant. \n\nIndirect identifiers however are not necessarily unique to a particular individual, but if combined with other information they could be used to identify a participant.\n\n  - age + gender + education level\n  - 50 + female + PhD\n  - itâ€™s possible that someone could use that information to identify someone in a dataset\n\n:::\n\n## De-identified\n\n- Direct identifiers are removed\n\n\n![](images/quality-identify2.PNG){fig-align=\"center\"}\n\n## De-identified\n\n- Open-ended questions\n  - These variables may contain information that can directly or indirectly identify individuals\n- Outliers\n  - If someone has extreme values for a variable, it may be easier to identify that individual\n- Small cell sizes\n  - [NCES Standard 4-2-10](https://nces.ed.gov/pubsearch/pubsinfo.asp?pubid=2003601), suggests that all categories have at least 3 cases to minimize risk\n- Combinations of variables, or crosstabs, can also create small cell-sizes\n  - race + gender + grade level\n\n<br>\n\nðŸš¨ Consider this in the context of risk\n\n- Math assessment may be low risk while a survey on substance use is higher risk\n\n::: {.notes}\n\nBut there is more you need to check for.\n\nYou also need to consider all of this in the context of risk. So if you are collecting information that is fairly innocuous (like maybe it's a math assessment), the risk of harm if your re-identified is pretty low. If you are collecting information like on substance use, the risk is higher because that information could impact your career, relationships, and so forth. \n:::\n\n## [Exercise]{style=\"color:#ccd64d\"}{.background-secondary}\n\n<br>\n\nWhat data quality issues do you detect for the \"de-identified\" indicator?\n\n![](images/example-data.PNG){fig-align=\"center\"}\n\n::: {.cell}\n::: {.cell-output-display}\n\n```{=html}\n<div class=\"countdown\" id=\"timer_6c4757dd\" data-update-every=\"1\" tabindex=\"0\" style=\"right:0;bottom:0;--countdown-font-size:2em;\">\n<div class=\"countdown-controls\"><button class=\"countdown-bump-down\">&minus;</button><button class=\"countdown-bump-up\">&plus;</button></div>\n<code class=\"countdown-time\"><span class=\"countdown-digits minutes\">01</span><span class=\"countdown-digits colon\">:</span><span class=\"countdown-digits seconds\">00</span></code>\n</div>\n```\n\n:::\n:::\n\n::: {.notes}\n\nThis is a very small dataset so don't worry about indirect identifiers right now. Focus more on direct identifiers\n\n:::\n\n## [Solution]{style=\"color:#ccd64d\"}{.background-secondary}\n\n- Replace School Name with an unique ID\n- Review outliers and combination of demographics to see if other alterations are necessary\n\n![](images/quality-exercise7.PNG){fig-align=\"center\"}\n\n\n## Biggest Advice\n\nThe number one way to reduce data errors is to make a plan before you collect data\n\n> Correct data at the source\n\n<br>\n\n. . .\n\n- Plan the variables you want to collect\n\n. . .\n\n- Build your data collection/entry tools in a way that follows your plan\n\n. . .\n\n- Test your data tools before collecting/entering data\n\n. . .\n\n- Check your data often during data collection/entry\n\n::: {.notes}\n\nSo before we move on to how to clean data for the purposes of data sharing, I want to point out one really important thing. And that is, if you are collecting your own original data\n\nDoing this ensures not only that you have much less data cleaning to do in the end, but it also prevents you from potentially losing data or having to recollect bad data. So it's 100% worth the time and effort to spend time planning for quality data collection in the beginning if you can.\n\nBut of course, we are not always in charge of data collection and we just have to deal with the data we are given and so are going to talk about this in the next sections.\n\n:::\n\n# Data Cleaning Checklist {.background-secondary}\n\n## Data Cleaning\n\n![](images/side-by-side-data.PNG){fig-align=\"center\"}\n\n\n## Standard Data Cleaning Checklist\n\n:::: {.columns}\n\n::: {.column width=\"50%\"}\n\n`<svg aria-hidden=\"true\" role=\"img\" viewBox=\"0 0 512 512\" style=\"height:1em;width:1em;vertical-align:-0.125em;margin-left:auto;margin-right:auto;font-size:inherit;fill:currentColor;overflow:visible;position:relative;\"><path d=\"M173.898 439.404l-166.4-166.4c-9.997-9.997-9.997-26.206 0-36.204l36.203-36.204c9.997-9.998 26.207-9.998 36.204 0L192 312.69 432.095 72.596c9.997-9.997 26.207-9.997 36.204 0l36.203 36.204c9.997 9.997 9.997 26.206 0 36.204l-294.4 294.401c-9.998 9.997-26.207 9.997-36.204-.001z\"/></svg>`{=html} Import the raw data\n\n`<svg aria-hidden=\"true\" role=\"img\" viewBox=\"0 0 512 512\" style=\"height:1em;width:1em;vertical-align:-0.125em;margin-left:auto;margin-right:auto;font-size:inherit;fill:currentColor;overflow:visible;position:relative;\"><path d=\"M173.898 439.404l-166.4-166.4c-9.997-9.997-9.997-26.206 0-36.204l36.203-36.204c9.997-9.998 26.207-9.998 36.204 0L192 312.69 432.095 72.596c9.997-9.997 26.207-9.997 36.204 0l36.203 36.204c9.997 9.997 9.997 26.206 0 36.204l-294.4 294.401c-9.998 9.997-26.207 9.997-36.204-.001z\"/></svg>`{=html} Review the raw data\n\n`<svg aria-hidden=\"true\" role=\"img\" viewBox=\"0 0 512 512\" style=\"height:1em;width:1em;vertical-align:-0.125em;margin-left:auto;margin-right:auto;font-size:inherit;fill:currentColor;overflow:visible;position:relative;\"><path d=\"M173.898 439.404l-166.4-166.4c-9.997-9.997-9.997-26.206 0-36.204l36.203-36.204c9.997-9.998 26.207-9.998 36.204 0L192 312.69 432.095 72.596c9.997-9.997 26.207-9.997 36.204 0l36.203 36.204c9.997 9.997 9.997 26.206 0 36.204l-294.4 294.401c-9.998 9.997-26.207 9.997-36.204-.001z\"/></svg>`{=html} Find missing data\n\n`<svg aria-hidden=\"true\" role=\"img\" viewBox=\"0 0 512 512\" style=\"height:1em;width:1em;vertical-align:-0.125em;margin-left:auto;margin-right:auto;font-size:inherit;fill:currentColor;overflow:visible;position:relative;\"><path d=\"M173.898 439.404l-166.4-166.4c-9.997-9.997-9.997-26.206 0-36.204l36.203-36.204c9.997-9.998 26.207-9.998 36.204 0L192 312.69 432.095 72.596c9.997-9.997 26.207-9.997 36.204 0l36.203 36.204c9.997 9.997 9.997 26.206 0 36.204l-294.4 294.401c-9.998 9.997-26.207 9.997-36.204-.001z\"/></svg>`{=html} Adjust the sample\n\n`<svg aria-hidden=\"true\" role=\"img\" viewBox=\"0 0 512 512\" style=\"height:1em;width:1em;vertical-align:-0.125em;margin-left:auto;margin-right:auto;font-size:inherit;fill:currentColor;overflow:visible;position:relative;\"><path d=\"M173.898 439.404l-166.4-166.4c-9.997-9.997-9.997-26.206 0-36.204l36.203-36.204c9.997-9.998 26.207-9.998 36.204 0L192 312.69 432.095 72.596c9.997-9.997 26.207-9.997 36.204 0l36.203 36.204c9.997 9.997 9.997 26.206 0 36.204l-294.4 294.401c-9.998 9.997-26.207 9.997-36.204-.001z\"/></svg>`{=html} De-identify data\n\n`<svg aria-hidden=\"true\" role=\"img\" viewBox=\"0 0 512 512\" style=\"height:1em;width:1em;vertical-align:-0.125em;margin-left:auto;margin-right:auto;font-size:inherit;fill:currentColor;overflow:visible;position:relative;\"><path d=\"M173.898 439.404l-166.4-166.4c-9.997-9.997-9.997-26.206 0-36.204l36.203-36.204c9.997-9.998 26.207-9.998 36.204 0L192 312.69 432.095 72.596c9.997-9.997 26.207-9.997 36.204 0l36.203 36.204c9.997 9.997 9.997 26.206 0 36.204l-294.4 294.401c-9.998 9.997-26.207 9.997-36.204-.001z\"/></svg>`{=html} Drop irrelevant columns\n\n`<svg aria-hidden=\"true\" role=\"img\" viewBox=\"0 0 512 512\" style=\"height:1em;width:1em;vertical-align:-0.125em;margin-left:auto;margin-right:auto;font-size:inherit;fill:currentColor;overflow:visible;position:relative;\"><path d=\"M173.898 439.404l-166.4-166.4c-9.997-9.997-9.997-26.206 0-36.204l36.203-36.204c9.997-9.998 26.207-9.998 36.204 0L192 312.69 432.095 72.596c9.997-9.997 26.207-9.997 36.204 0l36.203 36.204c9.997 9.997 9.997 26.206 0 36.204l-294.4 294.401c-9.998 9.997-26.207 9.997-36.204-.001z\"/></svg>`{=html} Split columns\n\n`<svg aria-hidden=\"true\" role=\"img\" viewBox=\"0 0 512 512\" style=\"height:1em;width:1em;vertical-align:-0.125em;margin-left:auto;margin-right:auto;font-size:inherit;fill:currentColor;overflow:visible;position:relative;\"><path d=\"M173.898 439.404l-166.4-166.4c-9.997-9.997-9.997-26.206 0-36.204l36.203-36.204c9.997-9.998 26.207-9.998 36.204 0L192 312.69 432.095 72.596c9.997-9.997 26.207-9.997 36.204 0l36.203 36.204c9.997 9.997 9.997 26.206 0 36.204l-294.4 294.401c-9.998 9.997-26.207 9.997-36.204-.001z\"/></svg>`{=html} Rename variables\n\n`<svg aria-hidden=\"true\" role=\"img\" viewBox=\"0 0 512 512\" style=\"height:1em;width:1em;vertical-align:-0.125em;margin-left:auto;margin-right:auto;font-size:inherit;fill:currentColor;overflow:visible;position:relative;\"><path d=\"M173.898 439.404l-166.4-166.4c-9.997-9.997-9.997-26.206 0-36.204l36.203-36.204c9.997-9.998 26.207-9.998 36.204 0L192 312.69 432.095 72.596c9.997-9.997 26.207-9.997 36.204 0l36.203 36.204c9.997 9.997 9.997 26.206 0 36.204l-294.4 294.401c-9.998 9.997-26.207 9.997-36.204-.001z\"/></svg>`{=html} Normalize variables\n\n`<svg aria-hidden=\"true\" role=\"img\" viewBox=\"0 0 512 512\" style=\"height:1em;width:1em;vertical-align:-0.125em;margin-left:auto;margin-right:auto;font-size:inherit;fill:currentColor;overflow:visible;position:relative;\"><path d=\"M173.898 439.404l-166.4-166.4c-9.997-9.997-9.997-26.206 0-36.204l36.203-36.204c9.997-9.998 26.207-9.998 36.204 0L192 312.69 432.095 72.596c9.997-9.997 26.207-9.997 36.204 0l36.203 36.204c9.997 9.997 9.997 26.206 0 36.204l-294.4 294.401c-9.998 9.997-26.207 9.997-36.204-.001z\"/></svg>`{=html} Standardize variables\n\n:::\n \n::: {.column width=\"50%\"}\n\n`<svg aria-hidden=\"true\" role=\"img\" viewBox=\"0 0 512 512\" style=\"height:1em;width:1em;vertical-align:-0.125em;margin-left:auto;margin-right:auto;font-size:inherit;fill:currentColor;overflow:visible;position:relative;\"><path d=\"M173.898 439.404l-166.4-166.4c-9.997-9.997-9.997-26.206 0-36.204l36.203-36.204c9.997-9.998 26.207-9.998 36.204 0L192 312.69 432.095 72.596c9.997-9.997 26.207-9.997 36.204 0l36.203 36.204c9.997 9.997 9.997 26.206 0 36.204l-294.4 294.401c-9.998 9.997-26.207 9.997-36.204-.001z\"/></svg>`{=html} Update variable types\n\n`<svg aria-hidden=\"true\" role=\"img\" viewBox=\"0 0 512 512\" style=\"height:1em;width:1em;vertical-align:-0.125em;margin-left:auto;margin-right:auto;font-size:inherit;fill:currentColor;overflow:visible;position:relative;\"><path d=\"M173.898 439.404l-166.4-166.4c-9.997-9.997-9.997-26.206 0-36.204l36.203-36.204c9.997-9.998 26.207-9.998 36.204 0L192 312.69 432.095 72.596c9.997-9.997 26.207-9.997 36.204 0l36.203 36.204c9.997 9.997 9.997 26.206 0 36.204l-294.4 294.401c-9.998 9.997-26.207 9.997-36.204-.001z\"/></svg>`{=html} Recode variables\n\n`<svg aria-hidden=\"true\" role=\"img\" viewBox=\"0 0 512 512\" style=\"height:1em;width:1em;vertical-align:-0.125em;margin-left:auto;margin-right:auto;font-size:inherit;fill:currentColor;overflow:visible;position:relative;\"><path d=\"M173.898 439.404l-166.4-166.4c-9.997-9.997-9.997-26.206 0-36.204l36.203-36.204c9.997-9.998 26.207-9.998 36.204 0L192 312.69 432.095 72.596c9.997-9.997 26.207-9.997 36.204 0l36.203 36.204c9.997 9.997 9.997 26.206 0 36.204l-294.4 294.401c-9.998 9.997-26.207 9.997-36.204-.001z\"/></svg>`{=html} Construct new variables\n\n`<svg aria-hidden=\"true\" role=\"img\" viewBox=\"0 0 512 512\" style=\"height:1em;width:1em;vertical-align:-0.125em;margin-left:auto;margin-right:auto;font-size:inherit;fill:currentColor;overflow:visible;position:relative;\"><path d=\"M173.898 439.404l-166.4-166.4c-9.997-9.997-9.997-26.206 0-36.204l36.203-36.204c9.997-9.998 26.207-9.998 36.204 0L192 312.69 432.095 72.596c9.997-9.997 26.207-9.997 36.204 0l36.203 36.204c9.997 9.997 9.997 26.206 0 36.204l-294.4 294.401c-9.998 9.997-26.207 9.997-36.204-.001z\"/></svg>`{=html} Add missing values\n\n`<svg aria-hidden=\"true\" role=\"img\" viewBox=\"0 0 512 512\" style=\"height:1em;width:1em;vertical-align:-0.125em;margin-left:auto;margin-right:auto;font-size:inherit;fill:currentColor;overflow:visible;position:relative;\"><path d=\"M173.898 439.404l-166.4-166.4c-9.997-9.997-9.997-26.206 0-36.204l36.203-36.204c9.997-9.998 26.207-9.998 36.204 0L192 312.69 432.095 72.596c9.997-9.997 26.207-9.997 36.204 0l36.203 36.204c9.997 9.997 9.997 26.206 0 36.204l-294.4 294.401c-9.998 9.997-26.207 9.997-36.204-.001z\"/></svg>`{=html} [Add metadata](https://github.com/Cghlewis/data-wrangling-functions/wiki/Label-Data)\n\n`<svg aria-hidden=\"true\" role=\"img\" viewBox=\"0 0 512 512\" style=\"height:1em;width:1em;vertical-align:-0.125em;margin-left:auto;margin-right:auto;font-size:inherit;fill:currentColor;overflow:visible;position:relative;\"><path d=\"M173.898 439.404l-166.4-166.4c-9.997-9.997-9.997-26.206 0-36.204l36.203-36.204c9.997-9.998 26.207-9.998 36.204 0L192 312.69 432.095 72.596c9.997-9.997 26.207-9.997 36.204 0l36.203 36.204c9.997 9.997 9.997 26.206 0 36.204l-294.4 294.401c-9.998 9.997-26.207 9.997-36.204-.001z\"/></svg>`{=html} Validate data\n\n`<svg aria-hidden=\"true\" role=\"img\" viewBox=\"0 0 512 512\" style=\"height:1em;width:1em;vertical-align:-0.125em;margin-left:auto;margin-right:auto;font-size:inherit;fill:currentColor;overflow:visible;position:relative;\"><path d=\"M173.898 439.404l-166.4-166.4c-9.997-9.997-9.997-26.206 0-36.204l36.203-36.204c9.997-9.998 26.207-9.998 36.204 0L192 312.69 432.095 72.596c9.997-9.997 26.207-9.997 36.204 0l36.203 36.204c9.997 9.997 9.997 26.206 0 36.204l-294.4 294.401c-9.998 9.997-26.207 9.997-36.204-.001z\"/></svg>`{=html} [Join data](https://cghlewis.com/blog/joins/)\n\n`<svg aria-hidden=\"true\" role=\"img\" viewBox=\"0 0 512 512\" style=\"height:1em;width:1em;vertical-align:-0.125em;margin-left:auto;margin-right:auto;font-size:inherit;fill:currentColor;overflow:visible;position:relative;\"><path d=\"M173.898 439.404l-166.4-166.4c-9.997-9.997-9.997-26.206 0-36.204l36.203-36.204c9.997-9.998 26.207-9.998 36.204 0L192 312.69 432.095 72.596c9.997-9.997 26.207-9.997 36.204 0l36.203 36.204c9.997 9.997 9.997 26.206 0 36.204l-294.4 294.401c-9.998 9.997-26.207 9.997-36.204-.001z\"/></svg>`{=html} [Reshape data](https://osf.io/xumg4)\n\n`<svg aria-hidden=\"true\" role=\"img\" viewBox=\"0 0 512 512\" style=\"height:1em;width:1em;vertical-align:-0.125em;margin-left:auto;margin-right:auto;font-size:inherit;fill:currentColor;overflow:visible;position:relative;\"><path d=\"M173.898 439.404l-166.4-166.4c-9.997-9.997-9.997-26.206 0-36.204l36.203-36.204c9.997-9.998 26.207-9.998 36.204 0L192 312.69 432.095 72.596c9.997-9.997 26.207-9.997 36.204 0l36.203 36.204c9.997 9.997 9.997 26.206 0 36.204l-294.4 294.401c-9.998 9.997-26.207 9.997-36.204-.001z\"/></svg>`{=html} Save clean data\n\n:::\n:::\n\n::: {.notes}\n\nHowever, to produce datasets that consistently meet the data quality criteria we just reviewed, it can be helpful to follow a standardized checklist of data cleaning steps. These steps, although they are really general here, once you tailor them to your specific data source they can help you produce a dataset that meets our data quality standards. \n\nAs you use this checklist to clean your specific datasaet you use the steps that are relevant to your data and remove the steps that are not relevant. \n\nThe order of these steps are fluid. With the exception of the first two on the list, you can move them around in whatever order makes sense for your specific dataset.\n\nWe are going to take some time to review each step on this list with the exception of the ones in blue. Those require more time to cover than we have today, so instead I have linked to more information here for you to review in your own time.\n\n\n:::\n\n## Import raw data\n\n![](images/checklist1.PNG){fig-align=\"center\"}\n\n::: {.notes}\n\nImporting your raw data will always be number one of course, and the most important rule here is to never make any manual edits directly in the raw data file. Your raw data file is your single source of truth for that data source. If you make errors in your data cleaning process, you should always be able to go back to the untouched raw data to start over again if you need to. \n\n:::\n\n## Review data\n\n![](images/checklist2.PNG){fig-align=\"center\"}\n\n::: {.notes}\n\nReviewing your data should always be step number two. It's important that you know exactly what is happening in your data before moving forward in the cleaning process.\n\nIf you have access to those documents we discussed earlier, participant tracking database and a data dictionary, now is the time to use them.\n\n:::\n\n## Find missing data\n\n![](images/checklist3.PNG){fig-align=\"center\"}\n\n::: {.notes}\n\nIf you find that any data is missing in your review process (missing cases/missing variables) you'll want to retrieve that missing data before moving forward in the cleaning process\n\nStart back at step 1\n\n:::\n\n## Adjust the sample\n\n![](images/checklist4.PNG){fig-align=\"center\"}\n\n::: {.notes}\n\nThis means removing anyone who should not be in the dataset - maybe they didn't consent to be in the study\n\nIt also means taking care of any duplicates in your data\n\nThe first thing you'll want to do before removing duplicates is determine if it is a true duplicate, not just an error in the data\n\nThen removing any true duplicates based on your duplicate removal rule\n\nIt's really important that these kinds of decisions rules are documented for future data users. And we'll talk more about where to document these kinds of things later.\n\n:::\n\n## De-identify data\n\n![](images/checklist5-1.PNG){fig-align=\"center\"}\n\n## De-identify data\n\n![](images/checklist5-2.PNG){fig-align=\"center\"}\n\n## De-identify data\n\n![](images/checklist5-3.PNG){fig-align=\"center\"}\n\n|Source|Resource|\n|--------|-----------|\n|[Alena Filip](https://www.sjsu.edu/research/docs/irb-data-management-handbook.pdf) |Table 2 provides pros and cons of various de-identification methods|\n|[J-PAL](https://www.povertyactionlab.org/resource/data-de-identification)| Table 3 provides a list of direct and indirect identifiers and recommended removal methods|\n|[Schatschneider, et.al](https://figshare.com/articles/preprint/De-Identification_Guide/13228664)| Deidentifying Data Guide|\n\n:::{.notes}\n\n- Redaction\n  - Eliminate the entire variable from the data\n- Suppression\n  - Remove data in a particular cell or row (In this example, age 67 was an outlier so I suppressed that cell value and replaced it with -98 which Iâ€™ve coded as suppressed).\n- Generalization\n  - Reduce precision in the data (In this example here, Iâ€™ve binned my age rages so they are less precise)\n- Truncation\n  - Restricting upper and lower ranges to mask outliers\n  \nThere are many, even more sophisticated ways, to de-identify data\n\n:::\n\n## Drop irrelevant columns\n\n<br>\n\n![](images/checklist6.PNG){fig-align=\"center\"}\n\n## Split columns\n\n![](images/checklist7.PNG){fig-align=\"center\"}\n\n## Rename variables\n\n![](images/checklist8.PNG){fig-align=\"center\"}\n\n## Normalize variables\n\n- Compare the variable types in your raw data to the types you expected in your data dictionary. \n  - Do they align? If not, what needs to be done so that they do\n\n![](images/checklist9.PNG){fig-align=\"center\"}\n\n:::{.notes}\n\nI realize this is unconventional terminology to use, but here I am using the term normalize to talk about returning variables to their normal or expected state. \n\n:::\n\n## Standardize variables\n\n- Are columns consistently measured, categorized, and formatted according to your data dictionary?\n  - If not, what needs to be done so that they are\n\n![](images/checklist10.PNG){fig-align=\"center\"}\n\n:::{.notes}\n\nHere I am using the term standardize to convey the process of checking for consistency\n\n:::\n\n## Update variable types\n\n![](images/checklist11.PNG){fig-align=\"center\"}\n\n:::{.notes}\n\nCharacter to Numeric, Numeric to Date, And so forth\n\n:::\n\n## Recode variables\n\n![](images/checklist12.PNG){fig-align=\"center\"}\n\n:::{.notes}\n\n- This includes recoding your categorical numeric values to match your data dictionary values\n- But it also includes any planned coding, such as reverse coding a variable\n- As well as recoding any implicit values to their explicit values\n\n:::\n\n## Construct additional variables\n\n![](images/checklist13.PNG){fig-align=\"center\"}\n\n:::{.notes}\n\n- This is not the time to construct analysis-specific variables. This is the time to create or calculate variables that should always be a part of the core study dataset.\n\n- This could be things like grouping variables (treatment, cohort, site)\n- It could be time component variables (year, wave)\n- It could be additional unique identifiers that you need to add for linking purposes (like adding a school ID to a teacher file)\n- Or it could be measure composite or summary scores that you want included in the core dataset\n- Any other variables you want added to the core sharing dataset\n\n- Some of these variables will be calculated, others may be merged in from other sources\n\n:::\n\n## Add missing values\n\n![](images/checklist14.PNG){fig-align=\"center\"}\n\n\n## Data validation\n\n::: columns\n\n::: {.column width=\"50%\"}\n\n![](images/checklist15-1.PNG)\n\n:::\n\n::: {.column width=\"50%\"}\n\n::: {layout-nrow=2}\n\n![](images/checklist15-2.PNG)\n\n![](images/checklist15-3.PNG)\n\n:::\n\n:::\n:::\n\n:::{.notes}\n\nYou should absolutely be checking your transformations throughout your cleaning process, but then, before exporting your data you should do one final review to make sure you haven't missed anything.  \n\nHere are several examples where various researchers did not have data validation as part of their data cleaning process and found out much later on that their data contained errors. And so we want to try to prevent this scenario by catching any errors now, rather than later.\n\n:::\n\n\n## Data validation\n\n:::: {.columns}\n\n::: {.column width=\"60%\"}\n\n- Complete\n  - Check for missing/duplicate cases\n    - Check Ns by groups for completeness\n  - Check for missing/too many columns\n- Valid and consistent\n  - Check for unallowed categories/values out of range\n    - Check ranges by groups\n  - Check for invalid, non-unique, or missing study IDs\n  - Check for incorrect variable types/formats\n  - Check missing value patterns\n\n:::\n \n::: {.column width=\"40%\"}\n\n- Accurate\n  - Agreement across variables\n- De-identified\n  - All direct identifiers are removed\n  - All indirect identifiers managed as needed\n- Interpretable\n  - Variables correctly named\n\n:::\n:::\n\n:::{.notes}\n\nUse your data quality indicator list as a guide when doing your final data review\n\n:::\n\n## Data validation\n\n:::: {.columns}\n\n::: {.column width=\"60%\"}\n\n1. Documentation errors\n    - Fix in documentation\n2. Data cleaning errors\n    - Fix in your cleaning process\n3. Data entry/export process errors\n    - Fix at the source and export new raw file\n4. True values that are inaccurate, uninterpretable, or outside of a valid range\n    - Leave the data as is (document the issue)\n    - Recode those values to designated error code\n    - Create data quality indicators\n    - Choose one source of truth for inconsistent values\n    - Use logical/deductive editing\n    \n:::\n \n::: {.column width=\"40%\"}\n\n![](images/checklist15-4.PNG){fig-align=\"center\"}\n\n:::\n:::\n\n:::{.notes}\n\nWhat's most important is that you document your decisions for future users\n\n:::\n\n## Export data\n\n<br>\n\n![](images/checklist16.jpg){fig-align=\"center\"}\n\n## Creating a data cleaning plan\n\n![](images/data_cleaning_plan.PNG){fig-align=\"center\"}\n\n\n:::{.notes}\n\nUltimately what I like to do in a cleaning process is pull out my checklist, import and review my data, and then plan out the steps that are needed to clean my specific dataset\n\n:::\n\n## BREAK!\n\n![](https://media1.tenor.com/m/XFNnJtXYH_gAAAAC/dog-wipe-face.gif){fig-align=\"center\" width=80%}\n\n## BREAK!\n\n::: {.cell}\n::: {.cell-output-display}\n\n```{=html}\n<div class=\"countdown\" data-update-every=\"1\" id=\"timer_17e8131a\" style=\"right:0;bottom:0;--countdown-font-size:10em; position: relative; width: min-content;\" tabindex=\"0\">\n<div class=\"countdown-controls\"><button class=\"countdown-bump-down\">&minus;</button><button class=\"countdown-bump-up\">&plus;</button></div>\n<code class=\"countdown-time\"><span class=\"countdown-digits minutes\">15</span><span class=\"countdown-digits colon\">:</span><span class=\"countdown-digits seconds\">00</span></code>\n</div>\n```\n\n:::\n:::\n\n# Cleaning in R {.background-secondary}\n\n:::{.notes}\n\nBefore we jump in I just want to preface this section with the understanding that this material isn't about learning all of the various ways you may be able to solve every unique data cleaning problem. There's no way to cover that much material, and on top of that, for every data cleaning issue you encounter in your data, there are probably 10 different ways to solve that issue. So I am sharing this to say, that this section is not about learning a specific set of data cleaning functions, it is about learning a standardized way of thinking through a data cleaning process and pulling from the available R functions, some of which we will learn today, to work through that process. \n\n:::\n\n## Packages\n\n- R has many built in (base) functions\n- We can also use functions that live in packages that we can install onto our computer\n\n- Once installed, there are two ways to call packages\n  - You may see both methods used in these slides\n\n<br>\n\n::: columns\n::: {.column width=\"50%\"}\n\nUsing `library()`\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(dplyr)\n\nselect(df, var1, var2) \n```\n:::\n:::\n\n::: {.column width=\"50%\"}\n\nUsing Namespacing `package::function()`\n\n::: {.cell}\n\n```{.r .cell-code}\n# library(dplyr) not needed\n\ndplyr::select(df, var1, var2) \n```\n:::\n:::\n:::\n\n:::{.notes}\n\nFoundational\n\n:::\n\n## Tidyverse\n\n<br>\n\nAn opinionated collection of R packages designed for data science\n\nAll packages share an underlying design philosophy, grammar, and data structures\n\n<br>\n\n::: {layout-nrow=4}\n\n![](images/dplyr.png)\n![](images/tidyr.png)\n![](images/stringr.png)\n![](images/readr.png)\n![](images/purrr.png)\n\n:::\n\n## Tidyverse\n\n<br>\n\nSelecting `test_score` and `grade_level` from our data frame named `sch_data`\n\n<br>\n\n::: columns\n::: {.column width=\"50%\"}\n\n[Tidy Evaluation](https://dplyr.tidyverse.org/articles/programming.html)\n\n<br>\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nselect(sch_data, test_score, \n       grade_level)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 2 x 2\n  test_score grade_level\n       <dbl>       <dbl>\n1          3         380\n2        290           3\n```\n\n\n:::\n:::\n:::\n\n::: {.column width=\"50%\"}\n\nBase R\n\n<br>\n\n::: {.cell}\n\n```{.r .cell-code}\nsch_data[ , c(\"test_score\", \n              \"grade_level\")]\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 2 x 2\n  test_score grade_level\n       <dbl>       <dbl>\n1          3         380\n2        290           3\n```\n\n\n:::\n:::\n:::\n:::\n\n## Pipes\n\n-   2014+ magrittr pipe `%>%`\n\n-   2021+ (R $\\geq$ 4.1.0) native R pipe `|>`\n\n. . .\n\nIsabella VelÃ¡squez's blog post [*Understanding the native R pipe* \\|\\>](https://ivelasq.rbind.io/blog/understanding-the-r-pipe/) (2022)\n\n<br>\n\n. . .\n\n::: columns\n::: {.column width=\"50%\"}\n::: {.cell}\n\n```{.r .cell-code}\nsch_data <- select(sch_data, id, \n                    test_score)\n\nsch_data <- filter(sch_data, \n                    test_score > 300)\n```\n:::\n:::\n\n::: {.column width=\"50%\"}\n::: {.cell}\n\n```{.r .cell-code}\nsch_data <- sch_data |>\n  select(id, test_score) |>\n  filter(test_score > 300)\n```\n:::\n:::\n:::\n\n. . .\n\n<br>\n\nTo turn on the native pipe:\n\n`Tools` â†’ `Global Options` â†’ `Code` â†’ `Editing` â†’ `Use Native Pipe Operator`\n\n## Operators\n\n::: columns\n::: {.column width=\"50%\"}\n\nComparison operators\n\n- `==` equal to\n- `!=` not equal to\n- `<` less than\n- `>` greater than\n- `%in%` value is present within\n\n::: {.cell}\n\n```{.r .cell-code}\ndf |>\n  filter(city %in% c(\"boston\",\"philly\"))\n```\n:::\n\n:::\n\n::: {.column width=\"50%\"}\n\nAssignment operators\n\n- `<-` Assign value to an object\n- `=` Assign value to an object\n\n::: {.cell}\n\n```{.r .cell-code}\ndf <- df |>\n  mutate(year = \"2024\")\n```\n:::\n\n:::\n:::\n\n## Scenario\n\n#### Take 5 minutes to open and look at our data file.\n\n1. Log in to Posit Cloud and navigate to our project\n    - [**https://posit.cloud/content/7872027**](https://posit.cloud/content/7872027)\n2. Open the `data` folder and open \"sample_tch_svy_raw.xlsx\"\n    - Notice that the \"labels\" tab has some basic information about the variables\n\n![](images/sample-data.PNG){fig-align=\"center\"}\n\n::: {.cell}\n::: {.cell-output-display}\n\n```{=html}\n<div class=\"countdown\" id=\"timer_ab00b36e\" data-update-every=\"1\" tabindex=\"0\" style=\"right:0;bottom:0;--countdown-font-size:2em;\">\n<div class=\"countdown-controls\"><button class=\"countdown-bump-down\">&minus;</button><button class=\"countdown-bump-up\">&plus;</button></div>\n<code class=\"countdown-time\"><span class=\"countdown-digits minutes\">05</span><span class=\"countdown-digits colon\">:</span><span class=\"countdown-digits seconds\">00</span></code>\n</div>\n```\n\n:::\n:::\n\n\n## Import our data\n\n<br>\n\nCommon data importing functions\n\n- `read_csv()`, `read_delim()` from the `readr` package\n\n- `read_excel()` from the `readxl` package\n\n- `read_sav()`, `read_sas()`, `read_dta()` from the `haven` package\n\n- Learn more about importing multiple files at once [here](https://github.com/Cghlewis/data-wrangling-functions/wiki/Import-Files)\n\n<br>\n\n. . .\n\n**Which function should we use to read in our sample data?**ðŸ¤”\n\n## Import our file\n\n::: columns\n \n::: {.column width=\"50%\"}\n\n- `read_excel()` has several arguments. \n  - path\n  - sheet = NULL\n  - col_names = TRUE\n  - na = \"\"\n  - skip = 0\n- Type `?read_excel()` in your console to see more arguments\n\n:::\n\n::: {.column width=\"50%\"}\n\n![](images/read_excel.PNG){fig-align=\"center\"}\n\n:::\n:::\n\n\n## [Exercise]{style=\"color:#ccd64d\"}{.background-secondary}\n\n<br>\n\n### Take 3 minutes to import the data.\n\n<br>\n\n1. Open \"exercises.Rmd\" in our Posit Cloud project.\n2. Navigate to exercise 1.\n3. Update the code and run the code chunks using the green arrows.\n4. If you get stuck, you can open \"solutions.Rmd\"\n\n::: {.cell}\n::: {.cell-output-display}\n\n```{=html}\n<div class=\"countdown\" id=\"timer_35645264\" data-update-every=\"1\" tabindex=\"0\" style=\"right:0;bottom:0;--countdown-font-size:2em;\">\n<div class=\"countdown-controls\"><button class=\"countdown-bump-down\">&minus;</button><button class=\"countdown-bump-up\">&plus;</button></div>\n<code class=\"countdown-time\"><span class=\"countdown-digits minutes\">03</span><span class=\"countdown-digits colon\">:</span><span class=\"countdown-digits seconds\">00</span></code>\n</div>\n```\n\n:::\n:::\n\n## Review our data\n\n::: columns\n::: {.column width=\"50%\"}\n\n- How many rows?\n  - In this hypothetical situation, we assume we are not missing any cases\n  - However, there may be duplicates\n- How many columns?\n  - Compare to our data dictionary\n- What are the variable values and ranges?\n  - Compare to our data dictionary\n- How much missing data do we have?\n\n:::\n\n::: {.column width=\"50%\"}\n\nThere are several functions we can use to explore data\n\n- `dplyr::glimpse()`\n- `skimr::skim()`\n- `base::summary()`\n- **`summarytools::dfSummary()`**\n- `Hmisc::describe()`\n\n:::\n:::\n\n## [Exercise]{style=\"color:#ccd64d\"}{.background-secondary}\n\n<br>\n\n### Take 5 minutes to review our data.\n\n1. Navigate to exercise 2.\n2. Run the code. \n    - Write down any potential issues you see in the data.\n3. Open \"sample_tch_svy_data_dictionary.xlsx\" in the `docs` folder. \n    - What issues do you see when you compare the data to our data dictionary?\n4. Review \"sample_tch_svy_cleaning-plan.txt\" in the `docs` folder. \n    - How does it compare to the issues you wrote down?\n\n::: {.cell}\n::: {.cell-output-display}\n\n```{=html}\n<div class=\"countdown\" id=\"timer_d190cb32\" data-update-every=\"1\" tabindex=\"0\" style=\"right:0;bottom:0;--countdown-font-size:2em;\">\n<div class=\"countdown-controls\"><button class=\"countdown-bump-down\">&minus;</button><button class=\"countdown-bump-up\">&plus;</button></div>\n<code class=\"countdown-time\"><span class=\"countdown-digits minutes\">05</span><span class=\"countdown-digits colon\">:</span><span class=\"countdown-digits seconds\">00</span></code>\n</div>\n```\n\n:::\n:::\n\n:::{.notes}\n\nSo we are going to follow this data cleaning plan for the rest of this section\n\n:::\n\n\n## Adjust the sample\n\n<br>\n\nThere are two key functions we can use to both identify and remove duplicates in our data\n\n<br>\n\n  - `janitor::get_dupes()`\n    - Tells you which rows contain duplicate unique identifiers, if any\n  - `dplyr::distinct()`\n    - Keeps the first instance of a duplicate unique identifier\n      - Helpful to first use `dplyr::arrange()` so that your data is always sorted the same way before dropping your duplicates\n      \n:::{.notes}\n\nSo the next step in our checklist is to adjust the sample\nAnd we found some duplicates in our sample\n\n:::\n  \n## Adjust the sample\n\n<br>\n\n::: columns\n::: {.column width=\"50%\"}\n\nCheck for duplicates\n\n::: {.cell}\n\n```{.r .cell-code}\ndf |>\n  get_dupes(id_vars)\n```\n:::\n\n- Replace `id_vars` with your unique identifier\n- If you have more than one variable that uniquely identifies rows, use `c(first_name, last_name)`\n\n:::\n\n::: {.column width=\"50%\"}\n\nRemove duplicates\n\n::: {.cell}\n\n```{.r .cell-code}\ndf |>\n  arrange(another_identier) |>\n  distinct(id_vars, \n           .keep_all = TRUE)\n```\n:::\n- Replace `another_identifier` with a variable that makes your duplicates unique (e.g., \"date\")\n  - The default is to sort values in ascending order\n- Replace `id_vars` with your unique identifier/s\n- Always add the argument *.keep_all = TRUE*\n\n\n:::\n:::\n\n\n## [Exercise]{style=\"color:#ccd64d\"}{.background-secondary}\n\n<br>\n\n### Take 5 minutes to check for and remove duplicates.\n\n1. Navigate to exercise 3.\n2. Run the code to check for duplicates. \n    - Which `tch_id` is duplicated?\n3. Run the code to remove our duplicates. \n    - Our documented rule is that if both surveys are complete, keep the most recently completed row.\n4. Run a check to make sure duplicates are removed.\n5. Run the code to confirm that we kept the most recent submission of the duplicate survey (\"2024-04-02\").\n\n::: {.cell}\n::: {.cell-output-display}\n\n```{=html}\n<div class=\"countdown\" id=\"timer_2a9a3336\" data-update-every=\"1\" tabindex=\"0\" style=\"right:0;bottom:0;--countdown-font-size:2em;\">\n<div class=\"countdown-controls\"><button class=\"countdown-bump-down\">&minus;</button><button class=\"countdown-bump-up\">&plus;</button></div>\n<code class=\"countdown-time\"><span class=\"countdown-digits minutes\">05</span><span class=\"countdown-digits colon\">:</span><span class=\"countdown-digits seconds\">00</span></code>\n</div>\n```\n\n:::\n:::\n\n## De-identify data\n\n<br>\n\nThe functions used here will depend on what is required.\n\n<br>\n\nExamples of functions you might use:\n\n- `dplyr::select()` to drop variables\n- `dplyr::case_when()` or `dplyr::recode()` to collapse categories/recode values\n- `dplyr::*_join()` to merge in study unique IDs\n- `stringr::str_remove_all()` or `stringr::str_replace_all()` to redact character values\n\n\nFor our sample data we are going to use the following.\n\n1. `dplyr::select()` to drop identifying variables and\n2. `dplyr::case_when()` to recategorize names into our unique study ID values\n\n## De-identify data - Select\n\n<br>\n\n\n::: columns\n::: {.column width=\"50%\"}\n\nTo select variables of interest\n\n::: {.cell}\n\n```{.r .cell-code}\ndf |>\n  select(varname1, varname2, varname3)\n```\n:::\n\n\n:::\n\n::: {.column width=\"50%\"}\n\nTo drop variables I add `-`\n\n::: {.cell}\n\n```{.r .cell-code}\ndf |>\n  select(-varname1)\n```\n:::\n\n- If I had more than one variable to drop, I can use `-c(var1, var2)`\n\n:::\n:::\n\n## De-identify data - Categorize\n\n<br>\n\n::: {.cell}\n\n```{.r .cell-code}\ndf |>\n  dplyr::mutate(new_var_name =\n                  case_when(\n                    var_name == old_value1 ~ new_value1,\n                    var_name == old_value2 ~ new_value2,\n                  ))\n```\n:::\n\n\n- To learn more about setting *default* values for `case_when()`, type `?case_when` in your console\n- Note that there is a new function, `case_match()`, that is worth looking in to. It reduces repetition in the syntax.\n\n## [Exercise]{style=\"color:#ccd64d\"}{.background-secondary}\n\n<br>\n\n### Take 5 minutes to de-identify our data\n\n1. Navigate to exercise 4.\n2. Run the code to create a `sch_id` variable.\n    - Review the new variable after it is created.\n3. Run the code to drop our identifying variables.\n    - Review to make sure those variables were removed.\n\n::: {.cell}\n::: {.cell-output-display}\n\n```{=html}\n<div class=\"countdown\" id=\"timer_6fafe0c7\" data-update-every=\"1\" tabindex=\"0\" style=\"right:0;bottom:0;--countdown-font-size:2em;\">\n<div class=\"countdown-controls\"><button class=\"countdown-bump-down\">&minus;</button><button class=\"countdown-bump-up\">&plus;</button></div>\n<code class=\"countdown-time\"><span class=\"countdown-digits minutes\">05</span><span class=\"countdown-digits colon\">:</span><span class=\"countdown-digits seconds\">00</span></code>\n</div>\n```\n\n:::\n:::\n\n## Rename variables\n\nTwo functions we can use to rename variables\n\n- `dplyr::rename()`\n    - Commonly used to rename just a few variables\n- `purrr::set_names()`\n    - Used to rename all of our variables\n    - Variables must be in the exact right order\n\n<br>\n\n::: columns\n::: {.column width=\"50%\"}\n\nRename one variable\n\n::: {.cell}\n\n```{.r .cell-code}\ndf |>\n  rename(new_name = old_name)\n```\n:::\n\n:::\n\n::: {.column width=\"50%\"}\n\nRename all variables\n\n::: {.cell}\n\n```{.r .cell-code}\ndf |>\n  set_names(c(\"name1\", \"name2\", \"name3\"))\n```\n:::\n\n:::\n:::\n\n## [Exercise]{style=\"color:#ccd64d\"}{.background-secondary}\n\n<br>\n\n### Take 3 minutes to rename variables\n\n1. Navigate to exercise 3.\n2. Review the current variable names.\n3. Rename variables according to our data dictionary.\n4. Check variable names again to make sure the renaming worked.\n\n::: {.cell}\n::: {.cell-output-display}\n\n```{=html}\n<div class=\"countdown\" id=\"timer_a202adb5\" data-update-every=\"1\" tabindex=\"0\" style=\"right:0;bottom:0;--countdown-font-size:2em;\">\n<div class=\"countdown-controls\"><button class=\"countdown-bump-down\">&minus;</button><button class=\"countdown-bump-up\">&plus;</button></div>\n<code class=\"countdown-time\"><span class=\"countdown-digits minutes\">03</span><span class=\"countdown-digits colon\">:</span><span class=\"countdown-digits seconds\">00</span></code>\n</div>\n```\n\n:::\n:::\n\n\n## Normalize variables\n\nThere are several functions that can help us remove unexpected values from our variables. \n\nSome examples of those include:\n\n- `stringr::str_remove_all()`\n- `stringr::str_replace_all()`\n- `readr::parse_number()`\n\n<br>\n\nSay this is our data\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 3 x 2\n     id income \n  <dbl> <chr>  \n1     1 $32,000\n2     2 120000 \n3     3 $45,000\n```\n\n\n:::\n:::\n\n\n## Normalize variables\n\n<br>\n\n::: columns\n::: {.column width=\"50%\"}\n\nRemove character values with `stringr::str_remove_all()`\n\n::: {.cell}\n\n```{.r .cell-code}\ndf |>\n  dplyr::mutate(income = \n                  str_remove_all(income, \"\\\\$|,\"))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 3 x 2\n     id income\n  <dbl> <chr> \n1     1 32000 \n2     2 120000\n3     3 45000 \n```\n\n\n:::\n:::\n\n- Notice that our variable is still character type\n\n:::\n\n::: {.column width=\"50%\"}\n\nRemove character values with `readr::parse_number()`\n\n::: {.cell}\n\n```{.r .cell-code}\ndf |>\n  dplyr::mutate(income = \n                  parse_number(income))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 3 x 2\n     id income\n  <dbl>  <dbl>\n1     1  32000\n2     2 120000\n3     3  45000\n```\n\n\n:::\n:::\n\n- Notice that `parse_number()` converts our variable to numeric type\n\n:::\n:::\n\n## [Exercise]{style=\"color:#ccd64d\"}{.background-secondary}\n\n<br>\n\n### Take 3 minutes to normalize our `tch_yrs` variable\n\n1. Navigate to exercise 6.\n2. Review the current values for `tch_yrs`.\n3. Remove all non-numeric values from this variable.\n4. Review the new values in `tch_yrs`.\n\n::: {.cell}\n::: {.cell-output-display}\n\n```{=html}\n<div class=\"countdown\" id=\"timer_9a38877c\" data-update-every=\"1\" tabindex=\"0\" style=\"right:0;bottom:0;--countdown-font-size:2em;\">\n<div class=\"countdown-controls\"><button class=\"countdown-bump-down\">&minus;</button><button class=\"countdown-bump-up\">&plus;</button></div>\n<code class=\"countdown-time\"><span class=\"countdown-digits minutes\">03</span><span class=\"countdown-digits colon\">:</span><span class=\"countdown-digits seconds\">00</span></code>\n</div>\n```\n\n:::\n:::\n\n## Update variable type\n\nDepending on what is needed, there are several functions we can use to change variable types.\n\nSome examples include:\n\n- `as.numeric()`\n- `as.character()`\n- `as.Date()`\n- Several functions in the `lubridate` package to assist with converting dates\n- `janitor::excel_numeric_to_date()` can be very helpful at times\n\n## Update variable type\n\nIt's important to normalize variables **before** converting types (especially when converting from character to numeric)\n\n<br>\n\n::: columns\n::: {.column width=\"50%\"}\n\nOur data without normalizing\n\n::: {.cell}\n\n```{.r .cell-code}\ndf\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 3 x 2\n     id income \n  <dbl> <chr>  \n1     1 $32,000\n2     2 120000 \n3     3 $45,000\n```\n\n\n:::\n:::\n\n:::\n\n::: {.column width=\"50%\"}\n\nWhen we try to convert `income` to numeric....\n\n::: {.cell}\n\n```{.r .cell-code}\ndf |>\n  dplyr::mutate(income = \n                  as.numeric(income))\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning in mask$eval_all_mutate(quo): NAs introduced by coercion\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 3 x 2\n     id income\n  <dbl>  <dbl>\n1     1     NA\n2     2 120000\n3     3     NA\n```\n\n\n:::\n:::\n\nWe end up converting several values to `NA` (notice our warning)\n\n:::\n:::\n\n## [Exercise]{style=\"color:#ccd64d\"}{.background-secondary}\n\n<br>\n\n### Take 3 minutes to convert `tch_yrs` to numeric\n\n1. Navigate to exercise 7.\n2. Review the current variable type for `tch_yrs`.\n3. Convert the variable to numeric.\n4. Review the new variable type for `tch_yrs`.\n\n::: {.cell}\n::: {.cell-output-display}\n\n```{=html}\n<div class=\"countdown\" id=\"timer_256eca66\" data-update-every=\"1\" tabindex=\"0\" style=\"right:0;bottom:0;--countdown-font-size:2em;\">\n<div class=\"countdown-controls\"><button class=\"countdown-bump-down\">&minus;</button><button class=\"countdown-bump-up\">&plus;</button></div>\n<code class=\"countdown-time\"><span class=\"countdown-digits minutes\">03</span><span class=\"countdown-digits colon\">:</span><span class=\"countdown-digits seconds\">00</span></code>\n</div>\n```\n\n:::\n:::\n\n## Recode variables\n\nCommon functions for recoding values are\n\n- `dplyr::case_when()`\n- `dplyr::recode()`\n- `tidyr::replace_na()`\n\n<br>\n\n::: columns\n::: {.column width=\"50%\"}\n\n::: {.cell}\n\n```{.r .cell-code}\ndf |>\n  mutate(newvar = \n           recode(oldvar,\n                  `oldvalue` = newvalue))\n```\n:::\n\n:::\n\n::: {.column width=\"50%\"}\n\n::: {.cell}\n\n```{.r .cell-code}\ndf |> \n  mutate(newvar = \n           replace_na(oldvar, \n                      replace = 0))\n```\n:::\n\n:::\n:::\n\n## Recode variables\n\n<br>\n\n`dplyr::across()` allows you to apply the same transformation across multiple columns\n\n<br>\n\n::: {.cell}\n\n```{.r .cell-code}\ndf |>\n  mutate(across(var1:var3, \n                ~ case_when(\n                  . == oldvalue1 ~ newvalue1,\n                  . == oldvalue2 ~ newvalue2\n                )))\n```\n:::\n\n\nIf you don't want to save over the existing variables, you can add the argument *.names* which lives in the `dplyr::across()` function. This creates new variables with new names.\n\n## [Exercise]{style=\"color:#ccd64d\"}{.background-secondary}\n\n<br>\n\n### Take 5 minutes to recode variables\n\n1. Navigate to exercise 8.\n2. Recode the blank values for the `grade` variables.  \n    - Check to see if the recoding worked.\n3. Recode the `mathanx` variable.  \n    - Check to see that the recoding worked.\n\n::: {.cell}\n::: {.cell-output-display}\n\n```{=html}\n<div class=\"countdown\" id=\"timer_e003110a\" data-update-every=\"1\" tabindex=\"0\" style=\"right:0;bottom:0;--countdown-font-size:2em;\">\n<div class=\"countdown-controls\"><button class=\"countdown-bump-down\">&minus;</button><button class=\"countdown-bump-up\">&plus;</button></div>\n<code class=\"countdown-time\"><span class=\"countdown-digits minutes\">05</span><span class=\"countdown-digits colon\">:</span><span class=\"countdown-digits seconds\">00</span></code>\n</div>\n```\n\n:::\n:::\n\n## Construct new variables\n\n- The most important function for constructing new variables is `dplyr::mutate()`\n\n- From there, other functions may be required. For today, we are going to use `rowSums()` which allows us to create sum scores for each row\n\n<br>\n\n::: columns\n::: {.column width=\"50%\"}\n\nThe default is to **not** calculate a sum if there are any `NA` values\n\n::: {.cell}\n\n```{.r .cell-code}\ndf |>\n  mutate(newvar = rowSums(\n    across(var1:var3)))\n```\n:::\n\n:::\n\n::: {.column width=\"50%\"}\n\nIf you want to calculate a sum even if there are NA values, add *na.rm = TRUE*\n\n::: {.cell}\n\n```{.r .cell-code}\ndf |>\n  mutate(newvar = rowSums(\n    across(var1:var3), na.rm = TRUE))\n```\n:::\n\n:::\n:::\n\n## [Exercise]{style=\"color:#ccd64d\"}{.background-secondary}\n\n<br>\n\n### Take 3 minutes to construct `gad_sum`\n\n1. Navigate to exercise 9.\n2. Calculate `gad_sum`\n3. Review summary information for the new variable.\n\n::: {.cell}\n::: {.cell-output-display}\n\n```{=html}\n<div class=\"countdown\" id=\"timer_3d68114c\" data-update-every=\"1\" tabindex=\"0\" style=\"right:0;bottom:0;--countdown-font-size:2em;\">\n<div class=\"countdown-controls\"><button class=\"countdown-bump-down\">&minus;</button><button class=\"countdown-bump-up\">&plus;</button></div>\n<code class=\"countdown-time\"><span class=\"countdown-digits minutes\">03</span><span class=\"countdown-digits colon\">:</span><span class=\"countdown-digits seconds\">00</span></code>\n</div>\n```\n\n:::\n:::\n\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<link href=\"../site_libs/countdown-0.5.0/countdown.css\" rel=\"stylesheet\" />\n<script src=\"../site_libs/countdown-0.5.0/countdown.js\"></script>\n"
      ],
      "include-after-body": [
        "\n<script>\n  // htmlwidgets need to know to resize themselves when slides are shown/hidden.\n  // Fire the \"slideenter\" event (handled by htmlwidgets.js) when the current\n  // slide changes (different for each slide format).\n  (function () {\n    // dispatch for htmlwidgets\n    function fireSlideEnter() {\n      const event = window.document.createEvent(\"Event\");\n      event.initEvent(\"slideenter\", true, true);\n      window.document.dispatchEvent(event);\n    }\n\n    function fireSlideChanged(previousSlide, currentSlide) {\n      fireSlideEnter();\n\n      // dispatch for shiny\n      if (window.jQuery) {\n        if (previousSlide) {\n          window.jQuery(previousSlide).trigger(\"hidden\");\n        }\n        if (currentSlide) {\n          window.jQuery(currentSlide).trigger(\"shown\");\n        }\n      }\n    }\n\n    // hookup for slidy\n    if (window.w3c_slidy) {\n      window.w3c_slidy.add_observer(function (slide_num) {\n        // slide_num starts at position 1\n        fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);\n      });\n    }\n\n  })();\n</script>\n\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}